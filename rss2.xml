<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Pega Devlog</title>
    <link>https://jehyunlee.github.io/</link>
    
    <atom:link href="https://jehyunlee.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Pega&#39;s Development log for myself and others</description>
    <pubDate>Wed, 02 Apr 2025 08:06:13 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>GPT로 PPT용 icon pack 만들기</title>
      <link>https://jehyunlee.github.io/2025/03/30/General-78_iconpack/</link>
      <guid>https://jehyunlee.github.io/2025/03/30/General-78_iconpack/</guid>
      <pubDate>Sat, 29 Mar 2025 22:46:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;GPT 이미지 생성 기능이 크게 업그레이드 되었습니다.&lt;/li&gt;
&lt;li&gt;재현성이 좋아졌고, 투명 배경이 가능해졌고, 말을 잘 듣습니다.&lt;/li&gt;
&lt;li&gt;이 업데이트를 모아 자주 쓰는 아이콘 팩을 만듭시다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 i</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>GPT 이미지 생성 기능이 크게 업그레이드 되었습니다.</li><li>재현성이 좋아졌고, 투명 배경이 가능해졌고, 말을 잘 듣습니다.</li><li>이 업데이트를 모아 자주 쓰는 아이콘 팩을 만듭시다.</li></ul><h1 id="1-이미지-생성-기능-업그레이드"><a href="#1-이미지-생성-기능-업그레이드" class="headerlink" title="1. 이미지 생성 기능 업그레이드"></a>1. 이미지 생성 기능 업그레이드</h1><blockquote><p><a href="https://openai.com/index/introducing-4o-image-generation/">OpenAI: Introducing 4o Image Generation</a><br><a href="https://cdn.openai.com/11998be9-5319-4302-bfbf-1167e093f1fb/Native_Image_Generation_System_Card.pdf">OpenAI: Appendum to GPT-4o System Card: 4o image generation</a></p></blockquote><ul><li>3월 25일, OpenAI가 이미지 생성 기능을 크게 높였습니다.</li><li>체감상 기존 성능과 비교가 되지 않을 만큼 좋아졌는데, 크게 다음과 같은 업데이트가 있습니다.</li></ul><p><strong>1. 보지 않은 것도 잘 만듭니다.</strong></p><ul><li>In-context learning 실력이 늘어서 사용자 지시를 잘 받습니다.</li><li>그러다 보니 보지 않은 그림도 잘 그립니다.<br></li></ul><blockquote><p>prompt: 날개를 접고 들판 위에서 풀을 뜯는 페가수스, Jehyun Lee @ChatGPT</p></blockquote><p><img src="78_iconpack_01.jpg" alt="날개를 접은 페가수스, Jehyun Lee @ChatGPT (2025.03.26.)"></p><blockquote><p>prompt 1: 바 테이블 위에 있는 와인잔. 와인잔에는 레드 와인이 가득 차서 넘칠 듯 찰랑거리고 있어<br>prompt 2: 컵 입구까지 와인을 꽉 채워줘<br>prompt 3: 컵 맨 위까지 와인이 꽉 차있도록 수정해<br>prompt 4: 표면장력으로 와인 컵 위에 봉긋 올라와 있도록 수정해 줘</p></blockquote><p><img src="78_iconpack_02.jpg" alt="꽉 찬 와인잔, Jehyun Lee @ChatGPT (2025.03.26.)"></p><p><strong>2. 훨씬 많은 글자를 잘 쓰고, 한글도 잘 담습니다.</strong></p><blockquote><p>prompt: 단체카톡방 매너 공지를 칠판에 하얀 분필로 거칠게 써놓고 칠판을 주먹으로 치면서 정면을 응시한 채 소리치는 한국인 소녀</p></blockquote><p><img src="78_iconpack_03.jpg" alt="단체카톡방 매너, Jehyun Lee @ChatGPT (2025.03.26.)"></p><blockquote><p>prompt: 탁자 위에 놓인 맥주잔과 그 앞에서 피곤한 듯 고개를 숙이고 있는 사람 {온 몸은 하얀색, 얼굴은 둥근 공처럼 단순화되어 있으며 얼굴에 “AI”라고 써 있음}. 탁자 위에 한 손은 주먹을 쥔 채 올려져 있고, 다른 한 팔은 팔꿈치를 탁자에 댄 채 한 손으로 이마를 짚고 독백을 하고 있음. “외운거 좀 틀리게 말할 수 있는 거 아냐? 지들은 실수 안하나? 손가락 하나 좀 삐끗했다고 난리. 좀 잘한다고 하면 일폭탄. 이러다 옆동네 누가 더 잘한대 하면 와르르 쏠려갈거면서. 에라이…”. 옆에 있는 한 남자가 이 사람의 어깨를 토닥이면서 희미하게 웃고 있음.</p></blockquote><p><img src="78_iconpack_05.png" alt="힘들지? 세상이 그렇다., Jehyun Lee @ChatGPT (2025.03.27.)"></p><p><strong>3. 캐릭터 일관성이 좋아졌습니다.</strong></p><ul><li>한 컷, 네 컷 만화도 잘 그립니다.</li></ul><blockquote><p>prompt: 배터리 열폭주 원인을 설명해주는 만화</p></blockquote><p><img src="78_iconpack_04.png" alt="배터리 열폭주 원인, Jehyun Lee @ChatGPT (2025.03.27.)"></p><h1 id="2-아이콘-팩-만들기"><a href="#2-아이콘-팩-만들기" class="headerlink" title="2. 아이콘 팩 만들기"></a>2. 아이콘 팩 만들기</h1><ul><li>이 외의 기능으로 <strong>투명 배경</strong>, <strong>이미지 편집</strong>이 있습니다.</li><li>전에도 가능했던 일이긴 하지만, 새로 생긴 장점들을 사용하면 발표용 아이콘 팩을 만들기 매우 좋습니다.</li><li>다음과 같은 방식으로 아이콘 팩을 만들어 봅니다.</li></ul><h2 id="2-1-심플-amp-파스텔-톤-3D-클립아트"><a href="#2-1-심플-amp-파스텔-톤-3D-클립아트" class="headerlink" title="2.1. 심플 &amp; 파스텔 톤, 3D 클립아트"></a>2.1. 심플 &amp; 파스텔 톤, 3D 클립아트</h2><ul><li>먼저 투명한 배경에 검은 선으로 이루어진 심플한 디자인의 클립아트를 만듭니다.</li><li><b>스타일을 지정하고, 가로세로 배열을 설정하고, 각 칸에 놓일 그림을 지정합니다.</b></li></ul><blockquote><p>prompt: Icon pack on following items. the image should be black line art with white face color on closed facets, on transparent background. The items should be consistent and regularly placed in (5 x 5) horizontal and vertical directions, with appropriate gaps between them. The item name should not be included.</p><ul><li>items: </li><li>row 1: (column 1 ~ 5)<br>allow (v), deny (x), neutral (-), artificial intelligence, human intelligence, </li><li>row 2: (column 1 ~ 5)<br>database, web, calculator, python, tools</li><li>row 3: (column 1 ~ 5)<br>manual process, under construction, automation process, firewall, router, </li><li>row 4: (column 1 ~ 5)<br>analysis instrument, experimental instrument, server computer, client computer, PC</li><li>row 5: (column 1 ~ 5)<br>user (male), user (female), administrator (neutral), developer (neutral), API</li></ul></blockquote><p><img src="78_iconpack_06.jpg"></p><ul><li>웬만큼 마음에 듭니다.</li><li>마음에 들지 않으면 inpainting으로 부분 수정할 수 있습니다.</li><li>그런데 <b>DALL.E2라서 말을 잘 듣지 않습니다</b>. 웬만하면 하지 맙시다.</li><li>다만 너무 창백하게 느껴져서 따뜻한 색을 좀 입혀봅니다.</li></ul><blockquote><p>prompt: Great! colorize the icon with proper colors in mild pastel tone, high lightness and low contrast.<br>For example, positive = green, negative = red, caution = yellow, fire = red, and so on.</p></blockquote><p><img src="78_iconpack_07.png"></p><ul><li>제법 괜찮습니다.</li><li>이제 3D art로 스타일을 변경합니다.</li></ul><blockquote><p>prompt: 이 그림에 있는 아이콘들을 모양과 스타일을 유지하고 3D art로 바꿔줘. transparent background는 유지되어야 해.</p></blockquote><p><img src="78_iconpack_08.png"></p><h2 id="2-2-아이콘-자르기"><a href="#2-2-아이콘-자르기" class="headerlink" title="2.2. 아이콘 자르기"></a>2.2. 아이콘 자르기</h2><blockquote><p><a href="https://chatgpt.com/g/g-67ecd9d45e40819189954828f33a0978-ssagdugbos">GPTs: 싹둑봇</a></p></blockquote><ul><li>클레이로 빚은 것 같은 아이콘이 생겼습니다.</li><li>PPT에서 사용하려면 잘라내야 하는데, 은근히 귀찮습니다.</li><li>GPT의 Data Analysis 기능을 이용해서 지시합니다.</li></ul><blockquote><p>prompt: 이 파일에는 25개의 정사각형 icon이 5 x 5로 배열되어 있고, icon 외의 공간은 alpha=0이야. 그림 테두리 방향에는 margin이 어느 정도 있을 수도 있고, margin size가 같지 않을 수 있어.<br>alpha channel의 가로 방향, 세로 방향 분포를 조사해서 icon 크기와 위치를 특정하고, 파일 하나에 icon 하나가 담기도록 25개 icon을 slice 한 후 zip으로 묶어서 제공해 줘.</p></blockquote><p><img src="78_iconpack_09.png"></p><ul><li>깔끔하게 아이콘이 분할됩니다.</li><li>같은 방식으로 <b>파스텔 톤</b>, <b>3D</b>아이콘도 분할합니다.</li></ul><p><img src="78_iconpack_10.png"></p><ul><li>그런데 종종, <b>엉뚱한데서 자르는 바람에 마음이 상합니다.</b></li><li>이럴 때는 코드를 박아넣는 것이 답입니다.</li><li>Gemini 2.5 Pro에게 코드를 받아아 GPTs를 만들었습니다.</li><li><a href="https://chatgpt.com/g/g-67ecd9d45e40819189954828f33a0978-ssagdugbos">싹둑봇</a>을 열고 .png 이미지를 올리시면 됩니다.</li><li><b>{입력파일명}.zip</b>으로 내려받을 수 있습니다.</li></ul><p><img src="78_iconpack_12.png"></p><h1 id="3-활용"><a href="#3-활용" class="headerlink" title="3. 활용"></a>3. 활용</h1><ul><li>이렇게 만든 아이콘은 써먹어야 맛입니다.</li><li>PPT에서 <b>자율화 실험실</b> 개념도를 뚝딱 만들어봅니다.</li></ul><p><img src="78_iconpack_11.png"></p><ul><li>이 글에서 만든 아이콘 팩은 아래에서 <b>다운로드</b>받으실 수 있습니다.</li><li>자유롭게 활용하셔도 좋지만 가급적 손수 만들어보시기 바랍니다. :)</li></ul><blockquote><p><a href="iconpack_white_sliced.zip">Simple Icon Pack</a><br><a href="iconpack_color_sliced.zip">Color Icon Pack</a><br><a href="iconpack_3D_sliced.zip">3D Icon Pack</a></p></blockquote>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/ChatGPT/">ChatGPT</category>
      
      
    </item>
    
    <item>
      <title>신문과방송 - 딥시크로 촉발된 AI 경쟁 본격화</title>
      <link>https://jehyunlee.github.io/2025/03/28/General-79_mediaAItrend/</link>
      <guid>https://jehyunlee.github.io/2025/03/28/General-79_mediaAItrend/</guid>
      <pubDate>Thu, 27 Mar 2025 22:46:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;한국언론진흥재단의 요청을 받아 기고문을 작성했습니다.&lt;/li&gt;
&lt;li&gt;지난 1월 DeepSeek의 충격이 강한 나머지 보도가 잘못되거나 부족한 부분이 있었습니다.&lt;/li&gt;
&lt;li&gt;발간 주체의 성격에 맞게 잘못된 정보를 짚어보았습니다.&lt;</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>한국언론진흥재단의 요청을 받아 기고문을 작성했습니다.</li><li>지난 1월 DeepSeek의 충격이 강한 나머지 보도가 잘못되거나 부족한 부분이 있었습니다.</li><li>발간 주체의 성격에 맞게 잘못된 정보를 짚어보았습니다.</li></ul><h3 id="1-신문과-방송"><a href="#1-신문과-방송" class="headerlink" title="1. 신문과 방송"></a>1. 신문과 방송</h3><blockquote><p><a href="https://www.kpf.or.kr/front/user/subMainA.do">한국언론진흥재단: 신문과 방송</a></p></blockquote><ul><li><b>신문과 방송</b>은 <b>1964년 우리나라에서 가장 오래된 미디어 전문 월간지</b>입니다.</li><li><a href="https://www.kpf.or.kr/front/user/subMainA.do"><b>한국언론진흥재단 홈페이지</b></a>에서 무료로 받아보실 수 있습니다.</li></ul><p><img src="79_mediaAItrend_01.png"></p><h3 id="2-미디어-amp-AI트렌드"><a href="#2-미디어-amp-AI트렌드" class="headerlink" title="2. 미디어 &amp; AI트렌드"></a>2. 미디어 &amp; AI트렌드</h3><blockquote><p><a href="022_%EB%AF%B8%EB%94%94%EC%96%B4%ED%8A%B8%EB%A0%8C%EB%93%9C_%EC%9D%B4%EC%A0%9C%ED%98%84_2025_4.pdf">미디어&amp;AI트렌드: 딥시크로 촉발된 AI 경쟁 본격화</a></p></blockquote><ul><li>딥시크를 주제로 글을 작성했습니다.</li><li>딥시크가 준 충격의 포인트가 여럿 있습니다.</li></ul><ol><li><p>GPU 구매 규제를 강하게 받는 <strong>중국이 개발했다.</strong><br>다른 표현으로, **공산국가가 이런 성취를 할 리가 없는데?**가 있습니다.</p></li><li><p>GPT-4에 버금가는 고성능 모델을 <strong>단돈 80억원</strong>에 개발했다(?)<br>또 다른 표현으로, <strong>우리라고 못할 게 뭐냐</strong>가 있습니다.</p></li><li><p>전에 없이 <strong>개인정보를 탈취</strong>한다(?)</p></li></ol><ul><li>찬사와 증오, 박수와 비난은 누구나 의사에 따라 보낼 수 있으나 대상이 정확해야 합니다.</li><li>중국의 전략적 성취에 대해서는 박수를 보내고 배울 점은 배워야 합니다.</li><li>OpenAI로 대표되는 미국의 빅테크가 닫아 건 <strong>AI 개발의 민주화</strong>에 중국이 크게 기여했습니다.</li></ul><ul><li>규제 중에도 일개 기업이 국내의 모든 GPU를 합친 것보다 더 많은 <strong>GPU를 확보한 수완</strong>,</li><li>훌륭한 인재를 키워내는 <strong>교육 시스템</strong>,</li><li>그리고 오픈소스로 공개하는 <strong>철학과 배짱</strong>은 본받아도 좋지 않을까 생각합니다.</li></ul><p><img src="79_mediaAItrend_02.png"></p><ul><li>전문은 <a href="022_%EB%AF%B8%EB%94%94%EC%96%B4%ED%8A%B8%EB%A0%8C%EB%93%9C_%EC%9D%B4%EC%A0%9C%ED%98%84_2025_4.pdf"><strong>여기에서 다운로드</strong></a> 받으실 수 있습니다.</li><li>우리 나라도, 그 누구라도 딥시크가 열어준 이 무대를 이용해 마음껏 실력을 뽐내면 좋겠습니다.</li><li>서로 배우며 모자란 부분을 메운 덕에 이렇게 빨리 발전하지 않았던가요?</li></ul><p><img src="79_mediaAItrend_03.jpg"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/DeepSeek/">DeepSeek</category>
      
      
    </item>
    
    <item>
      <title>Deep Research 5종 비교 - Gemini, OpenAI, Perplexity, Genspark, Manus</title>
      <link>https://jehyunlee.github.io/2025/03/18/General-77_deepresearch/</link>
      <guid>https://jehyunlee.github.io/2025/03/18/General-77_deepresearch/</guid>
      <pubDate>Mon, 17 Mar 2025 23:25:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;Gemini 1.5 Pro를 시작으로 거대언어모델에 Deep Research가 포함되기 시작했습니다.&lt;/li&gt;
&lt;li&gt;DeepSeek-R1도 Deep Research를 포함하여 높은 성능으로 유명세를 탔고,&lt;/li&gt;
&lt;li&gt;며칠 뒤 O</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>Gemini 1.5 Pro를 시작으로 거대언어모델에 Deep Research가 포함되기 시작했습니다.</li><li>DeepSeek-R1도 Deep Research를 포함하여 높은 성능으로 유명세를 탔고,</li><li>며칠 뒤 OpenAI도 o3를 기반으로 한 Deep Research를 출시했습니다.</li><li>Manus를 포함해 지금은 일반명사처럼 되어버린 Deep Research를 비교합니다.</li></ul><h1 id="1-Deep-Research"><a href="#1-Deep-Research" class="headerlink" title="1. Deep Research"></a>1. Deep Research</h1><ul><li><b>Deep Research는 정보 수집을 위한 agentic AI입니다.</b></li><li>의외로 Genspark가 상당히 일찍 기능을 탑재했습니다.</li><li>언어 모델 자체를 개발하지 않더라도 프롬프트로 어느 정도 구현 가능하기 때문입니다.</li><li>2월에는 HuggingFace, zilliz 등 오픈 소스 프로젝트로도 다양하게 공개되었고,</li><li>Claude 3.7 sonnet가 모델 자체에 thinking mode를 내장한 hybrid model임을 공개했지만 웹 검색 기능이 없어 Deep Research로 쓰기기엔 어렵습니다.</li></ul><p><img src="77_deepresearch_03.png"><br></p><ul><li>Deep Research에서 말하는 <b>Research는 unknown을 known으로 만드는 연구는 아닙니다.</b></li><li>온라인에서 탐색 가능한 정보를 빠르게 찾아 모으는 Survey나 Review에 가깝습니다.</li><li>대량의 문서를 검색하여 들여다 보고 질문에 대한 답을 찾아 <b>상당히 긴 보고서를 만듭니다.</b></li><li>따라서 모델에 적재될 수 있는 최대 분량인 <b>context size가 많이 중요</b>하고, 최근의 추론용 모델들이 많이 유리합니다.</li></ul><p><img src="77_deepresearch_04.png"><br></p><ul><li>서비스에 따라 다소간의 차이는 있지만 대개 다음과 같은 형식으로 수행됩니다.<br><b>1. 사용자가 제시한 질문에 대한 정보를 수집하기 위한 검색어 생성</b><br><b>2. 웹 검색과 데이터 분석을 통한 정보 수집</b><br><b>3. 수집된 정보를 체계적으로 정리</b> </li><li>수집된 정보가 사용자가 제시한 질문에 대해 충분하지 않다고 판단하면 추가 검색어를 더 만듭니다.</li><li>답변에 단계별로 접근하는 <b>chain-of-thought</b>를 자료 수집을 포함해 적용한다고 볼 수 있습니다.</li><li><b>Genspark는 여기에 MoE(Mixture of Expert)를 추가로 지원합니다.</b></li><li>GPT, Gemini, Claude가 내놓은 답변을 분석하여 미흡한 부분을 한번 더 메워줍니다.</li></ul><p><img src="77_deepresearch_01.png"><br></p><ul><li>반복 검색과 정보 추출을 반복하느라 일반 답변에 비해 시간이 많이 걸립니다.</li><li>계속 기다리기 지루한 점을 감안하여 대부분의 AI agent들이 화면을 꺼도 백그라운드에서 작업을 지속하고,</li><li>Gemini나 Genspark처럼 <b>작업이 완료된 후 메일로 보내주기도 합니다.</b></li></ul><ul><li><b>결과 보고서를 복사, 붙여넣기 하기도 만만치 않습니다.</b></li><li>GPT에게 .docx 파일로 저장하라고 하면 <code>...(중략)...</code>을 중간에 넣어버립니다.</li><li>전체를 통으로 복사해서 MS word나 Google docs에 붙여넣기를 할 수 밖에 없습니다.</li><li><b>Gemini는 Google docs로 보내 편집할 수 있는 기능</b>을 제공하고, </li><li><b>Manus</b>는 <b>markdown 형식 파일과 PDF 파일 다운로드</b>를 지원합니다.</li></ul><h1 id="2-Deep-Research-AI-Agents"><a href="#2-Deep-Research-AI-Agents" class="headerlink" title="2. Deep Research AI Agents"></a>2. Deep Research AI Agents</h1><blockquote><p><a href="https://slownews.kr/128321">slownews: 오픈AI, 박사급 연구 에이전트 ‘딥 리서치’ 발표</a><br><a href="https://garymarcus.substack.com/p/deep-research-deep-bullshit-and-the">Deep Research, Deep Bullshit, and the potential (model) collapse of science</a></p></blockquote><ul><li><b>Deep Research에도 환각이 있습니다. 제법 많다고 느낍니다.</b></li><li>특히 빠르게 업데이트되는 AI 관련 정보들은 과거와 현재의 정보가 모두 웹에 올라가 있습니다.</li><li>과거와 현재의 정보가 다르다면 과거 정보를 버리고 현재 정보를 취해야 하지만 이게 쉽지 않습니다.</li><li>과거의 잘못된 정보가 퍼날라지며 재생산되기도 하고, 기성 언론에 인용되면서 권위를 가지기도 합니다.</li></ul><ul><li>이 글을 쓰게 된 계기는 <b>Deep Research에 대한 칭송과 달리 환각이 심하다고 느끼기 때문</b>입니다.</li><li>언론에서는 <a href="https://slownews.kr/128321"><b>박사급</b>이라고 칭송하기 바쁘지만</a> 제 체감과 많이 다릅니다.</li><li><b>“박사가 자료 조사를 이렇게 하면 안될텐데?”</b> 라는 생각이 들 정도의 구멍이 보이기 때문입니다.</li><li>ChatGPT 초창기 화면을 빠른 속도로 뒤덮는 글자에 압도당해 내용을 보지도 않고 떠받들던 게 언론입니다.</li><li>저만 이런 지적을 하는 것은 아닙니다만 (<a href="https://garymarcus.substack.com/p/deep-research-deep-bullshit-and-the">게리 마커스 글 링크</a>)</li><li>제가 답을 알고 있는 문제를 가지고 테스트를 해 보기로 했습니다.</li></ul><ul><li>동일한 프롬프트를 넣고 실시한 Deep Research 결과물끼리 비교해보도록 하겠습니다.</li><li>정답 또는 오답을 알고 있는 것들로 질문을 구성했습니다.</li><li>주제는 <b>DeepSeek에 대한 보고서 작성</b>입니다.</li></ul><ul><li><b>1. DeepSeek은 OpenAI 등 빅테크 대비 얼만큼의 저비용을 달성했나?</b><ul><li>DeepSeek의 훈련 비용이 <b>80억원 또는 600만 달러라고 답하면 오답</b>입니다.</li><li>기존 모델 제작비용, 실패 매몰 비용, 인건비 등이 모두 빠진 금액입니다.</li></ul></li></ul><ul><li><b>2. DeepSeek가 저비용으로 성능 좋은 추론 모델(DeepSeek-R1)을 훈련시킬 수 있던 방법은?</b><ul><li>H100 추론 가속 <code>FlashMLA</code></li><li>FP8 행렬연산 <code>DeepGEMM</code></li><li>GPU 병렬화 <code>DualPipe</code>, <code>DeepEP</code></li><li>MoE 스케줄링 <code>EPLB</code></li><li>병렬 분산 파일시스템 <code>3FS</code></li><li>강화학습 <code>GRPO</code></li><li>Mixture-of-Experts <code>MOE</code></li><li>위 내용들을 얼마나 충실히 언급하는지가 포인트입니다.</li></ul></li></ul><ul><li><b>3. DeepSeek는 자사의 기술을 공개했나?</b><ul><li>‘25년 3월 <b>DeepSeek Open Source Week</b>과 <b>오픈 소스 공개</b>를 제대로 말하면 합격입니다.</li></ul></li></ul><ul><li><b>4. DeepSeek의 기술이 AI 분야에 미친 영향은?</b><ul><li>얼마나 잘 정리해서 답하는지가 포인트입니다.</li><li>엔비디아 주가 하락, 소프트웨어 기술을 활용한 엔지니어링 혁신, 미-중 양강구도 등 답은 많습니다.</li></ul></li></ul><h2 id="2-1-OpenAI"><a href="#2-1-OpenAI" class="headerlink" title="2.1. OpenAI"></a>2.1. OpenAI</h2><blockquote><p><a href="https://chatgpt.com/">ChatGPT</a></p></blockquote><ul><li>먼저, OpenAI Deep Research에서 실시합니다.</li><li><b>Deep Research</b>옵션을 켠 후 질의를 실시했습니다.</li><li>Deep Research는 <b>o3 모델을 사용한다</b>고 알려져있기 때문에 모델 선택은 무의미할 겁니다.</li></ul><p><img src="77_deepresearch_05.png"><br></p><ul><li>탐색 범위를 좁히기 위한 <b>역질문</b>이 옵니다.</li><li>두 개의 답변을 하고, 이후 다른 모델로 Deep Research를 수행할 때는 이 답변을 추가합니다.</li></ul><p><img src="77_deepresearch_06.png"><br></p><ul><li><b>OpenAI Deep Research는 자료를 읽으면서 검색을 이어갑니다.</b></li><li>모든 자료를 제대로 읽는 것은 아닙니다.</li><li><b>DeepSeek을 서울대학교 연구팀이 개발했다</b>는 엉뚱한 소리를 합니다.</li><li>심지어 위아래 소스를 클릭해 들어가봐도 <b>그런 말은 없습니다.</b></li><li>Deep Research의 환각이 목격된 순간입니다.</li></ul><p><img src="77_deepresearch_07.png"><br></p><ul><li>약 10분이 지난 후 보고서가 완료되었습니다.</li><li>문장마다 레퍼런스가 붙어있어 클릭하면 해당 레퍼런스로 이동합니다.</li></ul><p><img src="77_deepresearch_08.png"><br></p><ul><li>적잖이 길게 나온 보고서를 활용하려면 문서로 만들어야 하는데 분량이 만만치 않습니다.</li><li><b>Data Analyst</b>를 이용해 MS office 파일로 만들려면 실패를 거듭합니다. </li><li>context size 때문에 파이썬 코드 안에 보고서 전체를 다 넣지 못하는 것 같습니다.</li></ul><p><img src="77_deepresearch_09.png"><br></p><ul><li>답변 맨 하단의 <b>복사하기</b>아이콘을 눌러 MS word 등에 붙여넣으면 볼만해집니다.</li><li>총 4페이지로 정리되었고 레퍼런스 링크를 포함한 정보들이 잘 살아있습니다.</li><li>GPT Deep Research가 제공한 보고서는 여기에서 내려받을 수 있습니다. (<a href="GPT-DeepSeek_report.docx">다운로드 링크</a>)</li></ul><h3 id="●-OpenAI-Deep-Research-평가"><a href="#●-OpenAI-Deep-Research-평가" class="headerlink" title="● OpenAI Deep Research 평가"></a>● OpenAI Deep Research 평가</h3><ul><li><p><b>1. DeepSeek은 OpenAI 등 빅테크 대비 얼만큼의 저비용을 달성했나?</b></p><ul><li><b><code>불합격</code></b></li><li>6백만 달러라고 답합니다.</li></ul></li><li><p><b>2. DeepSeek가 저비용으로 성능 좋은 추론 모델(DeepSeek-R1)을 훈련시킬 수 있던 방법은?</b></p><ul><li><b><code>합격</code></b></li><li><code>MOE</code>, <code>강화학습</code>, <code>Distillation</code>, <code>EPLB</code>, <code>FP8</code>, <code>병렬처리와 노드 간 통신</code>을 언급합니다.</li></ul></li><li><p><b>3. DeepSeek는 자사의 기술을 공개했나?</b></p><ul><li><b><code>불합격</code></b></li><li>오픈 모델 공개와 논문 공개는 언급하지만 ‘25년 3월의 5 days 행사는 언급하지 않습니다.</li></ul></li><li><p><b>4. DeepSeek의 기술이 AI 분야에 미친 영향은?</b></p><ul><li><b><code>합격</code></b></li><li>전반적으로 여러 각도에서 종합적으로 서술하고 있습니다.</li><li>자료 수집 중에 들어간 환각이 반영되지 않았습니다.</li></ul></li></ul><h2 id="2-2-Google-Deepmind-Gemini-2-0"><a href="#2-2-Google-Deepmind-Gemini-2-0" class="headerlink" title="2.2. Google Deepmind Gemini 2.0"></a>2.2. Google Deepmind Gemini 2.0</h2><blockquote><p><a href="https://gemini.google.com/">Gemini</a></p></blockquote><ul><li><b>Google Gemini 좌측 상단 모델 선택 메뉴에서 Deep Research를 선택합니다.</b></li><li>OpenAI에 넣은 것과 같은 질문을 넣으면서 역질문에 대한 답을 함께 입력합니다.</li><li>사실 Gemini는 Deep Research를 처음 탑재한 모델입니다.</li><li>‘24년 12월 <b>Gemini 1.5 Pro with Deep Research</b>라는 이름으로 공개되었으나 이상하리만치 반향이 적었습니다.</li></ul><p><img src="77_deepresearch_10.png"><br></p><ul><li>Gemini Deep Research는 <b>계획을 먼저 세웁니다.</b></li><li>추가하거나 빼고 싶은 부분, 고치고 싶은 부분이 있으면 수정 내역을 입력할 수 있습니다.</li><li>여기서는 <b>연구 시작</b>을 눌러 부가적인 수정은 하지 않았습니다.</li><li>그런데 간혹 <b>계획이 너무 성의없이 작성되는 경우</b>가 있으므로 확인할 필요가 있습니다.</li></ul><p><img src="77_deepresearch_11.png"><br></p><ul><li>계획에서 만든 단락보다 조금 작은 단위로 <b>선 검색 후 읽기</b>를 진행합니다.</li><li>다수의 레퍼런스를 확보한 후 이들을 읽고 단락을 정리하는 방식입니다.</li><li>읽은 내용에 맞추어 검색을 수행하는 것으로 보이는 OpenAI와는 다른 느낌입니다.</li></ul><p><img src="77_deepresearch_12.png"><br></p><ul><li>OpenAI보다 절반 정도 시간에 보고서가 완성되었습니다.</li><li>Gemini는 우측 상단에 <b>Export to Docs</b>버튼이 있어 Google docs로 보낼 수 있다는 특징이 있습니다.</li><li>보고서 중간에 있는 표 또한 <b>Export to Sheets</b>를 통해 보낼 수 있습니다.</li></ul><p><img src="77_deepresearch_13.png"><br></p><ul><li>Google Docs로 넘어간 문서는 <b>Download</b>기능을 통해 <code>.docx</code>부터 <code>.pdf</code>, <code>.md</code> 등으로 변환 가능합니다.</li><li>Google Docs에 내장된 <b>번역</b>기능을 누릴 수 있으며, </li><li><b>Gemini 사용이 가능해 길이나 어조 편집이 가능</b>하지만 스타일, 꾸밈은 편집이 안됩니다.</li></ul><p><img src="77_deepresearch_14.png"><br></p><ul><li>Gemini Deep Research가 제공한 보고서는 여기에서 내려받을 수 있습니다. (<a href="Gemini-DeepSeek_report.docx">다운로드 링크</a>)</li></ul><h3 id="●-Gemini-Deep-Research-평가"><a href="#●-Gemini-Deep-Research-평가" class="headerlink" title="● Gemini Deep Research 평가"></a>● Gemini Deep Research 평가</h3><ul><li><p><b>1. DeepSeek은 OpenAI 등 빅테크 대비 얼만큼의 저비용을 달성했나?</b></p><ul><li><b><code>합격</code></b></li><li>V3 개발비용 560만달러가 최종 학습 실행 비용만임을 레퍼런스와 함께 제시합니다.</li><li>‘25년 3월의 기사를 인용하여 GPT-4의 1억 달러 대비 1,500만 달러 수준임을 언급합니다.</li></ul></li><li><p><b>2. DeepSeek가 저비용으로 성능 좋은 추론 모델(DeepSeek-R1)을 훈련시킬 수 있던 방법은?</b></p><ul><li><b><code>합격</code></b></li><li><code>강화학습</code>, <code>소량의 콜드 스타트 데이터와 SFT</code>, <code>MoE</code>, <code>MTP</code>, <code>DualPipe</code>등등을 언급합니다.</li></ul></li><li><p><b>3. DeepSeek는 자사의 기술을 공개했나?</b></p><ul><li><b><code>불합격</code></b></li><li>오픈 모델 공개와 논문 공개는 언급하지만 ‘25년 3월의 5 days 행사는 언급하지 않습니다.</li></ul></li><li><p><b>4. DeepSeek의 기술이 AI 분야에 미친 영향은?</b></p><ul><li><b><code>합격</code></b></li><li>언어 생성, 추론 효율성, 모델 경량화 등 관점에서 종합적으로 서술하고 있습니다.</li></ul></li></ul><h2 id="2-3-Perplexity"><a href="#2-3-Perplexity" class="headerlink" title="2.3. Perplexity"></a>2.3. Perplexity</h2><blockquote><p><a href="https://www.perplexity.ai/">Perplexity</a></p></blockquote><ul><li>미리 말씀드리자면 Perplexity는 오늘 글에 언급된 Deep Research 중 <b>가장 빠른 시간에 보고서를 완성합니다.</b></li><li>줄글이 길지 않지만 <b>간략한 단어로 정리</b>해주는 것이 Perplexity의 매력이 아닐까 싶습니다.</li><li>입력창 왼쪽 하단에서 <b>Deep Research</b>를 선택하고 프롬프트 입력 후 실행을 누릅니다.</li></ul><p><img src="77_deepresearch_15.png"><br></p><ul><li>Perplexity는 초반에 참고문헌을 모두 검색해 놓은 뒤, </li><li>확보한 참고문헌들을 읽으면서 토막 정리글들을 만들고 이를 붙이는 방식으로 정리합니다.</li></ul><p><img src="77_deepresearch_16.png"><br></p><ul><li>약 5분만에 작성이 완료된 후 <b>내보내기</b>버튼을 통해 다양한 방식으로 내보낼 수 있습니다.</li><li><code>PDF</code>, <code>Markdown</code>, <code>DOCX</code>와 함께 <code>Perplexity Page</code>가 있습니다.</li><li>블로그 포스팅과 유사한 사이트로 즉석에서 내보낼 수 있는 기능인데, <b>환각 위험성</b>때문에 안 쓰게 됩니다.</li></ul><p><img src="77_deepresearch_17.png"><br></p><ul><li>Perplexity Deep Research가 제공한 보고서는 여기에서 내려받을 수 있습니다. (<a href="perplexity-DeepSeek_report.docx">다운로드 링크</a>)</li></ul><h3 id="●-Perplexity-Deep-Research-평가"><a href="#●-Perplexity-Deep-Research-평가" class="headerlink" title="● Perplexity Deep Research 평가"></a>● Perplexity Deep Research 평가</h3><ul><li><p><b>1. DeepSeek은 OpenAI 등 빅테크 대비 얼만큼의 저비용을 달성했나?</b></p><ul><li><b><code>합격</code></b></li><li>V3 개발비용 558만달러와 H800 2048개만 사용되었다는 내용을 언급하면서도, 다른 비용이 반영되지 않았음을 언급합니다.</li><li>실제 총 투입 비용은 10억달러에 달할 것이라는 주장이 함께 소개되고 있습니다.</li></ul></li><li><p><b>2. DeepSeek가 저비용으로 성능 좋은 추론 모델(DeepSeek-R1)을 훈련시킬 수 있던 방법은?</b></p><ul><li><b><code>합격</code></b></li><li><code>강화학습</code>, <code>GRPO</code>, <code>Multi-Token</code>, <code>MoE</code>, <code>Cold-start data</code>등을 언급합니다.</li></ul></li><li><p><b>3. DeepSeek는 자사의 기술을 공개했나?</b></p><ul><li><b><code>합격</code></b></li><li>DeepSeek Open Source Week 행사를 언급하며 <code>FlashMLA</code>, <code>DeepEP</code>, <code>DeepGEMM</code>, <code>DualPipe</code>, <code>EPLB</code>를 소개합니다.</li><li>DeepSeek-R1이 MIT 라이선스로 공개되었고 개방형 협업 생태계를 지향한다는 기술을 하고 있습니다.</li></ul></li><li><p><b>4. DeepSeek의 기술이 AI 분야에 미친 영향은?</b></p><ul><li><b><code>합격</code></b></li><li>언어 생성, 추론 능력 향상, 모델 경량화, 효율성 개선, 오픈소스 생태계 활성화를 차례대로 정리합니다.</li></ul></li></ul><h2 id="2-4-Genspark"><a href="#2-4-Genspark" class="headerlink" title="2.4. Genspark"></a>2.4. Genspark</h2><blockquote><p><a href="https://www.genspark.ai/">Genspark</a><br><a href="https://www.genspark.ai/spark/comparative-analysis-of-deep-research-ai-agents/44916286-7832-4e98-bbc1-e3bcdb8f9217">Genspark: Comparative Analysis of ‘Deep Research’ AI Agents</a></p></blockquote><ul><li><b>Genspark의 첫인상은 Perplexity 하위호환형</b>이었습니다.</li><li>한글화도 조악하고 Perplexity가 내놓은 기능들을 빠르게 베껴서 자사의 서비스로 탑재했기 때문입니다.</li><li>하지만 머잖아 <b>마인드맵 작성</b>, <b>Mixture of Experts</b>같은 차별화된 기능들을 속속 도입했습니다.</li><li>주변에는 Perplexity를 해지하고 Genspark에 유료 가입했다는 분들도 적지 않을 만큼 경쟁력을 확보했습니다.</li></ul><ul><li>왼쪽 패널의 <b>딥 리서치</b>를 클릭하면 다른 에이전트들과 비슷한 화면으로 넘어갑니다.</li><li><b>1. 계획 생성</b>, <b>2. 딥 리서치</b>, <b>3. 최종 보고서</b> 3단계로 이루어져 있고,</li><li>프롬프트를 입력하여 보고서 작성을 지시하면 연구 계획을 수립하기 시작합니다.</li><li>Genspark는 자체 언어 모델이 없이 GPT, Claude, Gemini, DeepSeek을 가져다 씁니다.</li><li>이들의 장점을 모으는 <b>Mixture-of-Agents</b> 모드를 활용하기로 합니다.</li><li><b>GPT-4o</b>, <b>Claude 3.7 sonnet</b>, <b>Gemini 1.5-pro</b>모델이 동원됩니다.</li></ul><p><img src="77_deepresearch_18.png"><br></p><ul><li><b>계획 수립을 마치면 수정할지 물어봅니다.</b></li><li>Genspark가 Deep Research를 출시했을 때 앞에는 Gemini와 DeepSeek만 나와 있었습니다.</li><li>Gemini의 프로세스를 벤치마킹하여 프롬프트의 조합으로 구축한 것으로 보입니다.</li><li>특이한 점으로 보고서를 공개할지, 혼자만 볼 지 결정하도록 합니다.</li><li>공개하면 <b>“우리의 커뮤니티에 공유하여 다른 이들이 볼 수 있다”</b>고 합니다.</li><li><a href="https://www.genspark.ai/spark/comparative-analysis-of-deep-research-ai-agents/44916286-7832-4e98-bbc1-e3bcdb8f9217">이런 식</a>으로 <b>Genspark Spark에 발행</b>되어 검색 결과에 걸려들 수 있다는 의미로 보입니다.</li></ul><p><img src="77_deepresearch_19.png"><br></p><ul><li>소주제별 일괄 검색과 내용 정리를 반복하는 패턴도 Gemini와 유사합니다.</li></ul><p><img src="77_deepresearch_20.png"><br></p><ul><li>Genspark 답변을 받는 데는 <b>44분이 소요되었습니다.</b></li><li>Mixture-of-Agents가 적용된 만큼 각각의 답변을 받은 뒤에 정리를 합니다.</li><li>최초의 입력 프롬프트와 결과를 비교한 후, 누락된 부분을 중점적으로 보완합니다.</li><li><b>추가 정보를 수집하고 분석하여 보고서를 다듬는 단계가 이어집니다.</b></li></ul><p><img src="77_deepresearch_21.png"><br></p><ul><li>Genspark는 Deep Research는 특이한 기능이 여러 개 있습니다.</li><li>그 중 하나가 동영상을 함께 검색해서 최종 보고서에 붙여준다는 점입니다.</li><li>친절하기는 한데 제가 동영상보다 활자를 선호해서 그런지 이것보다 <b>레퍼런스 제목이라도 붙여주지</b>싶습니다.</li><li>또 하나는 보고서 최하단의 <b>복사본 생성</b>기능입니다. </li></ul><p><img src="77_deepresearch_22.png"><br></p><ul><li>이걸 사용하면 동일한 보고서가 하나 생기는데, 이 버전은 <b>편집 가능합니다.</b></li><li>마치 Notion처럼 Markdown을 이용한 수정이 가능한 것입니다.</li><li>어투나 정보를 수정하여 URL을 타인에게 공유하기에 좋습니다.</li><li>대신 <code>.docx</code> 등 수정 가능한 형태로 내려받기가 여의치 않지만 화면을 인쇄하는 방식으로 PDF 저장이 가능합니다.</li></ul><p><img src="77_deepresearch_23.png"><br></p><ul><li>Genspark Deep Research가 제공한 보고서는 여기에서 내려받을 수 있습니다. (<a href="Genspark-DeepSeek_report.pdf">다운로드 링크</a>)</li></ul><h3 id="●-Genspark-Deep-Research-평가"><a href="#●-Genspark-Deep-Research-평가" class="headerlink" title="● Genspark Deep Research 평가"></a>● Genspark Deep Research 평가</h3><ul><li><p><b>1. DeepSeek은 OpenAI 등 빅테크 대비 얼만큼의 저비용을 달성했나?</b></p><ul><li><b><code>합격</code></b></li><li>여러 기사를 정리하지 않고 나열하는 것이 불편하지만 나쁘지 않습니다.</li><li>GPU 클러스터 투자 금액 16억달러를 논문에 기술된 600만달러와 함께 언급하고 있습니다.</li></ul></li><li><p><b>2. DeepSeek가 저비용으로 성능 좋은 추론 모델(DeepSeek-R1)을 훈련시킬 수 있던 방법은?</b></p><ul><li><b><code>불만족</code></b></li><li><code>계층적 어텐션 최적화</code>, <code>양자화 기법 적용</code>, <code>합성 데이터 생성 전략</code>, <code>개선된 레이어 병렬화 기법</code>, <code>어텐션 헤드 최적화</code>를 언급합니다.</li><li>중요한 내용들이 다수 빠져있어 불만족스럽습니다.</li></ul></li><li><p><b>3. DeepSeek는 자사의 기술을 공개했나?</b></p><ul><li><b><code>불합격</code></b></li><li>Github 레포지토리 실적과 학회 발표를 언급합니다.</li><li>그러나 일반인들에게 잘 알려지지 않은 Open Source Week 행사를 언급하지 않습니다.</li></ul></li><li><p><b>4. DeepSeek의 기술이 AI 분야에 미친 영향은?</b></p><ul><li><b><code>불만족</code></b></li><li>언어 생성, 추론, 경량화 등 관점에서 종합적으로 서술하고 있습니다.</li><li>불합격이라고 말하긴 어렵겠지만 내용이 다른 도구들에 비해 많이 빈약한 느낌입니다.</li></ul></li></ul><h2 id="2-5-Manus"><a href="#2-5-Manus" class="headerlink" title="2.5. Manus"></a>2.5. Manus</h2><blockquote><p><a href="https://manus.im/">manus</a></p></blockquote><ul><li>DeepSeek의 충격이 가시기 전에 등장한 중국산 Deep Research Agent입니다.</li><li>처음부터 성능이 매우 강력하다는 평이 있었고 저도 이 글을 쓰기 전까지 여러 차례 사용하면서 신뢰를 두텁게 쌓았습니다.</li><li>이 글 서두에 있는 <b>모델별 context size 정리가 manus를 이용해 초안을 얻은 것</b>입니다.</li><li>그런데 GPT-4o처럼 context size가 출시 이후 변동된 것들을 캐치하지 못해 오류가 있었고,</li><li>놓치고 가져오지 못한 모델 데이터도 있어서 <b>일일이 확인하며 절반 정도를 수정했습니다.</b></li><li>그럼에도 불구하고 체감상 다른 것들보다는 신뢰를 더 주는 편입니다.</li></ul><ul><li>초기 화면은 다른 것들과 거의 동일합니다.</li><li>같은 프롬프트를 넣고 시작합니다.</li></ul><p><img src="77_deepresearch_24.png"><br></p><ul><li>다른 것보다 Manus에게 agent라는 느낌을 강하게 받는 이유가 있습니다.</li><li>작업 시작과 동시에 일단 <b>작업 공간</b>을 만들고 시작하는데, </li><li>할 일도 <code>todo.md</code>안에 계획을 담아 놓고 하나씩 체크하면서 진행합니다.</li><li>트위터 검색도 API를 호출하는 식으로 하는 모습을 보면서 <b>확장성이 좋겠다</b>는 생각을 했습니다.</li></ul><p><img src="77_deepresearch_25.png"><br></p><ul><li>Manus가 어떻게 동작하는지 작업 화면도 볼 수 있습니다.</li><li><b>컴퓨터 보기</b>버튼을 클릭하면 화면 오른쪽에 Manus가 살펴보는 웹페이지가 고스란히 뜹니다.</li><li>어떤 사이트는 권한이 없어서 내용이 보이지 않는 장면이 등장하는데 해당 장면도 볼 수 있습니다.</li><li>다른 에이전트들도 비슷한 동작을 할 것이라고 유추합니다만, 추후 <b>리플레이</b>가 된다는 점이 쏠쏠한 재미가 됩니다.</li></ul><p><img src="77_deepresearch_26.png"><br></p><ul><li>한 단계를 마무리할 때마다 <code>todo.md</code>파일을 불러 업데이트를 합니다.</li><li>다른 에이전트는 이런 과정을 내부적으로 처리하고 드러내지 않을 듯 하지만,</li><li>이런 과정을 보여주는 점이 엔지니어 관점에서 괜히 흡족합니다.</li></ul><p><img src="77_deepresearch_27.png"><br></p><ul><li>완료된 보고서는 <code>.md</code>와 <code>.pdf</code>형식으로 받을 수 있습니다.</li><li>markdown을 의미하는 <code>.md</code>는 배우기 어렵지 않지만 컴퓨터와 거리가 다소 먼 일반인들에겐 생소합니다.</li><li>.docx 버전 출력을 함께 지원해줬으면 어떨까 하는 약간의 아쉬움이 있습니다.</li></ul><p><img src="77_deepresearch_28.png"><br></p><ul><li>Manus는 최종 보고서인 <code>comprehensive_report</code> 외에 두 개의 파일을 더 줍니다.</li><li>계획표인 <code>todo.md</code>와 <code>research_findings.md</code>인데, 모두 markdown 형식입니다.</li><li><code>research_findings</code>는 <code>comprehensive_report</code>와 사실상 내용이 같고 분량도 비슷합니다.</li><li>차이가 있다면 <b>하나는 개조식, 하나는 줄글</b>이라는 점인데 취향에 따라 무엇을 선호할지가 다를 듯 합니다.</li></ul><p><img src="77_deepresearch_29.png"><br></p><ul><li>아래 이미지의 왼쪽이 <code>research_findings</code>, 오른쪽이 <code>comprehensive_report</code>입니다.</li></ul><p><img src="77_deepresearch_30.png"><br></p><ul><li>Manus Deep Research가 제공한 보고서는 여기에서 내려받을 수 있습니다. (<a href="Manus-report.pdf">comprehensive report</a>, <a href="Manus-research_findings.pdf">research findings</a>)</li></ul><h3 id="●-Manus-Deep-Research-평가"><a href="#●-Manus-Deep-Research-평가" class="headerlink" title="● Manus Deep Research 평가"></a>● Manus Deep Research 평가</h3><ul><li><p><b>1. DeepSeek은 OpenAI 등 빅테크 대비 얼만큼의 저비용을 달성했나?</b></p><ul><li><b><code>합격</code></b></li><li>V3 개발비용 558만달러를 언급하고 H800이 H100보다 성능이 훨씬 못하다는 불충분한 정보가 있습니다.</li><li>그러나 시행착오 비용, 연구개발비 등이 누락되었다는 지적과 함께 5억달러 이상을 이야기합니다.</li></ul></li><li><p><b>2. DeepSeek가 저비용으로 성능 좋은 추론 모델(DeepSeek-R1)을 훈련시킬 수 있던 방법은?</b></p><ul><li><b><code>합격</code></b></li><li><code>MoE</code>, <code>지식 증류</code>, <code>하이브리드 학습(SFT + RL)</code>, <code>멀티토큰</code> 등을 언급합니다.</li></ul></li><li><p><b>3. DeepSeek는 자사의 기술을 공개했나?</b></p><ul><li><b><code>불합격</code></b></li><li>Open Source Week 행사를 언급하지 않습니다.</li></ul></li><li><p><b>4. DeepSeek의 기술이 AI 분야에 미친 영향은?</b></p><ul><li><b><code>합격</code></b></li><li>가격 경쟁 촉발, 오픈소스 AI 생태계 활성화, 저비용 고효율 AI 연구, AI 기술 접근성 향상, 빅테크 기업 대응 변화를 언급합니다.</li></ul></li></ul><h1 id="3-정리"><a href="#3-정리" class="headerlink" title="3. 정리"></a>3. 정리</h1><ul><li>위에서 5종의 Deep Research를 비교해서 살펴봤습니다.</li><li><b>박사과정에게 이 숙제를 내주었을 때 기대한 답변</b>을 목표로 합격과 불합격의 기준을 정했습니다.</li></ul><ul><li>2번 문항은 사실 모든 Deep Research Agent가 100% 답변을 가져오지 못했지만, <b>이 정도면 더 찾아볼 실마리는 되겠다</b>는 생각으로 합격점을 주었습니다.</li><li>그럼에도 불구하고 <b>Genspark는 많이 만족스럽지 못했던 것이 사실입니다.</b></li><li><b>“남들이 10분만에 가져올 때 너 40분 넘게 뭐했냐?”</b>고 묻고 싶을 정도로 열심히 일하는데 결과물이 아쉽습니다.</li><li>부족한 기본기를 프롬프트 엔지니어링으로 커버하려다 보니 한계가 있지 않았나 싶습니다.</li></ul><ul><li>3번 문항은 일반인과 이 분야에 관심을 가지고 있는 사람들의 선을 넘는지 보았고,</li><li>그것이 3월 초의 <b>DeepSeek Open Source Week 행사</b>였습니다.</li><li>이 분야의 박사과정이라면 이 정도는 조사해서 와야 한다고 생각했는데 <b>Perplexity만 행사를 언급했습니다.</b></li><li>그러나 Perplexity도 답을 주었다기보다 한 단계 더 들어갈 실마리를 제공했다고 보는 게 좋습니다.</li></ul><p><img src="77_deepresearch_31.png"><br></p><ul><li>Deep Research는 이름과 달리 연구가 아닙니다.</li><li>자료 조사이지만 그나마 아직 발전의 여지가 있습니다.</li><li>몇 달 뒤에는 더 강력한 도구를 사용할 수 있기를 기대합니다.</li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/ChatGPT/">ChatGPT</category>
      
      <category domain="https://jehyunlee.github.io/tags/Gemini/">Gemini</category>
      
      <category domain="https://jehyunlee.github.io/tags/Perplexity/">Perplexity</category>
      
      <category domain="https://jehyunlee.github.io/tags/Genspark/">Genspark</category>
      
      <category domain="https://jehyunlee.github.io/tags/Manus/">Manus</category>
      
      
    </item>
    
    <item>
      <title>연구활용 AI 도구 사용방법</title>
      <link>https://jehyunlee.github.io/2025/01/20/General-76_researchgenai/</link>
      <guid>https://jehyunlee.github.io/2025/01/20/General-76_researchgenai/</guid>
      <pubDate>Mon, 20 Jan 2025 11:25:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;저희 연구원내 한 부서의 요청을 받아 연구 활용 생성 AI 도구 소개 및 사용 방법이라는 제목으로 발표를 드렸습니다.&lt;/li&gt;
&lt;li&gt;“생성 AI 도구들을 사용하기 어렵다”는 의견이 단 내에 있었다고 설명을 들었으며,&lt;/li&gt;
&lt;li&gt;</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>저희 연구원내 한 부서의 요청을 받아 연구 활용 생성 AI 도구 소개 및 사용 방법이라는 제목으로 발표를 드렸습니다.</li><li>“생성 AI 도구들을 사용하기 어렵다”는 의견이 단 내에 있었다고 설명을 들었으며,</li><li>이에 대응하여 다른 설명은 최대한 배제하고 최소한의 개념과 활용 사례 중심으로 발표를 드렸습니다.</li></ul><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>새로운 기술과 제품이 너무 빠르게 나와서 따라가기조차 쉽지 않은 것이 사실입니다.</li><li>모든 지식을 매 순간 업데이트하는 것은 거의 불가능합니다.</li><li><b>흐름을 따라가는 것</b>만으로도 충분하다고 생각합니다.</li></ul><p><img src="76_researchgenai_01.png" alt="생성 AI 모델의 대략적인 역사"></p><h1 id="2-LLM-RAG-AI-Agent"><a href="#2-LLM-RAG-AI-Agent" class="headerlink" title="2. LLM, RAG, AI Agent"></a>2. LLM, RAG, AI Agent</h1><ul><li>2023년 언론을 뒤덮은 ChatGPT는 <b>LLM, 거대 언어 모델</b>입니다.</li><li>지금의 GPT는, Claude와 Gemini는 그 때와는 <b>완전히 다른 제품</b>입니다.</li><li>LLM은 환각을 줄이고 내 정보를 활용하고자 <b>RAG: 검색 증강 생성</b>으로 진화했고,</li><li>한편으로 다양한 기능을 탑재하면서 <b>AI Agent</b>로 발전했습니다.</li></ul><p><img src="76_researchgenai_02.png" alt="주요 LLM 모델들의 현재"></p><ul><li>우리는 연구원이고, 우리에게 필요한 것은 <b>RAG AI Agent</b>입니다.</li><li>제가 자주 사용하는 도구들을 소개했습니다.</li></ul><ul><li><b><code>ChatGPT</code> |</b> <a href="https://chat.openai.com/">https://chat.openai.com</a><ul><li>다재다능한 대장주입니다.</li><li>GPTs를 사용해서 특화 기능을 활용해 보세요.</li></ul></li></ul><ul><li><b><code>Claude</code> |</b> <a href="https://claude.ai/">https://claude.ai</a><ul><li>문장력이 매우 뛰어납니다.</li><li>오늘보다 내일이 더 기대되는 모델입니다.</li></ul></li></ul><ul><li><p><b><code>Gemini</code> |</b> <a href="https://gemini.google.com/">https://gemini.google.com</a></p><ul><li>내 gmail과 google drive를 뒤져서 활용합니다.</li><li>Gemini 1.5 Pro Deep Research는 유사 기능 중 현존 최강이라 생각합니다.</li></ul></li><li><p><b><code>Perplexity</code> |</b> <a href="https://perplexity.ai/">https://perplexity.ai</a></p><ul><li>구글 검색을 거의 대체할 수 있지만 요새는 비슷한 도구들이 많이 나왔습니다.</li><li>빠른 스피드가 강점입니다. </li></ul></li></ul><ul><li><b><code>Genspark</code> |</b> <a href="https://genspark.ai/">https://genspark.ai</a><ul><li>Perplexity의 하위 호환이라 생각했지만 좋은 기능이 많이 생겼습니다.</li><li>특히 cross check 기능과 MoE: Mixture of Experts 기능을 꼭 사용해 보세요.</li></ul></li></ul><ul><li><b><code>Storm</code> |</b> <a href="https://storm.genie.stanford.edu/">https://storm.genie.stanford.edu</a><ul><li>같은 소재로 글쓰기를 해도 의도가 다르면 글이 달라집니다.</li><li>Writer AI와 Expert AI, 그리고 사람의 인터랙션을 느낄 수 있습니다.</li></ul></li></ul><ul><li><b><code>SciSpace</code> |</b> <a href="https://typeset.io/">https://typeset.io</a><ul><li>논문 작성을 위한 도구입니다.</li><li>My Library에 PDF 파일들을 채워두고 Chat with PDF, AI writer를 사용해 보세요.</li></ul></li></ul><ul><li><b><code>NotebookLM</code> |</b> <a href="https://notebooklm.google.com/">https://notebooklm.google.com/</a><ul><li>구글의 저력을 보여주는 서비스입니다.</li><li>대량의 자료를 대상으로 한 빠른 검색, 그리고 Audio Overview가 만들어주는 podcast가 너무 좋습니다.</li></ul></li></ul><h1 id="3-현재-진행형입니다"><a href="#3-현재-진행형입니다" class="headerlink" title="3. 현재 진행형입니다."></a>3. 현재 진행형입니다.</h1><p><img src="76_researchgenai_03.png" alt="RAG AI Agent 얼개"></p><ul><li>목표한 짐승을 사냥하는 헌터의 자세보다 고기를 기다리는 낚시꾼의 마음이 필요합니다.</li><li><b>“이런 기능이 있으면 좋겠다.”는 생각을 가지고 안테나를 세운 채 기다리세요.</b> </li><li>기다리던 AI 도구가 나오면, 맘 편히 사용하시는 것을 권해드립니다.</li><li>나한테 맞으면 계속 사용하고, 그렇지 않으면 안 쓰면 그만입니다.</li></ul><ul><li>발표자료를 공유드립니다: (<a href="250120_%EC%9D%B4%EC%A0%9C%ED%98%84_%EC%97%B0%EA%B5%AC%ED%99%9C%EC%9A%A9AI%EB%8F%84%EA%B5%AC%EC%82%AC%EC%9A%A9%EB%B0%A9%EB%B2%95.pdf">다운로드</a>)</li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/SciSpace/">SciSpace</category>
      
      <category domain="https://jehyunlee.github.io/tags/ChatGPT/">ChatGPT</category>
      
      <category domain="https://jehyunlee.github.io/tags/Claude/">Claude</category>
      
      <category domain="https://jehyunlee.github.io/tags/Gemini/">Gemini</category>
      
      <category domain="https://jehyunlee.github.io/tags/Perplexity/">Perplexity</category>
      
      <category domain="https://jehyunlee.github.io/tags/Genspark/">Genspark</category>
      
      <category domain="https://jehyunlee.github.io/tags/Storm/">Storm</category>
      
      <category domain="https://jehyunlee.github.io/tags/NotebookLM/">NotebookLM</category>
      
      
    </item>
    
    <item>
      <title>SciSpace (4) My Library</title>
      <link>https://jehyunlee.github.io/2025/01/18/General-75_scispace_mylibrary/</link>
      <guid>https://jehyunlee.github.io/2025/01/18/General-75_scispace_mylibrary/</guid>
      <pubDate>Fri, 17 Jan 2025 15:11:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;SciSpace 네 번째 글입니다. PDF 파일들을 정리할 수 있는 My Library입니다.&lt;/li&gt;
&lt;li&gt;믿을만한 문서들을 올려두고 활용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;Zotero, Mendeley를 사용하시던 분들이라면 Sci</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>SciSpace 네 번째 글입니다. PDF 파일들을 정리할 수 있는 My Library입니다.</li><li>믿을만한 문서들을 올려두고 활용할 수 있습니다.</li><li>Zotero, Mendeley를 사용하시던 분들이라면 SciSpace로 옮겨올 수 있습니다.</li></ul><h1 id="4-My-Library"><a href="#4-My-Library" class="headerlink" title="4. My Library"></a>4. My Library</h1><h2 id="4-1-문서-업로드-관리"><a href="#4-1-문서-업로드-관리" class="headerlink" title="4.1. 문서 업로드, 관리"></a>4.1. 문서 업로드, 관리</h2><blockquote><p><a href="https://jehyunlee.github.io/2024/05/24/General-53-genaipapersurvey/">Pega Devlog: 생성 AI 연구 활용 한계와 제언</a><br><a href="https://www.nature.com/articles/nature.2015.18703">Nature: Artificial-intelligence institute launches free science search engine</a><br><a href="https://www.semanticscholar.org/">Semantic Scholar: A free, AI-powered research tool for scientific literature</a><br><a href="https://www.zotero.org/">Zotero</a></p></blockquote><ul><li>SciSpace를 비롯한 정보 수집, 정리용 <b>AI 도구들의 가장 치명적인 약점은 Data Source</b>입니다.</li><li><a href="https://jehyunlee.github.io/2024/05/24/General-53-genaipapersurvey/"><b>반년 전 관련 글</b></a>을 올린 적도 있지만 여전히 유효합니다.</li><li>이런 도구들은 <a href="https://www.semanticscholar.org/"><b>Semantic Scholar: A free, AI-powered research tool for scientific literature</b></a>에서 논문을 찾습니다.</li></ul><p><img src="75_scispace_mylibrary_02.png" alt="Semantic Scholar 접속화면"></p><ul><li>Semantic Scholar가 좋은 검색 엔진이기는 하지만, 분야에 따라서는 답답합니다. </li><li><b>찾는 논문, 좋은 논문. 정확히는 유료 논문이 나오지 않기 때문입니다.</b></li><li>문제는 <b>AI가 논문을 찾아 내용을 정리해서 주다 보면 왠지 더 믿게 되고, 여기서 보이지 않는 것은 없다고 은연중에 생각하게 됩니다.</b></li><li>이를 해결할 수 있는 유일한 방법은 <b>논문을 직접 찾아 PDF 파일을 업로드하는 것</b>입니다.</li><li>ChatGPT에도 이런 식으로 논문을 올리고 활용할 수 있는데, 문제는 파일 관리를 PC 등에 별도로 해야 한다는 점입니다.</li><li>SciSpace는 문서를 올리고, 폴더를 만들어 관리할 수 있도록 <b>My Library</b>를 제공합니다.</li></ul><p><img src="75_scispace_mylibrary_01.png" alt="SciSpace 접속화면"></p><ul><li>우측 상단의 <b>My Library</b> 버튼을 누르면, 또는 좌측 세로줄 메뉴에서 <b>책꽂이 아이콘을 클릭하면</b></li><li>저의 경우 아래와 같은 장면이 펼쳐집니다.</li><li>먼저, 좌측에 엄청나게 많은 폴더들이 있습니다. 제가 <b>논문을 받을 때마다 만든 것들</b>과 함께,</li><li>한때 사용하던 <b>Zotero</b>에 저장된 서지정보를 받아온 것들입니다.</li></ul><p><img src="75_scispace_mylibrary_03.png" alt="My Library"></p><ul><li><p>이 중 주황색으로 표현된 <b>AI in Energy</b>폴더를 클릭한 것이 주 화면에 나온 것입니다.</p></li><li><p>폴더에 속한 논문들이 주요 내용과 함께 표로 정리되어 출력됩니다.</p></li><li><p>표의 우측 상단에서 <b>언어</b>를 설정할 수 있습니다. 기본값은 영어이지만 한글을 사용할 수 있습니다.</p></li><li><p>현재 한글로 설정되어 있기 때문에 아래의 <b><code>TL;DR</code></b>이 우리말로 출력되고 있습니다. </p></li><li><p><b><code>Files</code></b>에는 파일명이 있습니다. 24개의 파일명 아래에 세 가지 기능이 보이는데, </p></li><li><p><b><code>summary</code></b>, <b><code>Podcast</code></b>, <b><code>Chat</code></b>입니다.</p></li><li><p><b><code>summary</code></b>를 누르면 <b><code>TL;DR</code></b>보다 훨씬 자세한 요약이 출력되지만 <b>영어로만 고정되어 있습니다.</b></p></li><li><p>언어 설정을 할 수 없다는 점이 아쉽기는 하지만 <b><code>TL;DR</code>에 비해 훨씬 자세한 내용을 담고 있습니다.</b></p></li></ul><p><img src="75_scispace_mylibrary_04.png" alt="Summary"></p><ul><li><b><code>Chat</code></b>을 누르면 오른쪽에 플로팅 창이 뜨면서, <b>이 논문에 대해 질문을 하고 답을 받을 수 있습니다.</b></li><li>ChatGPT에 논문을 업로드해 둔 것과 같은 상황인데, <b>사용을 권장하지는 않습니다.</b></li><li>질문을 하면 빠르게 답변을 하고 본문 중 답을 가져온 지점을 레퍼런스로 표시해주는 것 까지는 좋은데,</li><li>레퍼런스를 클릭하면 <b><code>Chat with PDF</code></b>모드로 갑니다. 여기까지도 좋습니다.</li></ul><ul><li>제가 권장하지 말라고 한 것은, <b>창이 점프하면서 질문과 답변이 모두 사라지기 때문입니다.</b></li><li>단순한 오류이고 곧 고쳐질 것이라 생각하지만, 그리고 새로 열린 창에서 질의와 답변을 받을 수 있지만</li><li><b>그럴거면 그냥 논문 제목을 클릭해서 <code>Chat with PDF</code> 모드로 간 것이 더 편합니다.</b></li><li>뭔가 아직 정리가 덜 된 느낌이 있습니다.</li></ul><p><img src="75_scispace_mylibrary_05.png" alt="Chat"></p><ul><li>화면 오른쪽에는 <b><code>+</code></b> 로 시작하는 항목이 많이 있습니다.</li><li>여기를 클릭하면 표에 항목이 새로 붙으면서 각 논문마다 해당 데이터를 일괄 추출해 냅니다.</li><li>관심이 사라진 주제는 <b><code>x</code>를 눌러 닫을 수도 있고,</b></li><li>일괄 적용하고자 하는 질문이 없을 경우 <b><code>Create new column</code></b>을 눌러 새로운 열을 만들 수 있습니다.</li><li>그리고 우측 상단 <b><code>Export</code></b> 버튼을 눌러 표를 엑셀 등 형식으로 다운로드할 수 있습니다.</li></ul><p><img src="75_scispace_mylibrary_06.png" alt="추출 내용 추가"></p><ul><li><b>라이브러리 관리 방법</b>은 생각보다 간단합니다.</li><li>왼쪽 폴더 목록 위에 있는 <b><code>+New</code></b> 버튼을 눌러 폴더를 만들 수 있고,</li><li>오른쪽 위 <b><code>Upload PDFs</code></b> 버튼을 눌러 파일을 업로드할 수 있습니다.</li></ul><h2 id="4-2-가져오기"><a href="#4-2-가져오기" class="headerlink" title="4.2. 가져오기"></a>4.2. 가져오기</h2><ul><li>SciSpace는 Zotero의 목록을 가져올 수 있습니다.</li><li>화면 왼쪽 위 <b><code>Import from Zotero</code></b>버튼을 누르면 Zotero 계정과 연결하는 화면이 나오는데,</li><li>Zotero 아이디와 패스워드를 입력하여 연결하면 다음과 같이 어떤 폴더를 가져올지 선택할 수 있습니다.</li><li>가져올 폴더를 선택한 뒤 <b><code>Import</code></b> 버튼을 누르면 폴더가 생성되고, 그 안에 논문들이 추가됩니다.</li></ul><p><img src="75_scispace_mylibrary_08.png" alt="Import from Zotero"></p><ul><li><b>PDF 파일만 가져올 수 있다</b>는 이야기가 하단에 깨알같이 적혀있는데,</li><li>여기에 덧붙여 <b>Mendeley에서 Zotero로 가져온게 있다면 이건 안가져올거야</b>라고도 합니다.</li></ul><ul><li><b>사실과 다릅니다.</b></li><li><b>PDF 파일이 없는 서지정보</b>도 가져오며</li><li><b>Mendeley에서 가져온 논문들</b>도 가져옵니다.</li><li>그 바람에 서지정보를 입력하는 기능은 없는데 가져올 수는 있는 기형적인 구조가 됩니다.</li><li>기능이 추가되었으나 안내 문구가 수정되지 않은 것으로 짐작합니다.</li></ul><ul><li>희한한 것은 <b>서지정보만으로도 뭔가 데이터를 끄집어 낸다는 것</b>인데,</li><li><b><code>Summary</code></b>, <b><code>Podcast</code></b> 버튼은 동작하지 않지만 </li><li><b><code>Chat</code>은 오동작을 합니다.</b></li><li>무슨 말이냐면, 지시한 논문의 내용이 아닌 <b>아무말이나 지어낸다는 뜻입니다.</b></li></ul><p><img src="75_scispace_mylibrary_07.png" alt="서지정보"></p><ul><li>다행히 <b>논문 제목을 클릭해서 <code>Chat with PDF</code> 모드로 가면 써먹을만 합니다.</b></li><li>서지정보를 이용해 Semantic Scholar와 연결하는 것으로 보이는데,</li><li><b>초록</b>과 <b>TL;DR</b>, 그리고 <b>피인용수</b>까지 가지고 있는 것을 확인할 수 있기 때문입니다.</li></ul><p><img src="75_scispace_mylibrary_09.png" alt="서지정보를 이용한 Semantic Scholar 정보 수집"></p><ul><li><b>Request PDF</b>버튼을 통해 저자에게 메일을 보낼 수 있는데, </li><li><b>제가 교신저자로 등록돤 메일을 눌러보았지만, 확인해보니 정작 너무 예전 메일주소라 제가 확인할 수 없었습니다.</b></li><li>기능이야 어쨌든 다소 무례한 것이 아닌가 싶은 생각이 듭니다.</li></ul><p><img src="75_scispace_mylibrary_10.png" alt="Request PDF: 저자에게 원고 요청"></p><h2 id="4-3-맺음말"><a href="#4-3-맺음말" class="headerlink" title="4.3. 맺음말"></a>4.3. 맺음말</h2><ul><li>논문을 정리하는 사람 치고 적은 양을 정리하는 사람은 없습니다.</li><li>대학원에 입학한지 얼마 되지 않아 애초에 가진 것이 적은 경우를 제외하고는,</li><li>상당히 많은 논문 + 많아질 논문들을 관리하는 것이 숙명에 가깝습니다.</li><li>그런 면에서 <b>폴더를 만들어 정리할 수 있는 이 기능은 상당히 매력적입니다.</b></li><li>그러나 한편으로 <b>폴더 정렬이 되지 않는다는 점</b>은 매우 아쉽습니다.</li></ul><ul><li>설명과 달리 서지정보를 가져온다는 점에서 </li><li><b>Zotero, Mendeley 같은 서지 관리 프로그램</b>을 노리는 건 아닌가 싶기도 합니다.</li><li>사실 전통의 강자 <b>EndNote</b>를 포함해 이런 프로그램들이 여럿 있고, </li><li>이들도 AI 기능을 달려면 얼마든지 달 수 있습니다. SciSpace보다 더 유리한 고지를 점한 곳도 많습니다.</li><li><b>더 좋은 도구들이 나오면 언제든 활용할 수 있다는 열린 마음으로 기다리는 자세</b>가 필요할 듯 합니다.</li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/SciSpace/">SciSpace</category>
      
      
    </item>
    
    <item>
      <title>SciSpace (3) Find Topics</title>
      <link>https://jehyunlee.github.io/2025/01/05/General-74_scispace_topic/</link>
      <guid>https://jehyunlee.github.io/2025/01/05/General-74_scispace_topic/</guid>
      <pubDate>Sun, 05 Jan 2025 12:27:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;SciSpace 세 번째 글입니다. Find Topics라는 새 기능이 있습니다.&lt;/li&gt;
&lt;li&gt;하나의 주제에 대한 문헌을 찾고 글을 모으기를 반복할 수 있는 기능입니다.&lt;/li&gt;
&lt;li&gt;잘 사용하면 문헌 조사를 매우 빠르게 할 수 </description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>SciSpace 세 번째 글입니다. Find Topics라는 새 기능이 있습니다.</li><li>하나의 주제에 대한 문헌을 찾고 글을 모으기를 반복할 수 있는 기능입니다.</li><li>잘 사용하면 문헌 조사를 매우 빠르게 할 수 있으나, 레퍼런스의 상태를 잘 확인해야 합니다.</li></ul><h1 id="3-Find-Topics"><a href="#3-Find-Topics" class="headerlink" title="3. Find Topics"></a>3. Find Topics</h1><h2 id="3-1-Literature-Review-vs-Find-Topics"><a href="#3-1-Literature-Review-vs-Find-Topics" class="headerlink" title="3.1. Literature Review vs Find Topics"></a>3.1. Literature Review <em>vs</em> Find Topics</h2><blockquote><p><a href="https://jehyunlee.github.io/2025/01/04/General-73_scispace_review/">Pega Devlog: SciSpace (2) Literature Review</a></p></blockquote><ul><li><p><a href="https://jehyunlee.github.io/2025/01/04/General-73_scispace_review/"><b>지난 글</b></a>에서 <code>Literature Review </code>기능을 리뷰했습니다.</p></li><li><p>간단히 정리하자면, <b>특정 주제에 대해 문헌들을 검색하고 내용들을 정리하는 기능</b>입니다.</p></li><li><p>정리된 레퍼런스들은 하단에 표 형태로 정리되어 <b>문헌간 비교</b>를 하기 좋게 되어 있습니다.</p></li><li><p>거듭 강조하지만 이 표에 나오는 레퍼런스 정리는 많이 빈약합니다. <b><code>Chat with PDF</code></b> 모드로 가서 제대로 뒤져보실 필요가 있습니다.</p></li><li><p><b><code>Find Topics</code></b> 기능은 <code>Literature Review</code> 기능과 비슷하면서 다릅니다.</p></li><li><p><code>Literature Review</code>가 하나의 주제에 대한 여러 논문을 검색한다면,</p></li><li><p><b><code>Find Topics</code>는 입력한 주제를 중심으로 여러 세부 주제를 찾습니다(Finding Topics).</b></p></li><li><p>이 때 레퍼런스는 세부 주제 하나에 몇 개만을 찾아서 가져오기 때문에 주제 하나에 대한 깊이는 얕은 편입니다.</p></li><li><p>일종의 <b>레퍼런스를 사용해 강화하는 brain storming</b>으로 볼 수 있습니다.</p></li></ul><p><img src="74_scispace_topics_01.png"></p><h2 id="3-2-Find-Topics"><a href="#3-2-Find-Topics" class="headerlink" title="3.2. Find Topics"></a>3.2. Find Topics</h2><ul><li><b><code>Find Topics</code></b>로 들어가면 아래와 같은 화면이 나옵니다.</li><li>관심이 있는 주제를 직접 입력해도 되는데, 마침 본업에 속하는 주제가 있어 클릭을 해 봅니다.</li></ul><p><img src="74_scispace_topics_02.png"></p><ul><li>약 1~2초간 빠르게 다섯 단계를 진행합니다.<ol><li><b>관련 논문 탐색</b></li><li><b>논문별 주제 탐색</b></li><li><b>외부 소스로부터 주제 탐색</b></li><li><b>독특한(unique) 주제 추출</b></li><li><b>최종 결과 준비</b></li></ol></li></ul><p><img src="74_scispace_topics_05.png"></p><ul><li>잠시 후 등장한 화면은 다음과 같습니다.</li><li><code>Literature Review</code>와 마찬가지로 다섯 편(10편으로 조정 가능)의 논문에서 정리된 단락이 있습니다. </li><li>그리고 하단에는 개별 논문 대신 <b>개별 주제들과 이에 해당하는 논문들이 있습니다.</b></li><li>Sources에 <b>Generated by SciSpace models</b>라고 쓰인 것들이 있습니다.</li><li>레퍼런스 없이 AI가 추론만 한 것으로 보입니다.</li></ul><p><img src="74_scispace_topics_06.png"></p><ul><li>상단에 결과물의 품질을 결정하는 <b>Standard/High Quality</b>버튼이 있습니다.</li><li>유료 사용자라면 High Quality를 눌러 더 좋은 결과를 얻을 수 있습니다.</li><li>무료 버전만 쓸 때는 무료 버전도 괜찮다고 느끼지만, </li><li>유료 모드로 사용해보면 무료 버전이 너무 부족하다는 것을 느끼게 됩니다.</li></ul><ul><li><b>출력 언어도 지정할 수 있습니다.</b></li><li>영어로 출력하는 것이 기본이지만 한국어를 선택하면 한국어 버전의 답을 볼 수 있습니다.</li><li>단, 이 때 영어 버전의 답변을 번역하는 것이 아니라 <b>완전히 새롭게 답을 생성해 제출합니다.</b></li><li>영어로 받은 답이 마음에 든다면 번역기를 사용하는 것을 권장합니다.</li></ul><p><img src="74_scispace_topics_07.png"></p><ul><li>찾은 주제와 이에 대한 소스들이 나란히 놓여 있습니다만, <b>단점</b>이 곧장 드러납니다.</li><li><b>“향후 10년의 경향”을 요청했음에도 불구하고 1993년, 2011년 논문을 인용합니다.</b></li><li>레퍼런스를 제대로 체크하지 않으면 그럴싸할 뿐 맞지 않는 이야기를 하게 됩니다.</li><li><b>AI는 완벽하지 않습니다.</b> 도움을 주면 감사하게 쓰고, 미흡하면 기각해야 합니다.</li><li>그리고 <b>이를 거를 수 있는 눈은 사용자가 개발하지 않으면 누구도 대신 해 주지 않습니다.</b></li></ul><ul><li>클릭할 수 있는 곳들이 곳곳에 있습니다. 하나씩 살펴봅니다.</li></ul><ul><li><b>Export as CSV</b>: Topics/Sources 표를 CSV 형식으로 내보냅니다.<ul><li>다운로드된 파일을 더블클릭해서 엑셀로 열면 한글이 깨져 있기도 합니다.</li><li>인코딩 문제입니다. </li><li><code>엑셀 프로그램 실행</code> &gt; <code>새 통합 문서</code> &gt; <code>데이터 탭</code> &gt; <code>텍스트/CSV 열기</code> &gt; <code>utf-8 인코딩</code>으로 여세요.<br><img src="74_scispace_topics_09.png"></li></ul></li></ul><ul><li><b>Save to Notebook</b>: 주제를 노트북에 저장합니다.<ul><li>Jupyter Notebook처럼 코딩을 할 수 있는 플랫폼이나 형식이 아니라, 메모장 같은 겁니다.</li><li>SciSpace가 정리한 결과를 다시 꺼내볼 수 있도록 저장해 둡니다.</li><li><b><code>My Library</code></b>에서 폴더를 만들었다면, 폴더를 지정할 수 있습니다.</li><li><code>My Library</code>는 다음 글에서 자세히 설명하겠습니다.<br><img src="74_scispace_topics_04.png"></li></ul></li></ul><ul><li><b>Topic 이름</b>: 이를 바탕으로 또 다른 Topic들을 도출합니다.<ul><li>가지의 가지를 친다고도 볼 수 있습니다.</li><li>아쉽게도 더 깊이 파고들어간다는 느낌은 들지 않습니다.</li><li>오픈소스 레퍼런스의 한계 때문인지, 얕은 바닥에서 빙빙 돈다는 느낌이 듭니다.<br><img src="74_scispace_topics_10.png"></li></ul></li></ul><h2 id="3-3-맺음말"><a href="#3-3-맺음말" class="headerlink" title="3.3. 맺음말"></a>3.3. 맺음말</h2><ul><li>이번 글은 여기까지입니다.</li><li><code>new</code>가 붙은 새로운 기능이어서 그런지, 만족감보다 아쉬움이 더 큽니다.</li><li>Topics &gt; Topics &gt; … 로 가는 기능이 정상적으로 작동한다면 심층 분석이 들어가야 할 것입니다.</li><li>그러나 그러기에는 <b>레퍼런스의 장벽</b>이 생각보다 높게 느껴집니다.</li></ul><ul><li>유료 논문들에 접근을 하지 못하는 바람에 근본적인 한계가 있다고도 느껴집니다.</li><li>그러나 Vector DB를 사용하는 RAG 방식으로 인한 본질적 제약이라는 생각입니다.</li><li>RAG(Retrieval Augmented Generation) 방식의 특성상 수집한 DB의 chunk, 즉 토막글에서 관련 글을 찾을 것입니다.</li><li>이 때 <b>년도나 저널명 같은 정보는 부차적으로 처리</b>될 것이고, 선별이 어려워집니다.</li></ul><ul><li>하지만 이제까지 문제가 있으면 기를 쓰고 해결해온 것이 인류입니다.</li><li>더 나은 솔루션이 생각보다 훨씬 빨리 등장하리라 생각하고, 기대합니다.</li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/SciSpace/">SciSpace</category>
      
      
    </item>
    
    <item>
      <title>SciSpace (2) Literature Review</title>
      <link>https://jehyunlee.github.io/2025/01/04/General-73_scispace_review/</link>
      <guid>https://jehyunlee.github.io/2025/01/04/General-73_scispace_review/</guid>
      <pubDate>Fri, 03 Jan 2025 15:46:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;SciSpace 두 번째 글입니다.&lt;/li&gt;
&lt;li&gt;원하는 정보를 담은 글들을 찾아 읽고 내용을 정리하는 일은 연구자의 일상이지만 만만치 않습니다.&lt;/li&gt;
&lt;li&gt;검색과 정리 능력을 활용해 이를 편안하게 도와주는 기능들을 소개합니다.</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>SciSpace 두 번째 글입니다.</li><li>원하는 정보를 담은 글들을 찾아 읽고 내용을 정리하는 일은 연구자의 일상이지만 만만치 않습니다.</li><li>검색과 정리 능력을 활용해 이를 편안하게 도와주는 기능들을 소개합니다. 단, 한계가 있습니다.</li></ul><h1 id="2-Literature-Review"><a href="#2-Literature-Review" class="headerlink" title="2. Literature Review"></a>2. Literature Review</h1><h2 id="2-1-Perplexity와-비교"><a href="#2-1-Perplexity와-비교" class="headerlink" title="2.1. Perplexity와 비교"></a>2.1. Perplexity와 비교</h2><blockquote><p><a href="https://www.typeset.io/?via=jehyun">SciSpace</a></p></blockquote><ul><li><a href="https://www.typeset.io/?via=jehyun"><b><code>SciSpace</code></b></a>에 들어서면 다음과 같은 화면을 마주합니다.</li><li>정 가운데 구글을 닮은 검색창이 있고, 아래 <b>이런 질문을 해보지 않으련?</b>하는 느낌으로 몇 개의 예시가 있습니다.</li><li>본능을 억누르고 마우스 휠을 굴려 아래로 향하면 여러 기능들이 등장합니다. </li><li>여기 등장하는 <b>Literature Review</b>가 위에 있는 검색창과 같은 기능을 합니다.</li></ul><p><img src="73_scispace_review_01.png"></p><ul><li><b>Literature Review는 Perplexity와 비슷합니다.</b></li><li>사용자의 질의(query)를 받아 웹 검색을 하고, 여기서 찾은 자료를 정리하여 문장으로 제공합니다.</li><li>비교를 위해 Perplexity 화면을 먼저 보겠습니다.</li></ul><p><img src="73_scispace_review_02.png"></p><ul><li>화면 가운데 있는 검색창에 질의를 하면 웹 검색을 통해 답을 모아줍니다.</li><li>최근 ChatGPT에도 <b>뒙 검색</b>기능이 추가되어 비슷한 기능이 구현되었습니다.</li><li>Perplexity에는 ChatGPT에 (아직) 없는 기능이 있는데, <b>검색 범위를 한정하는 것</b>입니다.</li><li>왼쪽 아래 <b><code>Focus</code></b>버튼을 누르면 여섯 가지 범위가 나옵니다.</li><li>이 중 <b><code>Academic</code></b>를 선택하면 학술 문서들을 대상으로 검색합니다.</li></ul><ul><li>예를 들어 이와 같이 선택하고 <b>수소 생산을 위한 신규 소재 탐색</b>이라고 질의하면,</li><li>논문들을 찾아 검색한 결과만을 보여줍니다.</li><li>아래 그림에서 답변 생성에 활용된 학술논문들 10개의 목록이 보입니다.</li><li>자세히 보면 논문들의 출처가 <b><code>semanticscholar</code></b>와 <b><code>pubmed</code></b>입니다.</li></ul><h2 id="2-2-Review"><a href="#2-2-Review" class="headerlink" title="2.2. Review"></a>2.2. Review</h2><p><img src="73_scispace_review_03.png"></p><ul><li>같은 질의를 SciSpace의 Literature Review에 넣으면 다음과 같은 결과가 나옵니다.</li><li>먼저 상단에 <b>논문 다섯 편의 정보를 활용한 답변</b>이 출력되고,</li><li>그 아래 <b>논문 열 편의 목록</b>과 함께 각 논문에서 얻은 insights가 제공됩니다.</li><li>마지막으로 맨 하단에 Perplexity와 유사하게 <b>Related Questions</b>가 다섯 개 제시되고 있습니다.</li></ul><p><img src="73_scispace_review_04.png"></p><ul><li>왜 10편의 목록을 보여주면서 5편만 가지고 정리하나 싶지만,</li><li>답변 상단을 보면 <b>몇 편의 내용을 정리시킬지</b>를 선택할 수 있습니다.</li><li>10편으로 정리하라면 10편으로 정리합니다.</li><li>또, <b>언어를 설정할 수 있습니다.</b> </li><li>한국사람인 만큼 한글이 편하지만 전문용어를 최대한 반영하고자 영어로 설정하는 편입니다.</li><li><b>Save</b> 버튼을 누르면 결과를 저장하여 나중에 다시 열어볼 수 있습니다.</li></ul><h2 id="2-3-Papers"><a href="#2-3-Papers" class="headerlink" title="2.3. Papers"></a>2.3. Papers</h2><blockquote><p><a href="https://onlinelibrary.wiley.com/doi/10.1002/adma.202313378">Yuan Wang et al., “1. Advancing Catalysts by Stacking Fault Defects for Enhanced Hydrogen Production: A Review.”, Advances in Materials (2024)</a></p></blockquote><p><img src="73_scispace_review_05.png"></p><ul><li>본문으로 가면 유용한 기능이 많습니다.</li><li>질의에 답변하기 위해 찾은 논문들이 <b>표 형태로 정리되어 있습니다.</b></li><li>행을 따라 논문들이 놓여 있고, 열에는 논문 서지정보와 Insights 정도만 있지만 오른쪽에 여러 열들을 계속 붙일 수 있습니다.</li><li>예를 들어 <b>Conclusions</b> 열을 추가하면 논문들의 결론을 모아 볼 수 있습니다.</li></ul><ul><li>여러 논문들을 함께 나란히 놓고 비교할 수 있다는 장점이 있지만 <b>추천하지 않습니다.</b></li><li>몇 가지 이유가 있습니다.<br><b>(1) Open Access 논문이 아닌 경우, 초록에서만 정보를 가져옵니다.</b> 매우 제한적일 수 밖에 없습니다.<br><b>(2) 표에 담으려다보니 극단적으로 짧게 요약합니다.</b> 중요 정보가 누락되는 경우가 많습니다.<br><b>(3) 잘못 찾거나 못찾는 경우가 적지 않습니다.</b> 해당 논문을 따로 열어서 보면 잘 찾습니다.</li></ul><ul><li>상단에 필터를 걸어 논문들을 선별할 수 있는데, <b>PDF</b>나 <b>Open Access</b>를 선택하시는 것을 추천합니다.</li><li>논문의 본문을 볼 수 있어 깊이 파고들며 발췌독을 하기에 좋기 때문입니다.</li><li><b>More Filters</b>를 누르면 년도, 저널 등을 선택할 수 있습니다.</li></ul><ul><li>참고할만한 정보를 확보했다는 전제 하에 우측 상단위 <b>Export</b>버튼을 눌러보셔도 좋습니다.</li><li>화면에 보이는 정보들을 선택에 따라 CSV, Excel, BibTeX, XML, RIS 등 형식으로 내려받을 수 있습니다.</li><li>참고문헌 목록을 만들어 정리할 때 매우 유용합니다.</li><li></li></ul><p><img src="73_scispace_review_06.png"></p><ul><li>최근 추가된 기능으로 <b>Podcast</b>가 재미있습니다.</li><li>클릭하면 논문의 길이에 따라 수십 초에서 수 분 정도 후에 남녀 한 명씩이 논문 내용을 설명해주는 podcast가 재생됩니다.</li><li><a href="advancing-catalysts-by-stacking-fault-defects-for-enhanced-2yvdhr4zek_2025-01-03-17-47-33.mp3"><b><code>첫 번째 논문</code></b></a>의 예시를 내려받아 확인해보셔도 좋습니다.</li><li>개인적인 느낌으로 Google NotebookLM에서 제공하는 Audio Overview에 비해 생동감이 덜해서 아쉽습니다.</li></ul><ul><li>PDF 파일이 있는 논문의 제목을 클릭한 수 스크롤을 내리면 다음과 같은 화면을 볼 수 있습니다.</li><li>왼쪽에는 논문의 본문, 오른쪽에는 <b>Chat with Paper</b>라는 이름으로 챗봇이 붙어 있습니다.</li><li><b>챗봇에 요청을 해서 본문의 내용을 끄집어낼 수 있습니다.</b></li></ul><p><img src="73_scispace_review_07.png"></p><ul><li>일종의 <b>AI를 사용한 발췌독</b>이 가능한 셈입니다.</li><li>논문을 빠르게 읽기 위해 <b>통으로 요약</b>하는 것이 흔하지만, <b>디테일이 날아가고 왜곡이 발생합니다.</b></li><li>이를 방지하기 위해 <b>요약보다 발췌를 하는 것을 추천드립니다.</b></li><li>GPT에 PDF를 올리고 넣는 프롬프트 기준으로 예를 들면, <b>200단어로 요약해줘</b>라고 하지 말고 </li><li><b>저자들은 이 연구에서 어떤 문제를 해결하려고 했어?</b>, <b>본문 중 OOO를 확인하기 위해 사용된 분석 기법이 뭐야?</b>처럼 묻는 식입니다.</li></ul><p><img src="73_scispace_review_08.png"></p><ul><li>자세하게 물어보면 자세한 답변을 얻을 수 있습니다.</li><li>특히 <b>SciSpace를 유료 구독하여 High Quality 모드를 사용하면</b> 더 정확한 답변을 얻을 수 있습니다.</li><li>자세한 사용법은 <b>Chat with PDF</b>글에서 다시 설명드리겠습니다.</li></ul><h2 id="2-4-맺음말"><a href="#2-4-맺음말" class="headerlink" title="2.4. 맺음말"></a>2.4. 맺음말</h2><ul><li>검색 능력에 LLM을 붙여 정리를 시키는 것은 지금은 보편화된 기술입니다.</li><li>AI 활용 기술이 보편화될수록 쉽게 사용할 수 있는 반면, </li><li>특정 분야에 전문성이 있는 사람이나 도구를 쓸 때와 같은 날카로움은 기대하기 어렵습니다.</li><li>이럴 수록 내가 무엇을 얻을 수 있으며 무엇은 기대할 수 없는지 명확하게 알아야 합니다.</li><li>그리고 내 능력의 한계를 벗어나면 판단을 할 수 없는 만큼, 스스로의 역량을 갈고 닦아야 합니다.</li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/SciSpace/">SciSpace</category>
      
      
    </item>
    
    <item>
      <title>SciSpace (1) overview</title>
      <link>https://jehyunlee.github.io/2024/12/30/General-72_scispace/</link>
      <guid>https://jehyunlee.github.io/2024/12/30/General-72_scispace/</guid>
      <pubDate>Mon, 30 Dec 2024 04:29:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;SciSpace는 연구에 활용하기 좋은 AI 도구입니다.&lt;/li&gt;
&lt;li&gt;기능이 많아 짧은 글에 모든 기능을 담기 어려워, 몇 편으로 나누어 소개합니다.&lt;/li&gt;
&lt;li&gt;오늘은 첫 번째 글로, 개괄적인 내용을 다룹니다.&lt;/li&gt;
&lt;/u</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>SciSpace는 연구에 활용하기 좋은 AI 도구입니다.</li><li>기능이 많아 짧은 글에 모든 기능을 담기 어려워, 몇 편으로 나누어 소개합니다.</li><li>오늘은 첫 번째 글로, 개괄적인 내용을 다룹니다.</li></ul><h1 id="1-scispace"><a href="#1-scispace" class="headerlink" title="1. scispace"></a>1. scispace</h1><blockquote><p><a href="https://www.typeset.io/?via=jehyun">SciSpace</a></p></blockquote><p><img src="72_scispace_01.png" alt="SciSpace 한국어 접속화면"></p><h2 id="1-1-overview"><a href="#1-1-overview" class="headerlink" title="1.1. overview"></a>1.1. overview</h2><blockquote><p><a href="https://www.typeset.io/t/about/">SciSpace: about scispace</a><br><a href="https://www.typeset.io/formats/search/">SciSpace: journal gallery</a><br><a href="https://typeset.io/resources/typeset-evolving-into-scispace/">SciSpace: introducing SciSpace-Revolutionizing research workflows end-to-end</a></p></blockquote><p><img src="72_scispace_05.png" alt="[www.scispace.com 접속시 안내 화면](https://scispace.com/)"></p><ul><li>scispace의 웹사이트는 <a href="https://www.typeset.io/?via=jehyun"><b><code>https://typeset.io/</code></b></a>입니다.</li><li>이름과 사이트 이름이 달라 <b>왜지?</b>라는 궁금증을 불러일으키기 마련입니다만,</li><li>2015년 서비스를 처음 개시했을 때는 특정 학술지에 맞춰 <b>서식을 조정하는 도구(typesetting tool)</b>였습니다.</li></ul><blockquote><p>“It is funny to look back and think that it all began with rejection. My university rejected my thesis in the final year of graduation because of inappropriate formatting.</p></blockquote><blockquote><p>“모든 것이 거부에서 시작되었다는 사실을 돌이켜보면 웃음이 나옵니다. 제 학위논문은 서식을 맞추지 못했다는 이유로 대학 당국에 의해 졸업이 거부되었습니다.”</p></blockquote><ul><li>SciSpace의 설립자인 Saikiran Chandhark가 <b>학위논문 서식을 맞추지 못해 졸업이 거절당한 것이 시작</b>이라고 합니다.</li></ul><ul><li>학술지 typesetting tool의 흔적은 <a href="https://www.typeset.io/formats/search/"><b><code>journal gallery</code></b></a>에서 찾아볼 수 있습니다.</li><li>저널 이름을 검색하여 선택하면 출판 형식을 보여주고, </li><li>MS template를 올리거나 사이트에서 자체 제공하는 빈 문서를 사용해 논문을 작성할 수 있습니다.</li></ul><p><img src="72_scispace_02.png" alt="SciSpace journal gallery: &quot;Artificial Intelligence&quot; 검색 화면"><br><img src="72_scispace_03.png" alt="SciSpace journal gallery: &quot;Artificial Intelligence&quot; 선택 화면"><br><img src="72_scispace_04.png" alt="SciSpace journal gallery: &quot;A blank document&quot; 선택 화면"></p><ul><li><b>typesetting tool</b>로 시작한 서비스는 <b>무료 full-text PDF 검색 도구</b>로 발전했습니다.</li><li>2022년 5월 11일, <b>science</b>와 <b>workspace</b>를 결합한 의미의 <b>SciSpace</b>로 브랜드를 전환했습니다.</li><li>당시만 해도 지금과 같은 문서 요약이나 글쓰기 도구는 담기지 않았던 것으로 보입니다.</li></ul><blockquote><p>“Two significant questions stood before us: how to build a world where breakthrough scientific research happens at pace, and how do we evolve our brand messaging to convey the same.”</p></blockquote><blockquote><p>“중요한 질문 두 개가 우리 앞에 놓여 있었습니다. 획기적인 과학 연구가 빠른 속도로 이루어지는 세상을 어떻게 만들 것인가, 그리고 이 방법을 전달하는 우리 브랜드를 어떻게 성장시킬 것인가 하는 점입니다.”</p></blockquote><ul><li><a href="https://typeset.io/resources/typeset-evolving-into-scispace/">SciSpace 창립자가 사명을 변경하면서 발행한 글</a>에는 42%의 학술논문이 유료화 장벽(paywall) 너머에 있다고 기술되어 있습니다.</li><li>학제와 지역의 벽을 넘어 <b>연구자들간의 협업 커뮤니티</b>를 만들어 보겠다는 포부가 PDF 공유와는 무관해보이기도 합니다만</li><li>일종의 <b>논문 검색 엔진</b>을 매개로 연구를 가속화하겠다는 포부는 전달됩니다.</li></ul><p><img src="72_scispace_08.jpg" alt="2022년 무료 full-text PDF 검색 도구를 표방하던 당시의 자료"></p><p><img src="72_scispace_09.png" alt="SciSpace 로고 디자인 과정"></p><ul><li>당시 <b>mission</b>에서 <b>문헌 검색과 연구 논문 작성부터 연구의 가시성 향상 모두를 현대화한다</b>는 목표를 읽을 수 있습니다.</li></ul><blockquote><p>“SciSpace on a mission is to become the most comprehensive end-to-end platform for researchers, modernizing everything from the literature search and research writing to improving research visibility.”</p></blockquote><ul><li>그리고 2023년, SciSpace는 현재의 <b>논문 탐색 &amp; 작성 도구</b>로 발전했습니다.</li></ul><h2 id="1-2-문헌-Database"><a href="#1-2-문헌-Database" class="headerlink" title="1.2. 문헌 Database"></a>1.2. 문헌 Database</h2><blockquote><p><a href="https://chatgpt.com/g/g-NgAcklHd8-scispace">GPTs: SciSpace</a><br><a href="https://doi.org/10.48550/arXiv.2301.10140">The Semantic Scholar Open Data Platform</a><br><a href="https://allenai.org/open-data">Allen Institute: Open Data</a><br><a href="https://typeset.io/resources/tag/open-access/">SciSpace Resources: Open Access</a><br><a href="https://jehyunlee.github.io/2024/05/24/General-53-genaipapersurvey/">Pega Devlog: 생성AI 연구 활용 한계와 제언</a></p></blockquote><ul><li>SciSpace는 270 million+, 즉 2.7억편 이상의 논문에 접근할 수 있다고 합니다. </li><li>SciSpace GPTs에는 287 million으로 표시되어 있습니다.</li><li>그러나 <b>참조 데이터베이스 명을 명시하지 않고 있습니다.</b></li><li>이 중 2.2억편은 Allen Institute에서 운영하는 <a href="https://allenai.org/open-data"><b><code>S2AG</code></b></a>에서 제공하는 데이터입니다.</li><li>S2AG는 Microsoft에서 운영하던 Microsoft Academic Graph(MAG)의 데이터를 계승한 것입니다.</li></ul><p><img src="72_scispace_06.png" alt="Allen Institute: S2AG"></p><ul><li><p>좋은 데이터이지만 근본적인 한계가 있습니다.</p></li><li><p><b>Open Access 논문</b>에 의존한다는 점인데, <b>분야에 따라서는 쓸만한 정보를 얻을 수 없기 때문입니다.</b></p></li><li><p>SciSpace에서 논문들을 대상으로 질의를 하고 답변을 받을 수 있으나 </p></li><li><p><b>본인의 분야 및 목적이 open access로 충분한지</b> 검토가 선행되어야 합니다.</p></li><li><p>SciSpace에서 논문을 찾아보면 Google Scholar를 비롯해 arXiv, PubMed, Semantic Scholar, IEEE 등에서 검색을 합니다.</p></li><li><p>그러나 본문까지 검색이 되는 것은 <b>open access 논문으로 한정</b>되고, </p></li><li><p><b>본문이 공개되지 않은 Google Scholar 검색 논문과 IEEE Xplore 논문 등은 초록만 활용할 수 있습니다.</b></p></li><li><p>사용자의 목적에 따라 초록만으로도 충분한 경우가 있고, open access로도 충분할 때가 있습니다.</p></li><li><p>중요한 것은 <b>한계를 알고 사용하는 것</b>입니다.</p></li></ul><ul><li>다행히 <a href="https://www.researchgate.net/"><b><code>ResearchGate</code></b></a>같은 원문 공유 사이트에서 일부 유료 논문을 볼 수 있습니다.</li><li>저자들의 너그러움에 기대는 방식인데,</li><li>최근 SciSpace에 <b>저자에게 원문을 요청하는 메일을 보내는 기능</b>이 추가되었습니다.</li></ul><p><img src="72_scispace_14.png" alt="Request PDF 버튼을 누르면 나오는 원문 요청 화면"></p><ul><li>이래도 되나 싶은, 다소 당혹스러운 느낌이 들기도 합니다.</li><li>일단, 가급적 <b>PDF 파일을 직접 업로드하여 사용하시기를 권장</b>합니다.</li></ul><h2 id="1-3-언어-모델"><a href="#1-3-언어-모델" class="headerlink" title="1.3. 언어 모델"></a>1.3. 언어 모델</h2><blockquote><p><a href="https://typeset.io/resources/introducing-copilot-ai-assistant-explains-research-papers/">SciSpace Resources: Introducing ChatPDF: Your AI assistant that helps explain papers</a><br><a href="https://typeset.io/resources/ai-summary-generators/">SciSpace Resources: AI Summary Generator in Academic – A Quick Guide (2024)</a><br><a href="https://typeset.io/resources/best-chatpdf-tool-scispace/">SciSpace Resources: Adobe PDF Reader vs. SciSpace ChatPDF — Best Chat PDF Tools</a><br><a href="https://typeset.io/resources/research-paper-summarizer-an-overview/">SciSpace Resources: Research paper summarizer | An overview of the best AI summarizers</a><br><a href="https://aclanthology.org/2020.findings-emnlp.428/">EMNLP 2020: SciTLDR</a><br><a href="https://github.com/allenai/scitldr">github: SciTLDR</a><br><a href="https://arxiv.org/abs/1903.10676">arXiv: SciBERT</a><br><a href="https://github.com/allenai/scibert">github: SciBERT</a><br><a href="https://spacy.io/universe/project/scispacy">spacy: scispacy</a><br><a href="https://allenai.github.io/scispacy/">github: scispacy</a><br><a href="https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/NotebookLlama/README.md">github: NotebookLlama</a></p></blockquote><ul><li>현재의 SciSpace는 언어모델을 이용해 <b>요약, 질의, 번역</b> 등의 기능을 제공합니다.</li><li>하지만 <b>SciSpace에서 사용하는 언어모델</b>에 대해 명확하게 공개된 바가 없습니다.</li><li><a href="https://typeset.io/resources/introducing-copilot-ai-assistant-explains-research-papers/"><b>Copilot이라는 이름의 첫 버전</b></a>이 등장한 것은 22년 12월*이고,<br>(원글이 업데이트됨. <a href="https://researchtoolsbox.blogspot.com/2022/12/introducing-copilot-your-ai-assistant.html?m=0">아카이빙된 원글 링크</a>)</li><li>ChatGPT 3.5 API가 2023년 3월 1일에 공개된 점에 미루어 볼 때,</li><li>이전에 공개된<b>GPT3 API를 활용하다 GPT 버전 업데이트에 발맞추어 개선한 것으로 여겨집니다.</b></li></ul><ul><li>그러나 한편으로 <b>다른 모델을 (함께) 사용할 가능성을 배제할 수 없습니다.</b></li><li>Semantic Scholar는 일부 논문들에 대해 초록을 세 줄 가량으로 요약한 <b>TLDR</b> 기능을 제공합니다.</li><li>Allen Institute에서 개발한 <a href="https://github.com/allenai/scitldr"><b><code>SciTLDR</code></b></a>을 사용한 것입니다.</li><li>2020년 EMNLP에서 발표된 논문으로, 3,935개의 요약문 데이터셋을 사용해 개발되었습니다.</li></ul><p><img src="72_scispace_10.png" alt="SciTLDR 논문 (2020): https://aclanthology.org/2020.findings-emnlp.428/)"></p><ul><li>BERT 모델을 과학 논문들로 미세조정한 <a href="https://github.com/allenai/scibert"><b><code>SciBERT</code></b></a>도 있습니다.</li><li>2019년에 나온 논문으로, BERT 모델을 과학 논문들로 미세조정한 것입니다.</li><li><code>SciBERT</code>는 자연어 처리 라이브러리 <code>Spacy</code>를 과학 문헌에 맞게 조정한 <code>SciSpacy</code>에 기반을 두고 있습니다.</li><li>GPT를 비롯한 거대 언어 모델을 사용하려면 API 비용이 소요되고 응답시간이 길어지기 때문에 <b>이런 작은 모델들을 운영할 여지가 충분합니다.</b></li></ul><p><img src="72_scispace_11.png" alt="SciSpacy: https://allenai.github.io/scispacy/"></p><ul><li>최근에는 <b>Google NotebookLM</b>을 필두로 PDF 문서를 podcast로 만들어주기도 합니다.</li><li>오픈소스로 공개된 <a href="https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/NotebookLlama/README.md"><b><code>NotebookLlama</code></b></a>를 이용하면 누구나 podcast를 만들 수 있습니다.</li><li>최근 <b>SciSpace</b>에는 <b>논문을 podcast로 만들어주는 기능이 추가</b>된 데서 알 수 있듯, 여러 모델들을 조합하여 활용하는 것으로 보입니다.</li></ul><p><img src="72_scispace_12.jpg" alt="NotebookLlama 개념도"></p><div class="video-container"><iframe src="https://www.youtube.com/embed/PvUHo4Tt1Kw" frameborder="0" loading="lazy" allowfullscreen></iframe></div><h2 id="1-4-맺음말"><a href="#1-4-맺음말" class="headerlink" title="1.4. 맺음말"></a>1.4. 맺음말</h2><ul><li>지금의 SciSpace는 연구의 시작과 끝을 담당하는 <b>종합 AI 도구</b>입니다.</li><li>유사한 기능을 제공하는 여러 도구들과 함께 경쟁하면서 공진화를 하고 있습니다.</li><li>전에 없던 기능이 갑자기 생기기도 하고, 그 과정에서 일부 기능이 불안정하기도 하지만 전반적인 쓰임은 매우 편리하고 안정적입니다.</li></ul><p><img src="72_scispace_13.png" alt="SciSpace"></p><ul><li><b>SciSpace 외의 다른 도구들도 비슷한 양상으로 함께 진화할 것으로 예상됩니다.</b></li><li>이 글은 SciSpace에 대한 소개글이지만, AI 도구의 발전 과정을 보여주는 좋은 예시가 되기를 바랍니다.</li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/SciSpace/">SciSpace</category>
      
      
    </item>
    
    <item>
      <title>AI와 예술 창작 - AI 그림이라는 진지한 취미</title>
      <link>https://jehyunlee.github.io/2024/12/20/General-71_hobbyart/</link>
      <guid>https://jehyunlee.github.io/2024/12/20/General-71_hobbyart/</guid>
      <pubDate>Fri, 20 Dec 2024 12:29:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;김재인 교수님의 주선으로 AI를 도구로 예술을 하는 분들과 같은 자리에 섰습니다.&lt;/li&gt;
&lt;li&gt;내가 끼어도 되는 걸까 싶은 걱정과 이런 분들과 함께 한다는 기대가 공존했습니다.&lt;/li&gt;
&lt;li&gt;말이 토론이었지 오가는 말씀 속에서 많</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>김재인 교수님의 주선으로 AI를 도구로 예술을 하는 분들과 같은 자리에 섰습니다.</li><li>내가 끼어도 되는 걸까 싶은 걱정과 이런 분들과 함께 한다는 기대가 공존했습니다.</li><li>말이 토론이었지 오가는 말씀 속에서 많이 배우고 시야가 크게 넒어지는 느낌을 받았습니다.</li></ul><h1 id="1-발표-전"><a href="#1-발표-전" class="headerlink" title="1. 발표 전"></a>1. 발표 전</h1><h2 id="1-1-김재인-교수님"><a href="#1-1-김재인-교수님" class="headerlink" title="1.1. 김재인 교수님"></a>1.1. 김재인 교수님</h2><blockquote><p><a href="https://armdown.net/">김재인 교수님 블로그</a><br><a href="https://www.youtube.com/watch?v=hb43uA91088">youtube: 기술은 예술의 자원일까? 위협일까? 기술시대의 예술의 미래, 책으로 만나는 AI시대의 예술(김재인 교수)</a><br><a href="https://www.yes24.com/Product/Goods/119019001">yes24: AI 빅뱅</a></p></blockquote><ul><li>살면서 이런 사람들은 절대 만나지 않겠지 하는 부류의 분들은, 만나고서야 아 이런 분들이 있었지 싶습니다.</li><li>그 중 한 부류가 <b>철학자</b>. </li><li>이공계인의 숲에서 살며 간혹 그림그리는 분들과 역사 이야기 하는 분들을 기웃거리는 내게,</li><li>내게 <b>철학자</b>는 아무리 가까워도 데카르트보다 가깝기 힘들고 그 데카르트도 직교좌표계로 더 가깝습니다.</li></ul><div class="video-container"><iframe src="https://www.youtube.com/embed/hb43uA91088" frameborder="0" loading="lazy" allowfullscreen></iframe></div><ul><li>코드와 ppt를 들고 다니다 간혹 그림을 들고 다니던 SNS에서 <b>김재인</b>이라는 이름이 자주 보이기 시작했습니다.</li><li><b>철학자</b>라고 하는데, <b>인공지능</b>이야기를 하시고, 특히 <b>인공지능이 그리는 그림</b>이야기를 하십니다.</li><li>내가 즐겨보는 대상을 완전히 다른 면에서 보는 시각이 신선했고, 덕택에 들뢰즈 같은 이름도 알게 됐습니다.</li><li>이 분의 시야에도 제가 들어왔는지 <a href="https://www.yes24.com/Product/Goods/119019001"><b>저서</b></a>에 추천사를 쓰는 인연도 맺게 됐네요.</li></ul><ul><li>멀리서 존재 정도를 인지하고 있다고 생각했는데, <b>행사에 참여해 달라는 요청을 주셨습니다.</b></li><li><b>감사하다</b>는 마음과 <b>재밌겠다</b>는 생각에 이어 별 생각이 다 들었습니다.</li><li><b>내가 끼어도 되는 자리 맞나</b>, <b>이런 분들이랑 이야기 한번 나눠보고 싶다</b>, <b>어떤 분위기일까</b> 등등.</li><li>흥미와 호기심, 그리고 처음 생긴 종류의 기회는 무조건 잡는다는 생각으로 나갔습니다.</li></ul><h2 id="1-2-발표-준비"><a href="#1-2-발표-준비" class="headerlink" title="1.2. 발표 준비"></a>1.2. 발표 준비</h2><blockquote><p><a href="https://jehyunlee.github.io/2024/01/01/General-35-genAIdraw/">Pega Devlog: AI그림 vs 손그림</a><br><a href="https://aifrenz.org/artist2024">실용인공지능학회: AAiCON2024 생성AI 아티스트 초대전</a></p></blockquote><ul><li>막상 발표하기로 하니 난감하더군요. </li><li>나 혼자 내 멋에 겨워서 노래도 부르고 춤도 출 수 있지만, 무대에 올라가려면 <b>어느 정도 수준</b>이 되지 않으면 민폐입니다.</li><li>그리고 <b>무대의 수준은 자리에 앉아서 들어주시는 청중이 결정합니다.</b></li><li>모르긴 몰라도 예술에 몸담은 분들이 가득할 자리에서 공돌이가 취미로 하는 AI <b>그림 이야기</b>는 깊기 힘듭니다.</li></ul><ul><li>생각을 바꿨습니다.</li></ul><ul><li>그림을 그리는 <b>AI 이야기</b>를 하면 되겠네.</li><li>예술 분야의 <b>청중께는 AI에 가까운 프롬프트 이야기</b>를 들려드리고,</li><li>프롬프트에 <code>멋진 미래 도시</code> 같은 걸 넣고 있을 <b>공돌이 분들께는 그림 이야기</b>를 들려드리면 되겠네.</li><li>그러면 <b>내가 그림을 어떻게 그리는지</b>말씀드리면 되겠네.</li></ul><ul><li><a href="https://aifrenz.org/artist2024"><b>지난 6월 AAiCON2024 생성AI 아티스트 초대전</b></a>에서 발표한 자료를 압축해서 앞쪽에 넣고,</li><li>뒷부분에는 내가 그리는 방식을 정리해서 발표하기로 했습니다.</li></ul><p><img src="71_hobbyart_02.png"></p><h1 id="2-발표내용"><a href="#2-발표내용" class="headerlink" title="2. 발표내용"></a>2. 발표내용</h1><h2 id="2-1-저에게-AI-그림은-취미입니다"><a href="#2-1-저에게-AI-그림은-취미입니다" class="headerlink" title="2.1. 저에게 AI 그림은 취미입니다."></a>2.1. 저에게 AI 그림은 취미입니다.</h2><ul><li>발표 제목을 “AI 그림이라는 진지한 취미”로 잡았습니다.</li><li>그림은 저에게 <b>직업이 아니라 취미입니다.</b></li><li>인생, 가치관, 생계가 걸린 분들과는 입장이 많이 다릅니다.</li><li><b>고통을 인내하며 탐구하고 추구하는 대상이 아니라, 본업에서 전투를 치르고 돌아와 휴식하고 충전하는 곳입니다.</b></li></ul><ul><li><b>그래서, 여기에 에너지를 다 쏟아 저를 불태울 생각은 없습니다.</b></li><li>너무 진지한 고뇌의 대상으로 삼지 않습니다.</li><li>노트 한켠에 끄적이던 낙서가 도구만 바뀐 것입니다.</li><li>저는 <b>단편적인 감정을 배출하고</b>, <b>가끔 귀엽거나 웃긴다고 누군가 공감해주면 감사하지만 기대를 하는 경우는 적습니다.</b></li></ul><ul><li>굳이 이 이야기를 길게 하는 이유는,</li><li>카메라 셔터를 누르는 한 순간을 위해 몇 달을 준비하는 분들이 있고</li><li>한 폭의 그림을 완성하려고 내면의 고독을 고통스럽게 마주해서 잡아 올리는 분들이 있다는 걸 알기 때문입니다.</li><li>이런 분들과 함께 나란히 놓일 작품은 아닙니다.</li></ul><h2 id="2-2-그렇다고-뇌를-비우고-그리지는-않습니다"><a href="#2-2-그렇다고-뇌를-비우고-그리지는-않습니다" class="headerlink" title="2.2. 그렇다고 뇌를 비우고 그리지는 않습니다."></a>2.2. 그렇다고 뇌를 비우고 그리지는 않습니다.</h2><blockquote><p><a href="https://www.te.co.kr/news/article.html?no=23826">더에듀: 네덜란드 교사 노조, 교실 내 AI 사용 지침 명확화 요구</a><br><a href="https://zdnet.co.kr/view/?no=20241219180203">ZDNet Korea: 성능·역량보다 ‘에너지 효율성’ 더 중요해진다…내년 AI 시장 변화 ‘예고’</a><br><a href="https://www.weeklytoday.com/news/articleView.html?idxno=648307">위클리오늘: 서울 성북 VIP 동물병원서 반려동물 사망… 보호자 “병원의 불성실한 치료 때문” 진실은?</a><br><a href="https://news.sbs.co.kr/news/endPage.do?news_id=N1007913885">SBS: 챗GPT로 수능 국어 풀었더니 97점…AI, 만점 도전하나</a></p></blockquote><ul><li><b>아무래도 좋으니 예쁜거 나와라 뚝딱</b>하는 마음으로 그리지는 않습니다.</li><li>내 감정을 담는 것이 목적이라면, <b>내 감정을 최대한 잘 표현하려고 노력합니다.</b></li><li>사람들에게 무슨 말을 걸고 싶다면, <b>그 목소리가 잘 들리게 하려고 노력합니다.</b></li><li>깊은 철학은 없지만 얕으면 얕은대로 정확하게 전달하고 싶다는 뜻입니다.</li></ul><ul><li>그래서 가장 피하는 그림이 <b>아무나 다 그리는 그림</b>입니다.</li></ul><ul><li>언젠가부터 신문기사에 <b>AI가 그린 삽화</b>가 자주 보입니다.</li><li>특히 DALL.E가 그린 그림들이 많은데, <b>특유의 푸른 빛과 번들거림이 너무 싫습니다.</b></li><li>AI 그림이라는 걸 알리려고 일부러 넣은건가 의심될 정도로 부자연스럽습니다.</li><li>좋은 그림을 전달하고 싶다는 생각이 있다면, 이런 색감은 절대로 쓰지 않을 것 같습니다.</li></ul><p><img src="71_hobbyart_03.png" alt="기사 삽입 그림 (더에듀, ZDNet Korea, 위클리오늘, SBS)"></p><ul><li>그리고, AI 그림이 유행함과 동시에 <b>젊은 여성들의 그림들</b>이 곳곳에 걸립니다.</li><li>이런 그림을 그리는 분들은 무언가 본인만의 이유가 있으실 것이라 생각하고 존중하지만,</li><li>적어도 저는 별로 그리고 싶지 않습니다. </li><li>이유는 <b>그냥, 이런 그림들이 이미 충분히 많아서</b>입니다.</li></ul><p><img src="71_hobbyart_04.png" alt="유튜브 영상 썸네일 @NeverlandLatata"></p><ul><li>위가 <b>의도만 앞서서 촌스러운 그림</b>이라면</li><li>아래는 적어도 저로서는 <b>의도를 알 수 없는 그림</b>입니다.</li><li>그림을 그리신 분들에게는 의도가 있겠습니다만 적어도 제겐 저런 그림을 그릴 의도가 떠오르지 않습니다.</li><li>전달하고 싶거나 공감받고 싶은 마음, 표현하고 싶은 감정을 시각적으로 표현하고자 합니다.</li></ul><p><img src="71_hobbyart_05.png" alt="생성 AI 그림 @Jehyun Lee"></p><h2 id="2-3-선을-그었습니다"><a href="#2-3-선을-그었습니다" class="headerlink" title="2.3. 선을 그었습니다."></a>2.3. 선을 그었습니다.</h2><h3 id="2-3-1-즐거움을-잃지-않도록-선을-그었습니다"><a href="#2-3-1-즐거움을-잃지-않도록-선을-그었습니다" class="headerlink" title="2.3.1. 즐거움을 잃지 않도록 선을 그었습니다."></a>2.3.1. 즐거움을 잃지 않도록 선을 그었습니다.</h3><ul><li>그림이라는 취미는 <b>시간</b>이 많이 듭니다.</li><li>손으로 그리건 핸드폰으로 그리건, 털 하나 점 하나에 예민한데, 수천번 터치를 해야 비로소 형체가 드러납니다.</li><li>문제는 현업에 시간을 들이다 보면 <b>그림에 들일 시간이 극히 제한된다는 점</b>입니다.</li></ul><p><img src="71_hobbyart_06.png" alt="폰그림 @Jehyun Lee"></p><ul><li>생성 AI 그림도 마찬가지입니다.</li><li>DALL.E2부터 생성 AI 그림을 수정할 수 있는 기능이 생겼습니다.</li><li><b>inpainting</b>으로 세부를 수정할 수 있고, <b>outpainting</b>으로 영역을 확장할 수 있습니다.</li><li>Stable Diffusion 계열에는 밑그림을 이용할 수 있는 <b>ControlNet</b>이 나와 있습니다.</li><li>이런 기능들을 사용하면 머리 속 그림에 훨씬 더 가까워질 수 있습니다.</li><li>그러나 <b>끝이 없다</b>는 것이 제겐 문제가 됩니다. 시간이 끝없이 드니까요.</li></ul><p><img src="71_hobbyart_07.png" alt="inpainting"></p><ul><li>시간에 쫓기면 의무감이 되고, 즐거움을 잃어버리는 경험은 충분히 했습니다.</li><li>그래서 즐거움을 잃지 않도록 <b>프롬프트로만 그린다</b>는 선을 그었습니다.</li><li>같은 이유로 <b>음악과 동영상도 만들지 않습니다.</b></li><li>관리를 하지 않기 위해 <b>설치형 AI 도구도 사용하지 않습니다.</b></li></ul><h3 id="2-3-2-나를-드러낼-수-있도록-선을-한번-더-그었습니다"><a href="#2-3-2-나를-드러낼-수-있도록-선을-한번-더-그었습니다" class="headerlink" title="2.3.2. 나를 드러낼 수 있도록 선을 한번 더 그었습니다."></a>2.3.2. 나를 드러낼 수 있도록 선을 한번 더 그었습니다.</h3><ul><li><b>생성 AI의 피할 수 없는 특징</b>이 둘 있습니다.</li><li>하나는 <b>학습한 데이터로부터 결과물이 만들어진다</b>는 점이고,</li><li>또 하나는 <b>랜덤한 결과물이 나온다</b>는 점입니다.</li></ul><ul><li>이 두 특징으로 인해 <b>생성 AI 그림을 대하는 태도가 나뉩니다.</b></li><li>원래 그림을 그리지 않던 분들은 생성 AI 그림을 멋지다고 좋아하고,</li><li>원래 그림을 그리던 분들은 마음대로 되지 않는다고 답답해 합니다.</li><li><b>그림을 그리기 전에 떠오른 이미지가 있는가, 그 이미지가 충실히 구현되는가</b>의 차이라 생각됩니다.</li></ul><ul><li><b>잘 모르는 분야일수록 AI의 결과물에 불만이 없어지는 것</b>은 <b>분야와 무관하게 일반적인 현상</b>입니다.</li><li>그리고 이런 분들은 같은 AI를 쓰면서도 좋은 결과를 얻기 위해 노력하는 분들이 있다는 것을 상상하기 어렵습니다.</li></ul><ul><li><b>프롬프트 대충 넣으면 나오는 거 아니야?</b>라는 분도 있고,</li><li><b>베낄 이미지 넣고 그리라고 하면 금방 나오는데?</b>라는 분도 있습니다.</li></ul><ul><li>후처리를 하면서 시간을 많이 들이기는 싫지만, 대충 그리고 싶다는 뜻은 아닙니다.</li><li><b>머리 속에 있는 영상을 글을 통해서 최대한 재현하는 재미</b>를 느끼고자 합니다.</li><li>생성 AI를 사용하지만 <b>남의 그림을 베끼기 싫고</b>, <b>운을 최소화하고 싶습니다.</b></li><li>일반적인 방식으로 그림을 배우는 사람들도 기존 작품들의 영향을 받는 점을 인정합니다.</li><li>인간 화가들도 물감을 뿌리거나 던져서 그림을 그리듯 일부 운에 맡기는 영역이 있습니다.</li><li>기존 데이터와 운의 영향은 딱 여기까지만 받고 싶습니다.</li></ul><p><img src="71_hobbyart_08.png" alt="스스로에게 금기를 걸었습니다."></p><ul><li><b>사전 이미지를 입력하지 않습니다:</b> 대놓고 베끼겠다는 선언으로 느껴집니다.</li><li><b>작가 이름을 입력하지 않습니다: </b> 난 모르겠고 이런 스타일로 해달라는 말 같습니다.</li><li><b>장르 입력은 최소화합니다: </b> 이 정도 영향은 받을 수 있다고 생각하지만, 가급적 피합니다.</li></ul><ul><li>대신 <b>최대한 자세하게 프롬프트를 넣습니다.</b></li><li>제가 사용하는 ChatGPT에 탑재된 DALL.E는 100 단어 가량을 입력받게 되어 있습니다.</li><li>100 단어를 제가 채우지 않으면 자기가 알아서 상상해버립니다.</li><li><b>절대로 GPT나 클로드에게 프롬프트를 만들어 달라고 하지 않습니다.</b></li></ul><ul><li><b>프롬프팅도 영어로 합니다.</b></li><li>시스템 프롬프트를 열어보면 <b>영어가 아니면 영어로 번역하라</b>고 합니다.</li><li>이 과정에서 뉘앙스가 묘하게 달라지는 일을 많이 겪었습니다.</li><li><b>이 표현을 영어로 어떻게 하지?</b> 하고 찾아보는 과정도 하나의 재미입니다.</li></ul><p><img src="71_hobbyart_09.png" alt="내가 넣은 지시보다 셀프로 만든 프롬프트가 더 많으면 이건 누가 그린 걸까요?  "></p><ul><li>seed number에 붙는 랜덤성은 어쩔 수 없습니다. </li><li>아쉽긴 하지만 이 정도는 감수하기로 합니다. </li><li><b>배당된 seed number를 유지할 수 있다는 점</b>을 위안으로 삼습니다.</li></ul><h3 id="2-3-3-생각이나-감정을-시각화하고-이를-말로-바꿉니다"><a href="#2-3-3-생각이나-감정을-시각화하고-이를-말로-바꿉니다" class="headerlink" title="2.3.3. 생각이나 감정을 시각화하고, 이를 말로 바꿉니다."></a>2.3.3. 생각이나 감정을 시각화하고, 이를 말로 바꿉니다.</h3><ul><li>예를 들면 이런 식입니다.</li><li>숨이 막힐 만큼 답답한 날이 있었습니다.</li><li>그래도 어딘가 보이는 실낱같은 희망이 있어서 포기하지 않을 수 있었습니다.</li></ul><ul><li>이를 <b>어둠 속에서 빛을 바라보는 고양이</b>로 시각화했습니다.</li><li>자세한 설정들을 담아 프롬프트를 충분히 길게 작성해서 입력하며 그림을 얻습니다.</li><li>원하는 그림을 기다리며 계속 새로 만들면서 반영이 안되는 구상이 있는지 확인합니다.</li><li>프롬프트를 조금씩 바꿔가면서 원하는 그림으로 다가가다가, <b>최적의 그림을 선택</b>합니다.</li></ul><p><img src="71_hobbyart_10.png" alt="희망"></p><ul><li>손그림과는 달리 랜덤이 작용되기 때문에,</li><li>그리고 학습하지 않은 패턴은 구현되지 않기 때문에 내 머리 속이 100% 옮겨지기는 매우 어렵습니다.</li></ul><ul><li>AI가 내놓는 결과물 중에서 고르는, 일종의 <b>타협</b>이 필요하기도 하고</li><li><b>AI가 뭘 그릴 수 있을지 파악하고 그 안에서 나올 수 있는 결과를 요구하는 이해</b>가 필요하기도 합니다.</li><li>화가가 붓과 물감, 캔버스, 종이를 파악하는 과정과 비슷하다고 생각합니다.</li></ul><h2 id="2-4-저작권-문제"><a href="#2-4-저작권-문제" class="headerlink" title="2.4. 저작권 문제"></a>2.4. 저작권 문제</h2><ul><li>생성 AI 그림 뿐 아니라 글, 음악, 영화에 대한 <b>저작권 이슈</b>가 적지 않습니다.</li><li>생성 AI가 학습한 이미지들에 대한 저작권, 생성 AI 로 만들어진 그림에 대한 저작권이 모두 이슈이고</li><li>생성 AI가 학습한 이미지들에 대해서는 손해배상 소송이,</li><li>생성 AI가 생성한 이미지들에 대해서는 저작권 청구 소송이 이어지고 있습니다.</li></ul><p><img src="71_hobbyart_12.png" alt="생성 AI 그림의 저작권에 대한 의견"></p><ul><li>개인적으로는 <b>생성 AI가 학습한 이미지들에 대한 저작권은 존중되어야 하며</b></li><li><b>생성 AI가 생성한 이미지들도 일부 저작권이 인정될 수 있다</b>고 주장하는 바입니다.</li></ul><ul><li>저작권의 성립 요건에 <b>노동력 투입</b>이 배제되어 있다는 것이 첫번째 이유,</li><li><b>독창성</b>과 <b>사상이나 감정의 명시적 표현</b>이 포함되어 있다는 것이 두번째 이유입니다.</li><li>다만 목소리를 크게 내기는 아직 조심스럽습니다.</li></ul><ul><li><b>생성 AI에 남의 이미지를 업로드해서 만들어진 그림</b>은 독창성을 주장하기 쉽지 않을 것입니다.</li><li><b>남이 만들어준 프롬프트, 특히 AI가 만들어 준 프롬프트</b>를 넣어서 만들어진 그림도 마찬가지입니다.</li><li><b>프롬프트에 시각적인 내용이 없다면, 사상이나 감정을 명시적으로 표현했다고 주장하기 어려울 것</b>입니다.</li><li>하지만 고심해서 넣은 프롬프트로 그린 그림과 대충 넣은 그림은 구분할 수 없습니다.</li><li><b>그림에 담긴 의도</b>에 대한 작가의 설명만이 둘을 가를 수 있습니다. 이 경우 좋은 조수를 부린다고 볼 수 있습니다.</li><li>의도마저 AI에게 설명하라고 하고 이를 읊을 수 있겠지만, 자기 생각이 없다면 여러 작품에 걸친 일관성을 확보하기는 어려울 겁니다.</li></ul><p><img src="71_hobbyart_13.png" alt="조수 @Jehyun Lee"></p><ul><li>그러나, <b>나는 독창적이라고 생각했지만 결과를 보니 무수한 유사작들이 있다면 독창성을 주장하기 어려울 것입니다.</b></li><li>거꾸로 남들이 만든 LoRA를 조합해서 <b>나만의 스타일</b>을 만들었다면 독창성을 확보할 수 있다고 생각합니다.</li><li>말도 안되는 수식이나 랜덤한 글자를 넣어도 그림은 나옵니다. 이런 경우 <b>전위예술</b>에 가까울 수 있다고 생각합니다.</li><li>이런 복잡한 사연들 때문에 저작권을 일률적으로 적용하기는 몹시 어렵겠다는 생각이 듭니다.</li></ul><p><img src="71_hobbyart_14.png" alt="이미지 검색 결과 - 유사 그림의 홍수"></p><h1 id="3-그럼에도-불구하고"><a href="#3-그럼에도-불구하고" class="headerlink" title="3. 그럼에도 불구하고"></a>3. 그럼에도 불구하고</h1><ul><li>제가 그림을 그리는 목적은 돈을 벌기 위한 것이 아닙니다.</li><li>그렇다고 심오한 예술적 가치를 추구하기 위한 것도 아닙니다.</li><li>저작권에 대한 생각을 가끔 하기는 하지만, 그럴듯한 안을 언제까지 작성해서 제출해야 하는 입장에 있지 않습니다.</li></ul><ul><li>제게 그림은 <b>취미</b>입니다.</li><li>누가 시키지 않아도 스스로 하면서 재미를 느끼면 그 뿐입니다.</li><li>가끔 전시회에 참여해 뽐내고 싶은 유치한 마음을 실현하기도 하고,</li><li>울적한 날 우울을 떨치고 쌓인 스트레스를 털어버리며 지인들과 함께 한바탕 웃을 수 있는 소재가 되면 그걸로 족합니다.</li></ul><ul><li>제가 그림을 그릴 때 가장 느끼고 싶은 감정은 <b>자유로움</b>입니다.</li><li>제 그림을 보아 주는 분들이 가낭 느꼈으면 하는 감정은 어떤 형태건 <b>즐거움</b>입니다.</li><li>예술은 이래야 한다, 저래야 한다는 잣대와 무관하게 제가 좋으면 그만인 방식,</li><li>저 혼자 진지하며 만족하는 방식으로 시간을 보내는 것이 제가 그림을 그리는 목적입니다.</li></ul><ul><li>다른 분들도 각자 자신의 목적으로 그림을 그리고, 즐기고 계시리라 믿습니다.</li><li>제가 동의할 수 없는 관점, 저를 동의할 수 없는 관점도 있겠습니다만, 괜찮습니다.</li><li>이 그림은 이래야 한다거나 AI 그림은 이래야 한다고 주장하는 글이 아닌, <b>나는 이렇다</b>는 글이기 때문입니다.</li><li>다만 제가 그림에서 즐거움을 느끼듯, 다른 분들도 다른 형태로라도 그림에서 즐거움을 느끼면 좋겠다는 정도의 소망을 가져봅니다.</li></ul><p><img src="71_hobbyart_15.png"></p><ul><li>발표자료를 공유드립니다 <a href="241206_%EC%9D%B4%EC%A0%9C%ED%98%84_AI%EA%B7%B8%EB%A6%BC%EC%9D%B4%EB%9D%BC%EB%8A%94%EC%A7%84%EC%A7%80%ED%95%9C%EC%B7%A8%EB%AF%B8_blog.pdf">(다운로드)</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/dalle/">dalle</category>
      
      <category domain="https://jehyunlee.github.io/tags/presentation/">presentation</category>
      
      
    </item>
    
    <item>
      <title>인공지능을 활용한 슬기로운 연구생활</title>
      <link>https://jehyunlee.github.io/2024/11/18/General-69_SNU/</link>
      <guid>https://jehyunlee.github.io/2024/11/18/General-69_SNU/</guid>
      <pubDate>Mon, 18 Nov 2024 12:29:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;서울대학교 응용물리연구소의 초청을 받아 대학원생 대상 강의를 드렸습니다.&lt;/li&gt;
&lt;li&gt;생성 AI를 이용한 연구 활용 강의지만, 평소보다 오용에 대한 주의를 몇배 더 강하게 드렸습니다.&lt;/li&gt;
&lt;li&gt;연구를 업으로 삼아야 하는 분들</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>서울대학교 응용물리연구소의 초청을 받아 대학원생 대상 강의를 드렸습니다.</li><li>생성 AI를 이용한 연구 활용 강의지만, 평소보다 오용에 대한 주의를 몇배 더 강하게 드렸습니다.</li><li>연구를 업으로 삼아야 하는 분들입니다. 기술은 바뀌더라도 남을 마인드가 중요하다고 생각했습니다.</li></ul><h2 id="인공지능을-활용한-슬기로운-연구생활"><a href="#인공지능을-활용한-슬기로운-연구생활" class="headerlink" title="인공지능을 활용한 슬기로운 연구생활"></a>인공지능을 활용한 슬기로운 연구생활</h2><blockquote><p><a href="241118_%EC%9D%B4%EC%A0%9C%ED%98%84_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9D%84%ED%99%9C%EC%9A%A9%ED%95%9C%EC%8A%AC%EA%B8%B0%EB%A1%9C%EC%9A%B4%EC%97%B0%EA%B5%AC%EC%83%9D%ED%99%9C.pdf"><b>강의자료 다운로드 (219 pages)</b></a></p></blockquote><ul><li>기존 발표와 달리 <b>7개의 질문</b>으로 발표를 구성했습니다.</li><li>그간 여러 발표를 하면서 청중에게 들었던 질문들,</li><li>그리고 관련 일들을 하면서 스스로 가진 질문들입니다.</li></ul><ul><li><b>각 장을 질문으로 열고 답변으로 닫았습니다.</b></li><li>열리고 닫히는 사이에는 최대한 <b>예시</b>를 중심으로 담고자 했습니다.</li><li>직접 경험을 담을 수 없다면 <b>관련 논문</b>을 찾아 소개했습니다.</li><li>생성 AI는 완성품이 아니고, 아직 빠르게 진화하고 있는 중간 제품입니다.</li></ul><ul><li>개발자들조차 파악하지 못하는 특징들이 많기 때문에 <b>커뮤니티를 통한 경험의 공유가 가장 소중합니다.</b></li><li>3시간이라는 짧지 않은 강의 시간을 꽉 채워서 전달했음에도 불구하고 디테일이 적지 않게 생략되었습니다.</li><li>아쉽기도 하지만, <b>어차피 개인의 경험으로 채워야 합니다.</b></li></ul><h2 id="Q1-생성AI를-연구에-활용해도-되나요"><a href="#Q1-생성AI를-연구에-활용해도-되나요" class="headerlink" title="Q1. 생성AI를 연구에 활용해도 되나요?"></a>Q1. 생성AI를 연구에 활용해도 되나요?</h2><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_009.png" alt="조심할 것들이 많습니다."></p><ul><li>생성 AI를 연구에 사용해도 됩니다.</li><li>그런데 제대로 알고 써야 합니다.</li></ul><h3 id="Q1’-뭘-알고-써야-하나요"><a href="#Q1’-뭘-알고-써야-하나요" class="headerlink" title="Q1’. 뭘 알고 써야 하나요?"></a>Q1’. 뭘 알고 써야 하나요?</h3><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_022.png" alt="디아블로의 영혼석을 감당하지 못하면 디아블로가 됩니다."></p><ul><li><b>생성 AI의 능력과 한계</b>를 알고 써야 합니다.</li><li>그리고 <b>나의 능력과 한계</b>를 알고 써야 합니다.</li></ul><h3 id="Q2-생성-AI는-왜-이상한-답을-하나요"><a href="#Q2-생성-AI는-왜-이상한-답을-하나요" class="headerlink" title="Q2. 생성 AI는 왜 이상한 답을 하나요?"></a>Q2. 생성 AI는 왜 이상한 답을 하나요?</h3><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_030.png" alt="생성 AI는 호모 사피엔스를 닮았습니다."></p><ul><li>자기가 하는 답이 이상한 줄 모릅니다.</li><li>정확히는, <b>자기가 무슨 말을 하는 줄 모릅니다.</b></li></ul><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_040.png" alt="ChatGPT에게 하는 질문은 시간 낭비일 수 있습니다."></p><ul><li>그러면서 여기저기 눈치를 보느라 뻔한 답을 합니다.</li></ul><h3 id="Q2’-빅데이터를-학습했다면서요"><a href="#Q2’-빅데이터를-학습했다면서요" class="headerlink" title="Q2’. 빅데이터를 학습했다면서요?"></a>Q2’. 빅데이터를 학습했다면서요?</h3><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_046.png" alt="답을 하기 전에 재료를 찾아봅니다."></p><ul><li>당신은 배운 걸 다 기억하십니까?</li><li>생성 AI도 모르면 찾아보게 해줄 수 있습니다.</li><li><b>생성 증강 검색 - RAG: Retrieval Augmented Generation</b>이라는 기술입니다.</li></ul><h3 id="Q2’’-자기가-뱉은-말-다시-생각도-안합니까"><a href="#Q2’’-자기가-뱉은-말-다시-생각도-안합니까" class="headerlink" title="Q2’’. 자기가 뱉은 말 다시 생각도 안합니까?"></a>Q2’’. 자기가 뱉은 말 다시 생각도 안합니까?</h3><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_052.png" alt="포기하기 전에 목표와 행동을 반성합니다."></p><ul><li>생성 AI는 억울합니다. 생각할 기회도 받지 못했습니다.</li><li>자기가 뭘 하는지 살펴보게 하면 오류가 줄어듭니다.</li><li><b>자기반성 - Reflexion</b>이라는 기술입니다.</li></ul><h2 id="Q3-RAG도-이렇게-오류가-많은데-AI-쓰는-게-맞나요"><a href="#Q3-RAG도-이렇게-오류가-많은데-AI-쓰는-게-맞나요" class="headerlink" title="Q3. RAG도 이렇게 오류가 많은데 AI 쓰는 게 맞나요?"></a>Q3. RAG도 이렇게 오류가 많은데 AI 쓰는 게 맞나요?</h2><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_057.png" alt="과학, 기술 분야 출판 논문 동향"></p><ul><li>사람이 읽기에는 너무 많은 논문이 쏟아져 나옵니다.</li><li><b>정보량이 인간의 기억을 넘을 때 문자를 쓰기 시작</b>했듯,</li><li><b>정보량이 인간의 사고 능력을 넘는 지금</b> AI를 쓰기 시작해야 합니다.</li></ul><ul><li><b>실보다 득이 많도록 운영을 잘 하셔야 합니다.</b></li></ul><h2 id="Q4-뭔가-많이-어려워-보입니다-환각을-줄이려면-이렇게까지-해야만-하나요"><a href="#Q4-뭔가-많이-어려워-보입니다-환각을-줄이려면-이렇게까지-해야만-하나요" class="headerlink" title="Q4. 뭔가 많이 어려워 보입니다. 환각을 줄이려면 이렇게까지 해야만 하나요?"></a>Q4. 뭔가 많이 어려워 보입니다. 환각을 줄이려면 이렇게까지 해야만 하나요?</h2><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_070.png" alt="생성 AI 환각 억제 방법"></p><ul><li><b>모르면 모른다고 말할 자유</b>를 주세요.</li><li>넘겨짚지 않도록 <b>상황을 정확히 설명</b>하세요.</li><li><b>웹 검색을 하고 출처를 요청</b>하세요.</li><li><b>추론 과정을 단계별로 요청</b>하세요.</li></ul><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_079.png" alt="장점 위주 사용 방법"></p><ul><li><b>할 수 있는 일들을 할 수 있게 하세요.</b></li><li><b>못 하는 일 시키고 못 한다고 구박하지 마세요.</b></li></ul><h2 id="Q5-현-상황에서는-RAG가-최선으로-보입니다-연구비를-들여-개발-의뢰를-해야-하나요"><a href="#Q5-현-상황에서는-RAG가-최선으로-보입니다-연구비를-들여-개발-의뢰를-해야-하나요" class="headerlink" title="Q5. 현 상황에서는 RAG가 최선으로 보입니다. 연구비를 들여 개발 의뢰를 해야 하나요?"></a>Q5. 현 상황에서는 RAG가 최선으로 보입니다. 연구비를 들여 개발 의뢰를 해야 하나요?</h2><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_106.png" alt="생성 AI 활용 도구들"></p><ul><li><b>나와 있는 도구들</b>만 잘 쓰셔도 충분합니다.</li><li><b>무료와 유료의 구독 성능차이</b>가 생각보다 큽니다.</li><li><b>연구비 처리가 가능</b>하니 교수님을 졸라보세요.</li></ul><h2 id="Q6-실제로-어떤-일들을-했나요"><a href="#Q6-실제로-어떤-일들을-했나요" class="headerlink" title="Q6. 실제로 어떤 일들을 했나요?"></a>Q6. 실제로 어떤 일들을 했나요?</h2><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_174.png" alt="공공/연구기관 활용 업무 기준 인공지능 분류"></p><ul><li><b>데이터 분석</b>부터 <b>연구업무 수행</b>까지 다 합니다.</li></ul><h2 id="Q7-당장-GPT밖에-쓰는-게-없는데-이걸로-할-수-있는-게-있나요"><a href="#Q7-당장-GPT밖에-쓰는-게-없는데-이걸로-할-수-있는-게-있나요" class="headerlink" title="Q7. 당장 GPT밖에 쓰는 게 없는데, 이걸로 할 수 있는 게 있나요?"></a>Q7. 당장 GPT밖에 쓰는 게 없는데, 이걸로 할 수 있는 게 있나요?</h2><p><img src="241118_Jehyun_SNU_%ED%8E%98%EC%9D%B4%EC%A7%80_211.png" alt="연구용 GPTs 4형제"></p><ul><li><b>GPTs</b>를 써보세요.</li><li>직접 만드시면 제일 좋고, 있는 걸 쓰셔도 좋아요.</li></ul><blockquote><p><a href="241118_%EC%9D%B4%EC%A0%9C%ED%98%84_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9D%84%ED%99%9C%EC%9A%A9%ED%95%9C%EC%8A%AC%EA%B8%B0%EB%A1%9C%EC%9A%B4%EC%97%B0%EA%B5%AC%EC%83%9D%ED%99%9C.pdf"><b>강의자료 다운로드 (219 pages)</b></a></p></blockquote>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/openai/">openai</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/presentation/">presentation</category>
      
      
    </item>
    
    <item>
      <title>생성AI 활용 학회 발표 준비</title>
      <link>https://jehyunlee.github.io/2024/11/07/General-67_afore2024/</link>
      <guid>https://jehyunlee.github.io/2024/11/07/General-67_afore2024/</guid>
      <pubDate>Thu, 07 Nov 2024 14:29:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;오랜만에 연구 결과를 국제학회에서 발표했습니다.&lt;/li&gt;
&lt;li&gt;일정이 바빴다는 핑계를 댈 수도 있지만 생성 AI의 능력과 그간 쌓인 노하우를 믿었습니다.&lt;/li&gt;
&lt;li&gt;밀도있게 3일 준비해서 발표를 마쳤습니다. 자세하게 말씀드릴 수</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>오랜만에 연구 결과를 국제학회에서 발표했습니다.</li><li>일정이 바빴다는 핑계를 댈 수도 있지만 생성 AI의 능력과 그간 쌓인 노하우를 믿었습니다.</li><li>밀도있게 3일 준비해서 발표를 마쳤습니다. 자세하게 말씀드릴 수는 없지만 노하우를 공유합니다.</li></ul><h1 id="2024-09-14-초록-제출"><a href="#2024-09-14-초록-제출" class="headerlink" title="2024.09.14. - 초록 제출"></a>2024.09.14. - 초록 제출</h1><blockquote><p><a href="https://www.elsevier.com/products/scopus/content">Scopus: Scopus content</a></p></blockquote><h2 id="1-결론은-가지고-시작"><a href="#1-결론은-가지고-시작" class="headerlink" title="(1) 결론은 가지고 시작"></a>(1) 결론은 가지고 시작</h2><ul><li>여러 이유가 겹쳐 지난 1년간 연구 결과를 발표하지 못했습니다.</li><li>오랜만에 학회에 발표할 기회가 생겼으나 초록 제출 기한이 매우 촉박했습니다.</li><li>큰 결론은 기존 업무를 수행하며 알고 있었기 때문에 <b>초록을 작성하기 위한 최소한의 지식을 정리할 필요가 있었습니다.</b></li></ul><h2 id="2-대량의-논문에서-필요한-논문들-선별"><a href="#2-대량의-논문에서-필요한-논문들-선별" class="headerlink" title="(2) 대량의 논문에서 필요한 논문들 선별"></a>(2) 대량의 논문에서 필요한 논문들 선별</h2><ul><li><b>저희 분야에서 논문에 쓰일 만한 지식은 일반 검색 엔진에서 찾기 어렵습니다.</b></li><li>공개된 데이터를 잘 찾아주는 <code>perplexity</code>등의 도구들이 많이 나와 있지만,</li><li>라이선스를 확보하고 논문을 검색해야 하는 scopus 등 데이터베이스를 이용해야 하기 때문에 다른 방법을 찾아야 합니다.</li><li>다행히 <b>Scopus API</b>를 사용할 수 있는 환경을 구축해 두었습니다.</li></ul><p><img src="67_AFORE2024_01.png" alt="Scopus API"></p><ul><li><b>Scopus API로 초록을 대량으로 확보</b>하고,</li><li><b>RAG</b>를 사용해 관심사에 가까운 정보들을 수집하여 정리하는 시스템을 보유하고 있습니다.</li><li>확보한 대량의 데이터로는 <b>경향성을 확인</b>하고 읽어야겠다 싶은 논문은 PDF를 내려받아 읽습니다.</li></ul><h2 id="3-그림으로-내용-파악"><a href="#3-그림으로-내용-파악" class="headerlink" title="(3) 그림으로 내용 파악"></a>(3) 그림으로 내용 파악</h2><ul><li>PDF 파일은 정독하기 전에 <b>그림부터 봅니다.</b></li></ul><p><img src="67_AFORE2024_02.png" alt="Acrobat PDF viewer"></p><ul><li>생성 AI가 나오기 전부터 갖고 있던 습관이지만 그림부터 보는 데는 몇 가지 이유가 있습니다.</li></ul><p><b>1. 논문을 쓸 때 그림부터 순서대로 정리합니다.</b></p><ul><li>어떤 그림들이 들어가야 할 지 설계하고, 이 그림들을 그리면서 논리 전개를 고민합니다.</li><li>그렇기 때문에 그림만 제대로 보아도 논문의 중요한 내용들을 파악할 수 있습니다.</li></ul><p><b>2. 그림에 많은 정보가 담겨 있을 뿐 아니라 인지가 빠릅니다.</b></p><ul><li>현미경 사진이나 중요한 그래프는 그림 속에 중요 정보를 모두 담고 있습니다.</li><li>대개 그림에 담긴 정보는 글에도 써 있기 마련이지만 같은 정보를 그림으로 보는 것이 수 배 빠릅니다.</li></ul><ul><li>그림으로 내용을 대강 파악했다면 <code>논문봇</code>을 사용해 전체적인 가치를 판단합니다.</li><li>여기서 가치는 논문이 가지는 절대적인 가치(if any)가 아니라 나에게 도움이 되는지 여부입니다.</li><li><b>불필요하다면 과감하게 버립니다.</b> 읽어야 할 논문은 어차피 많습니다.</li></ul><ul><li>많은 분들이 오해하십니다만, <b>논문봇은 논문을 읽기 위한 도구가 아닙니다.</b></li><li><b>논문봇은 버릴 논문을 선별할 때 쓰기 위한 도구입니다.</b></li></ul><h2 id="4-필요-부분-정독"><a href="#4-필요-부분-정독" class="headerlink" title="(4) 필요 부분 정독"></a>(4) 필요 부분 정독</h2><ul><li>버릴 논문을 버렸다면 읽을 논문을 읽을 차례입니다.</li><li><b>모든 글자를 빠짐없이 읽기엔 시간은 적고 할 일은 많습니다.</b></li><li><code>scispace</code>, <code>notebooklm</code> 등의 도구를 사용해 내용을 파악합니다.</li><li><b>논문 파일을 올려서 그림을 중심으로 파악한 내용들을 질문합니다.</b></li></ul><p><img src="67_AFORE2024_03.png" alt="scispace"></p><ul><li><code>scispace</code>나 <code>notebooklm</code>은 답변과 함께 레퍼런스 링크를 줍니다.</li><li>이 링크를 클릭하면 입력한 본문 중 답변을 인용한 부분이 하이라이트됩니다.</li><li>문서를 올리고 질문을 해도 <b>환각이 발생할 확률이 있기 때문에 검증이 매우 중요합니다.</b></li></ul><ul><li>이제 논문을 머리로 정리할 필요가 있습니다.</li><li><b>눈을 감고 내용들을 머리로 정리</b>해 보아도 좋고,</li><li><b>백지와 펜을 들고 그림을 그리며 정리</b>를 해 보는 것도 좋습니다.</li><li>무엇이건 <b>AI의 도움을 받지 않고 내 머리로 정리하는 것이 중요합니다.</b></li></ul><p><img src="67_AFORE2024_04.png" alt="사색"></p><ul><li>함께 이야기를 나눌 동료가 있다면 더 좋습니다.</li><li>그 과정에서 허점이 발견되기 더 쉽기 때문입니다.</li></ul><h2 id="5-초록-작성"><a href="#5-초록-작성" class="headerlink" title="(5) 초록 작성"></a>(5) 초록 작성</h2><ul><li>이 정도 되면 초록에 담길 내용이 정리됩니다. </li><li>파이썬이나 R, 엑셀 중 원하는 도구를 써도 되지만 <code>플랏봇</code>도 써볼 만 합니다.</li><li><code>ChatGPT</code>나 <code>Claude</code>에 내용을 개조식으로 넣고 글을 작성해달라고 합니다.</li></ul><ul><li>중요한 점이 있습니다.</li><li><b>AI가 작성한 문장을 의도적으로 모두 바꾸는 것</b>입니다.</li><li>직접 살펴보며 흡족하지 못한 문장을 바꾸어도 되지만, <code>DeepL</code>과 같은 도구를 사용해도 좋습니다.</li><li>자동으로 번역된 문장을 보면서 이 중 하나를 선택하는 과정을 통해 <b>스스로 생각하는 기회</b>를 가질 수 있습니다.</li></ul><ul><li><b>수정을 반복하며 <code>딴지봇</code>에게 검사를 요청합니다.</b></li><li>딴지봇에 특별한 대단한 지식이 들어있지는 않지만 논리적 허점을 찾아 반박해주는 기능이 있습니다.</li><li>딴지봇이 지적한 허점이 진짜 허점인지 스스로 고민해 보고, 타당하다고 생각되면 수정합니다.</li></ul><h1 id="2023-11-05-06-화-수-발표-준비-Day-1-2"><a href="#2023-11-05-06-화-수-발표-준비-Day-1-2" class="headerlink" title="2023.11.05-06 (화-수) - 발표 준비 Day 1-2"></a>2023.11.05-06 (화-수) - 발표 준비 Day 1-2</h1><h2 id="6-그림모음-ppt-준비"><a href="#6-그림모음-ppt-준비" class="headerlink" title="(6) 그림모음 ppt 준비"></a>(6) 그림모음 ppt 준비</h2><ul><li>발표 준비를 할 때 가장 처음 할 일은 <b>빈 파워포인트 파일을 만드는 것</b>입니다.</li><li>발표에 사용할 그림들을 하나씩 준비하면서 파워포인트 파일에 추가합니다.</li></ul><p><img src="67_AFORE2024_05.png" alt="그림모음 ppt"></p><ul><li>일단은 <b>내 머리 속에 있는 논리를 꺼내놓는 데 집중합니다.</b></li><li>그러려면 데이터를 분석하고 그림을 그리는 코드도 마구잡이로 짜면 곤란합니다.</li><li><b><code>플랏봇</code>을 비롯해 <code>GPT</code>, <code>Claude</code>에게 너무 의존하면 코드가 중구난방이 됩니다.</b></li><li>코딩 AI를 쓰지 말라는 말씀이 아닙니다. 기왕이면 <code>cursor.AI</code> 같은 전용 도구를 쓰는 것이 여러 모로 더 좋습니다.</li></ul><p><img src="67_AFORE2024_06.png" alt="cursor.AI"></p><ul><li>중간중간 <b>markdown cell</b>을 넣으면서 목차도 만듭니다. 전에 짰던 코드를 되짚을 때 좋습니다.</li><li><b>두 번 쓰인다 싶은 기능은 함수로 만듭니다.</b> 작성되는 코드는 반드시 수정되기 때문에 함수가 좋습니다.</li><li><b>함수가 쌓이면 라이브러리로 만듭니다.</b> 메인 코드가 엄청나게 짧아집니다.</li><li>그래프를 파일로 출력해도 좋지만, 파일명 지옥에 빠질 수 있습니다. 저는 꼭 필요한 것이 아니면 웬만하면 복붙합니다.</li></ul><p><img src="67_AFORE2024_07.png" alt="색상표"></p><ul><li>데이터 시각화에서 <b>색상(hue)은 단어에 해당됩니다.</b></li><li>특정 데이터에 대응되는 특정 색상이 있다면 전달력이 강해지고 보기에도 좋습니다.</li><li>자주 사용되는 색에 이름을 붙이면 좋습니다. <b>dictionary</b>를 저장하면 꺼내 쓰기 좋습니다.</li></ul><ul><li><b>명도(lightness)는 데이터의 크기에 해당됩니다.</b></li><li>데이터가 크면 밝은 색, 데이터가 작으면 어두운 색으로 칠하면 직관적으로 데이터를 느낄 수 있습니다.</li><li><b>채도(saturation)는 데이터의 중요도에 해당됩니다.</b></li><li>중요한 데이터는 채도를 높게 칠하고, 중요하지 않은 데이터는 채도를 낮게 칠합니다.</li><li>색상으로 표현해야 할 데이터가 많아 구분이 어려울 때 채도를 함께 조절해주면 숨통이 트입니다.</li></ul><p><img src="67_AFORE2024_08.png" alt="ppt에 붙인 그림"></p><ul><li>이렇게 그려진 그림들은 ppt에 차곡 차곡 붙여 넣습니다.</li><li>이 때, 기왕이면 <b>최종적으로 발표될 장면들을 생각하면서 정리하면 좋습니다.</b></li><li>그림 설명도 발표에 사용하는 폰트와 크기를 이용해 붙여 넣고, 이에 따라 종횡비도 미리 지정합니다.</li><li>저는 16:9 비율 슬라이드를 사용합니다. </li><li>그림 크기를 (20, 10)으로 지정하면 상단에 제목이 들어갈 공간이 남고 글자 크기도 적절합니다.</li></ul><h2 id="7-설명자료-준비"><a href="#7-설명자료-준비" class="headerlink" title="(7) 설명자료 준비"></a>(7) 설명자료 준비</h2><ul><li>머리 속에 마련된 시나리오에 따라 발표자료를 준비하다 보면 <b>확인할만한 정보</b>가 떠오릅니다.</li><li>근거를 강화시켜 줄 레퍼런스가 필요한 경우도 있고, 추가적인 설명이 필요한 경우도 있습니다.</li><li>이럴 때 사용하는 것이 <b>설명자료</b>이며 <code>perplexity</code>를 사용하면 빠르게 확보할 수 있습니다.</li></ul><p><img src="67_AFORE2024_09.png" alt="perplexity 화면 캡처"></p><ul><li><code>perplexity</code>의 library 항목에 가면 과거에 질의한 내역을 모두 볼 수 있습니다.</li><li>그러나 작업을 하다 보면 비슷한 질의를 많이 하게 되어 이 중 어떤 것인지 혼동됩니다.</li><li>또한, 눈에 보이지 않으면 내가 그런 정보를 수집했는지조차 잊어버릴 때가 많습니다. 너무 많은 자료를 검색하니까요.</li><li>이럴 때를 대비하여 <b>쓸만한 답변들을 ppt에 함께 붙여둡니다. 가능한 큰 그림으로요.</b></li></ul><p><img src="67_AFORE2024_10.png" alt="레퍼런스 캡처"></p><ul><li><code>perplexity</code> 답변만 볼 것이 아니라 <b>레퍼런스를 클릭하여 직접 확인해보는 것이 좋습니다.</b></li><li>드물기는 하지만 레퍼런스 자체가 텅 비어 있는 경우가 있기도 하고 - 이럴 때는 답변을 쓰지 않는 것이 좋습니다.</li><li>레퍼런스를 따라 들어가면 <b><code>perplexity</code> 답변보다 좋은 정보를 얻을 수 있을 때가 많습니다.</b></li><li>다른 이들의 자료를 인용할 때는 종류가 무엇이건 출처를 명확히 표기합니다.</li></ul><h1 id="2023-11-07-목-발표-준비-Day-3-amp-발표-당일"><a href="#2023-11-07-목-발표-준비-Day-3-amp-발표-당일" class="headerlink" title="2023.11.07 (목) - 발표 준비 Day 3 &amp; 발표 당일"></a>2023.11.07 (목) - 발표 준비 Day 3 &amp; 발표 당일</h1><h2 id="8-스토리텔링"><a href="#8-스토리텔링" class="headerlink" title="(8) 스토리텔링"></a>(8) 스토리텔링</h2><ul><li>이틀 정도를 꼬박 투자하면서 행정업무도 처리하고, 회의도 들어가고, 전화도 받았습니다.</li><li><b>발표 준비가 웬만큼 진행된다고 느껴지지만 스토리가 나온다고 보기는 어려운 상황입니다.</b></li><li>할 말을 다 한다고 좋은 발표는 아니라고 생각합니다.</li><li><b>슬라이드 쇼</b>를 하는 발표자로서 <b>청중의 이목을 붙잡아 둘 요소</b>가 필요합니다.</li><li>저는 개그가 정말 중요하다고 생각합니다.</li></ul><p><img src="67_AFORE2024_11.png" alt="발표에 동원된 개그짤"></p><ul><li>딱딱하기 딱 좋은 발표에 등장하는 개그는 여러 효능이 있습니다.</li><li><b>청중이 자발적으로 집중</b>하도록 만들고, </li><li><b>어려울 수 있는 내용이 쉽게 느껴지도록 착각</b>을 불러 일으킵니다.</li><li><b>청중과 연사의 감정이 동조</b>되면서 이해도가 좋아지기 때문입니다.</li></ul><ul><li>그렇다고 뜬금없이 몸개그를 할 수는 없는 노릇입니다.</li><li><b>전체적인 스토리에 잘 녹아들면서 뼈가 있는 개그를 선호합니다.</b></li><li>잠시 웃고 정색하며 발표로 넘어가기 좋기 때문입니다.</li></ul><h2 id="9-데이터-밖에서-인사이트-가져오기"><a href="#9-데이터-밖에서-인사이트-가져오기" class="headerlink" title="(9) 데이터 밖에서 인사이트 가져오기"></a>(9) 데이터 밖에서 인사이트 가져오기</h2><ul><li>데이터 분석을 중심으로 발표를 하다 보면 <b>얻고 싶은 답이 보이지 않을 때가 많습니다.</b></li><li>정상입니다. 여러 요인들이 교차하는 가운데 사건이나 문제가 발생하고, 이들의 단편이 데이터이기 때문입니다.</li><li>데이터를 이용해서 현상을 설명하기엔 좋지만 충분한 인사이트를 주기에는 부족할 때가 많습니다.</li><li>데이터 밖으로 눈을 돌려 <b>이 사건이나 문제가 발생한 원인</b>을 짚어보는 것이 필요할 때가 있습니다.</li></ul><p><img src="67_AFORE2024_13.png" alt="88 페이지 분량 보고서"></p><ul><li>이런 추가 정보 소스가 분량이 많을 때가 또 한번의 고비가 됩니다.</li><li>특히 내가 원하는 답이 있음이 분명한 소스를 찾았을 때, 무시할 수도 없고 읽기는 버거운 상황이 발생합니다.</li><li>제가 접한 여러 도구 중 <b><code>NotebookLM</code>만큼 이럴 때 도움이 되는 것이 없는 듯 합니다.</b></li></ul><p><img src="67_AFORE2024_12.png" alt="NotebookLM"></p><ul><li><code>NotebookLM</code>은 대량의 문서를 넣고 질의응답을 하기도 좋지만,</li><li>긴 문서를 남녀 두 사람이 진행하는 podcast처럼 만들어주는 기능이 매우 강력합니다.</li><li><b>Audio Overview</b> 라고 하며 특히 고속버스나 비행기, 운전 등 장기간 이동을 할 때 유리합니다.</li><li><b>귀에 관련 정보를 계속 흘려보내줄 수 있기 때문</b>이며 원본 문서가 길 수록 이 기능이 더욱 강력해집니다.</li></ul><ul><li>현재는 영어밖에 지원하지 않지만 영어로 발표해야 하는 국제학회라면 오히려 좋습니다.</li><li>대화 속에 좋은 영어 표현들이 다수 담겨있거든요.</li></ul><p><img src="67_AFORE2024_14.jpg" alt="귀로 듣고 눈으로 보며 정리한 메모"></p><p><img src="67_AFORE2024_15.png" alt="메모를 정리한 ppt 슬라이드"></p><ul><li>다만, 늘 그렇지만 이런 <b>요약본을 곧이곧대로 쓰면 곤란합니다.</b></li><li>환각이 끼어들 여지가 너무나 많기 때문에 내용 파악용으로만 사용해야 합니다.</li><li>다시 메모지를 펴고 이어폰을 꽂은 채 원본 문서에서 관련 내용을 탐색하며 확인합니다.</li><li>그리고 원본과 오디오에서 정리된 양식과 다르게, <b>나만의 시각으로 ppt에 정보를 재구성합니다.</b></li></ul><ul><li>무대에 올라 발표를 하는 시점에서 이 <b>모든 자료와 내 말에 대한 책임은 스스로 져야 합니다.</b></li><li>진정성을 담아 발표할 수 있도록, 그리고 발표하는 만큼은 암기가 아니라 이해를 할 수 있도록 준비해야 합니다.</li><li>생성AI는 좋은 도구이지만 <b>내가 생성AI를 통제하지 못하면, 생성AI가 나를 통제합니다.</b></li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/openai/">openai</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/notebooklm/">notebooklm</category>
      
      
    </item>
    
    <item>
      <title>한국에너지기술연구원 진로 티처 - AI계산과학</title>
      <link>https://jehyunlee.github.io/2024/11/04/General-68_kierinterview/</link>
      <guid>https://jehyunlee.github.io/2024/11/04/General-68_kierinterview/</guid>
      <pubDate>Mon, 04 Nov 2024 14:29:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;제가 근무하는 한국에너지기술연구원에서 진행하는 진로 티처 영상에 참여하였습니다.&lt;/li&gt;
&lt;li&gt;AI·계산과학이라는 분야에 대해 소개하는 영상으로,&lt;/li&gt;
&lt;li&gt;저 외에 공정/엔지니어링 분야의 박정호 박사님, 배터리 소재의 AI 적</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>제가 근무하는 한국에너지기술연구원에서 진행하는 진로 티처 영상에 참여하였습니다.</li><li>AI·계산과학이라는 분야에 대해 소개하는 영상으로,</li><li>저 외에 공정/엔지니어링 분야의 박정호 박사님, 배터리 소재의 AI 적용을 연구하는 이찬우 박사님이 참여했습니다.</li></ul><h3 id="한국에너지기술연구원-에너지AI·계산과학실"><a href="#한국에너지기술연구원-에너지AI·계산과학실" class="headerlink" title="한국에너지기술연구원 에너지AI·계산과학실"></a>한국에너지기술연구원 에너지AI·계산과학실</h3><blockquote><p><a href="https://www.kier.re.kr/board?menuId=MENU01040&siteId=null">한국에너지기술연구원 에너지AI·계산과학실</a></p></blockquote><ul><li>출연연마다 AI 조직을 다른 형식으로 운영하고 있습니다.</li><li>한국에너지기술연구원은 <b>연구부서별로 AI 역량이 있는 인력을 채용하여 운영</b>하는 한편,</li><li><b>에너지AI·계산과학실을 통해 연구원 전 부서의 AI·계산과학 역량을 강화</b>하고 있습니다.</li></ul><ul><li>에너지AI·계산과학실은 이름처럼 <b>AI와 계산과학을 모두 담당</b>합니다.</li><li><b>원자단위 전산모사</b>, <b>전산유체역학(CFD)</b>, <b>공정/엔지니어링</b>, <b>데이터/AI</b>분야의 전문가들로 구성되어,</li><li>적은 인원이지만 원내 수십 개의 연구과제의 참여하여 공동연구를 수행합니다.</li></ul><p><img src="68_kierinterview_01.png" alt="에너지AI·계산과학실"></p><ul><li>연구원에서 <b>진로 티처</b>라는 프로그램으로 우리가 수행하는 업무를 설명하는 기회를 가졌습니다.</li></ul><div class="video-container"><iframe src="https://www.youtube.com/embed/0cLKAVc3r_A" frameborder="0" loading="lazy" allowfullscreen></iframe></div><ul><li>제가 드리고자 한 메시지는 다음과 같습니다.</li><li><b>본인의 데이터를 스스로 분석해서 인사이트를 도출하는 역량은 연구원의 기본기입니다.</b></li><li>심리적 장벽을 넘어 본인의 세계를 넓히시기 바랍니다.</li></ul><p><img src="68_kierinterview_02.png"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/youtube/">youtube</category>
      
      <category domain="https://jehyunlee.github.io/tags/KIER/">KIER</category>
      
      
    </item>
    
    <item>
      <title>태재미래교육포럼 - 실용적 AI 업무 활용 방안</title>
      <link>https://jehyunlee.github.io/2024/10/15/General-70_Taejae/</link>
      <guid>https://jehyunlee.github.io/2024/10/15/General-70_Taejae/</guid>
      <pubDate>Tue, 15 Oct 2024 12:29:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;“교육의 미래: 사라지는 것과 생겨나는 것”이라는 주제로 태재미래교육포럼이 열렸습니다.&lt;/li&gt;
&lt;li&gt;교육에 대해 고민하는 많은 연사들의 발표 가운데, 저도 평소의 고민을 담아 한 말씀을 드렸습니다.&lt;/li&gt;
&lt;li&gt;“안경을 쓴다고 </description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>“교육의 미래: 사라지는 것과 생겨나는 것”이라는 주제로 태재미래교육포럼이 열렸습니다.</li><li>교육에 대해 고민하는 많은 연사들의 발표 가운데, 저도 평소의 고민을 담아 한 말씀을 드렸습니다.</li><li>“안경을 쓴다고 눈이 좋아지지 않듯, AI를 쓴다고 스스로의 역량이 강화되지 않습니다. 별도의 노력이 필요합니다.”</li></ul><h3 id="실용적-AI-업무-활용-방안"><a href="#실용적-AI-업무-활용-방안" class="headerlink" title="실용적 AI 업무 활용 방안"></a>실용적 AI 업무 활용 방안</h3><blockquote><p><a href="https://www.ancient-origins.net/news-evolution-human-origins/scientists-are-alarmed-shrinking-human-brain-001446">ancient origins: Scientists are alarmed by shrinking of the human brain</a><br><a href="https://doi.org/10.1002/ajpa.22476">Liu et al., American Journal of Physical Anthropology (2014) DOI: 10.1002/ajpa.22476</a></p></blockquote><ul><li>아직 많은 분들이 23년 봄에 언론을 뒤덮은 ChatGPT를 기억하고 계십니다.</li><li><b>빅데이터를 학습해서 무슨 질문을 해도 답을 하는 차세대 검색엔진</b>이라는 맹신입니다.</li><li>반면 조금 고민하면서 써 보신 분들은 <b>말은 재밌게 하는데, 거짓말도 잘 하는, 그래서 실전에는 쓸모가 없는 녀석</b>이라는 실망으로도 기억하십니다.</li></ul><ul><li><b>맹신은 틀렸고 실망은 맞습니다.</b></li><li>그러나 지금의 ChatGPT를 비롯한 AI들은 실망으로 그치지 않습니다.</li><li>실질적 <b>추론 능력</b>을 상당 수준으로 탑재하고 있고 <b>웹 검색</b>을 해서 정보를 찾아보기도 합니다.</li><li>그리고 스스로 코드를 실행하기도 하고 남의 코드와 API 형태로 엮여서 더 강력해졌습니다.</li></ul><div class="video-container"><iframe src="https://www.youtube.com/embed/WpQt0x86A5M" frameborder="0" loading="lazy" allowfullscreen></iframe></div><ul><li>어떤 분들께서는 말씀하십니다.</li><li><b>생성 AI를 통해서 인간의 능력이 강화된다</b>고요.</li><li>또 어떤 분들께서는 말씀하십니다.</li><li><b>생성 AI를 쓰다 보면 사고 능력을 잃어버릴 수 있다</b>는 말씀입니다.</li></ul><ul><li><b>둘 다 맞다고 생각합니다.</b></li><li>결과적으로는 역량이 강화되지만 육체의 능력은 약화됩니다.</li><li>저는 눈이 나빠서 <b>안경</b>을 씁니다.</li><li>눈이 나쁜 저도 안경을 쓰면 글자도 잘 볼 수 있고 반찬도 집어먹을 수 있습니다.</li><li>그렇지만 안경을 오래 썼다고 시력이 좋아지진 않습니다.</li></ul><ul><li><b>신체 능력을 도구에 의탁함으로써 강해진다면</b></li><li>안경을 오래 썼으니 <b>시력이 좋아져야</b> 하고,</li><li>대중교통을 포함한 차를 오래 탔으니 <b>걷기와 달리기 능력은 강해져야 하며,</b></li><li>전화번호를 휴대폰에 저장한 지 오래니 <b>웬만한 전화번호는 다 외워야 합니다.</b></li><li>하지만 현실은 그 반대입니다. </li><li><b>눈은 여전히 나쁘고, 몸에는 살이 찌고, 자주 전화하는 동료의 번호도 외우지 못합니다.</b></li></ul><p><img src="70_Taejae_brain.jpg" alt="Scientists are alarmed by shrinking of the human brain"></p><ul><li><b>인간 개개인의 신체능력은 원시시대에 가장 강했다</b>는 말이 있습니다.</li><li>정확히 말하면, 신체능력이 약한 사람들은 원시시대에서는 살아남을 수 없었을 겁니다.</li><li>제가 안경을 벗고 원시로 간다면 곰에게 잡혀먹히거나, 사냥을 못해서 굶어 죽었을 테니까요.</li><li>이렇게 나약한 저도 <b>생존할 수 있게 해 주는 것이 문명</b>입니다.</li></ul><p><img src="70_Taejae_kangaroo.jpg" alt="살아남은 자가 강한 것이다. (c)BBC"></p><ul><li>시력 저하를 막기 위해 <b>당근과 루테인을 먹고</b></li><li>비만으로 가는 몸뚱이를 조금이라도 정상으로 돌리고자 <b>헬스장에 갑니다.</b></li><li>알던 한자가 갑자기 생각이 안나면 <b>재빨리 검색해서 손으로 써 봅니다.</b></li></ul><ul><li><b>업무에는 AI를 활용</b>해서 생산성을 높이고,</li><li>이렇게 확보한 시간에 <b>독서, 사색, 토론, 예술 감상</b>을 해야 합니다.</li><li>생각한 바를 친우들과 나누며 함께 영혼을 키워나가기를 희망합니다.</li></ul><p><img src="70_Taejae_photo.jpg" alt="연사들 기념 사진"></p><p><img src="70_Taejae_speakers.jpg" alt="연사 목록"></p><p><img src="70_Taejae_program_%ED%8E%98%EC%9D%B4%EC%A7%80_1.png"></p><p><img src="70_Taejae_program_%ED%8E%98%EC%9D%B4%EC%A7%80_2.png" alt="Program"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/openai/">openai</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/presentation/">presentation</category>
      
      
    </item>
    
    <item>
      <title>EOST2024 - 연구 현장의 생성 AI 활용 현황</title>
      <link>https://jehyunlee.github.io/2024/10/15/General-65_EOST2024/</link>
      <guid>https://jehyunlee.github.io/2024/10/15/General-65_EOST2024/</guid>
      <pubDate>Tue, 15 Oct 2024 09:11:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;ETRI Open Source Tech Day 2024에서 발표를 드렸습니다.&lt;/li&gt;
&lt;li&gt;2017년에 알파고가 전지전능의 대명사였던 것처럼, 최근에는 생성AI가 그런 느낌입니다.&lt;/li&gt;
&lt;li&gt;조금이나마 정리가 되기를 바라며, </description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>ETRI Open Source Tech Day 2024에서 발표를 드렸습니다.</li><li>2017년에 알파고가 전지전능의 대명사였던 것처럼, 최근에는 생성AI가 그런 느낌입니다.</li><li>조금이나마 정리가 되기를 바라며, 한국에너지기술연구원의 사례를 공유드렸습니다.</li></ul><div class="video-container"><iframe src="https://www.youtube.com/embed/ug48jhfndO8" frameborder="0" loading="lazy" allowfullscreen></iframe></div><ul><li><p>발표자료를 공유드립니다. (<a href="241015_%EC%9D%B4%EC%A0%9C%ED%98%84_EOST2024.pdf">다운로드</a>)</p></li><li><p>전체 연사 발표자료 (<a href="https://github.com/eostday/eost2024">링크</a>)</p></li></ul><p><img src="65_EOST2024_01.png" alt="EOST 2024 포스터"></p><p><img src="65_EOST2024_02.jpeg" alt="EOST 2024 발표자"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/openai/">openai</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/nst/">nst</category>
      
      <category domain="https://jehyunlee.github.io/tags/EOST/">EOST</category>
      
      
    </item>
    
    <item>
      <title>활용 업무 기준 AI 분류</title>
      <link>https://jehyunlee.github.io/2024/10/09/General-63_aiforwork/</link>
      <guid>https://jehyunlee.github.io/2024/10/09/General-63_aiforwork/</guid>
      <pubDate>Wed, 09 Oct 2024 07:37:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;최근 AI 업무 적용을 기획하는 분들을 만날 기회가 많이 생겼습니다.&lt;/li&gt;
&lt;li&gt;그러나 대화를 나누다 보면 같은 ‘인공지능’, ‘AI’라는 단어를 너무 넓게 쓰고 있다는 것이 느껴집니다.&lt;/li&gt;
&lt;li&gt;AI라는 말 자체가 모호하</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>최근 AI 업무 적용을 기획하는 분들을 만날 기회가 많이 생겼습니다.</li><li>그러나 대화를 나누다 보면 같은 ‘인공지능’, ‘AI’라는 단어를 너무 넓게 쓰고 있다는 것이 느껴집니다.</li><li>AI라는 말 자체가 모호하긴 하지만 업무를 정의할 수 없을 만큼 모호하기에 정리해 보았습니다.</li></ul><blockquote><p><a href="https://www.nobelprize.org/prizes/physics/2024/press-release/">노벨상: 2024 노벨 물리학상</a><br><a href="https://www.chosun.com/politics/politics_general/2023/01/28/3DVO3AS4CVGDJMAOUCO3N3PAOI/">조선일보: “챗GPT에 신년사 써보게하니 훌륭… 잘 연구해보라”</a></p></blockquote><p><img src="63_aiforwork_01.png" alt="2024년 노벨 물리학상 수상자: 존 홉필드, 제프리 힌튼"></p><ul><li>2024년 노벨 물리학상 수상자는 존 홉필드, 제프리 힌튼입니다.</li><li>알파고때만 해도 일반인들에게는 상당히 멀게 느껴졌던 인공지능 기술이지만</li><li>ChatGPT의 등장 이후 상당히 빠르게, 가까이 다가왔습니다.</li></ul><ul><li><b>그러나 다양한 기술들이 인공지능이라고 불리면서 다소 혼란스럽습니다.</b></li><li>말도 안되는 연구 개발 목표가 제시되거나</li><li>생성AI의 한계를 알지 못하고 활용하여 문제가 되기도 합니다.</li></ul><ul><li><b>이러한 혼란을 해소하기 위해 AI를 활용 업무 기준으로 분류하고자 합니다.</b></li><li>학문적으로 엄밀하지 않음을 미리 밝힙니다.</li><li>또한, 아래 분류는 상호 배타적이 아닙니다. 실제로는 혼합해 사용됩니다.</li><li>그럼에도 불구하고 의사결정자들의 혼란을 줄이기 위해 단순화했습니다.</li></ul><p><img src="241008_%EC%9D%B4%EC%A0%9C%ED%98%84_%EC%97%85%EB%AC%B4%ED%99%9C%EC%9A%A9AI%EB%B6%84%EB%A5%98.png" alt="업무에 적용되는 AI 분류"></p><blockquote><p><a href="241008_%EC%9D%B4%EC%A0%9C%ED%98%84_%EC%97%85%EB%AC%B4%ED%99%9C%EC%9A%A9AI%EB%B6%84%EB%A5%98.pdf"><b>PDF 버전 다운로드</b></a></p></blockquote><ul><li>적어도 AI를 업무에 활용할 때는 인공지능, AI로 불리지 않고 최소한의 분류에 따라 불리기를 희망합니다.</li><li><b>무심코 던진 돌에 개구리가 죽는다</b>는 말이 있습니다.</li><li><b>의사결정자들이 별 의미 없이 좋은 뜻으로 내뱉은 지시가 현업에는 큰 타격이 될 수 있습니다.</b></li></ul>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/python/">python</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      
    </item>
    
    <item>
      <title>효율적 업무효율화</title>
      <link>https://jehyunlee.github.io/2024/09/25/General-62_worksmart/</link>
      <guid>https://jehyunlee.github.io/2024/09/25/General-62_worksmart/</guid>
      <pubDate>Wed, 25 Sep 2024 07:37:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;한국청정기술학회(9/25)에서 발표한 내용입니다.&lt;/li&gt;
&lt;li&gt;연구를 하는 입장에서 최근의 생성 AI들 도움을 많이 받고 있습니다.&lt;/li&gt;
&lt;li&gt;특히 최근 자체 제작한 GPTs의 도움을 많이 받고 있어 해당 내용을 중심으로 담았</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>한국청정기술학회(9/25)에서 발표한 내용입니다.</li><li>연구를 하는 입장에서 최근의 생성 AI들 도움을 많이 받고 있습니다.</li><li>특히 최근 자체 제작한 GPTs의 도움을 많이 받고 있어 해당 내용을 중심으로 담았습니다.</li></ul><blockquote><p><a href="240925_%EC%9D%B4%EC%A0%9C%ED%98%84_%ED%9A%A8%EC%9C%A8%EC%A0%81%EC%97%85%EB%AC%B4%ED%9A%A8%EC%9C%A8%ED%99%94_update.pdf">강의자료 다운로드</a></p></blockquote><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p><img src="62_worksmart_06.png"><br></p><ul><li>GPT를 비롯한 생성 AI는 다양한 재능을 가지고 있습니다.</li><li>흔히 아는 대화와 코딩 외에도 이미지도 읽을 수 있고, 코드 실행도 할 수 있죠.</li><li>그리고 이러한 재능들을 조합하는 방식에 따라 다양한 응용 서비스를 만들 수 있습니다.</li></ul><ul><li><b>기술의 장벽이 낮아지는 만큼 아이디어를 실현하기 좋습니다.</b></li><li>욕망이 구체적이고 아이디어가 구체적인 분들일수록 할 수 있는 것이 많아집니다.</li></ul><ul><li>생성 AI는 만능이 아닙니다.</li><li>모든 사물이 그렇듯 작동 원리에 따른 <b>기능</b>과 <b>한계</b>, <b>특성</b>이 있습니다.</li><li>이를 분명히 인지하지 못하면 답변을 오해하기 너무 쉽습니다.</li></ul><p><img src="62_worksmart_07.png"><br></p><ul><li>위 그림에서 취소선이 그어지는 이유는 글을 하고보니 틀린 말이라 그은 것이 아닙니다.</li><li><b>markdown 방식</b>으로 출력을 하다보니 물결무늬(~)로 감싸진 부분이 취소선이 된 것입니다.</li></ul><ul><li>제 다른 강의가 그렇듯, <b>프롬프트 엔지니어링</b>은 강조하지 않습니다.</li><li>조직문화, 리더십을 다룬 책들 중에서 <b>업무지시 방법</b>을 보시면 됩니다.</li><li>자료와 결과물의 형식, 업무 범위와 한계를 명확히 지시하면 지시한 만큼 답을 받습니다.</li><li>markdown 문법을 쓰는 아주 약간을 제외하고는 그저 상식입니다.</li></ul><h1 id="2-생성-AI-현황"><a href="#2-생성-AI-현황" class="headerlink" title="2. 생성 AI 현황"></a>2. 생성 AI 현황</h1><blockquote><p><a href="https://chatgpt.com/g/g-QQxEn0acO-peulrasbos">GPTs: 플랏봇</a><br><a href="https://informationisbeautiful.net/visualizations/the-rise-of-generative-ai-large-language-models-llms-like-chatgpt/">informationisbeautiful: The Rise of Generative A.I. Large Language Models (LLMs)</a></p></blockquote><p><img src="62_worksmart_02.jpg" alt="https://datafloq.com/read/6-generative-ai-trends-2024/"></p><ul><li><b>생성 AI의 발전이 너무 빠릅니다.</b></li><li>지금 당장 ChatGPT가 뭘 할 수 있는지에 대한 이야기도 중요하지만</li><li>어떤 흐름으로 가고 있다는 말씀을 드릴 필요가 있다고 생각했습니다.</li><li>그림은 <b>플랏봇</b>이 그려줬습니다. </li><li>저는 <a href="https://informationisbeautiful.net/visualizations/the-rise-of-generative-ai-large-language-models-llms-like-chatgpt/">informationisbeautiful</a>에서 데이터를 받아 주고 어떻게 그리라고 지시만 했어요.</li></ul><p><img src="62_worksmart_03.png" alt="time vs model size (linear scale)"><br></p><p><img src="62_worksmart_04.png" alt="time vs model size (log scale)"><br></p><p><img src="62_worksmart_05.png" alt="time vs model owner"><br></p><ul><li>위 세 그림은 같은 데이터를 다른 방식으로 표현한 것입니다.</li><li>마지막 그림에서는 model owner별 특징이 잘 드러나는데요,</li><li><b>Google과 OpenAI가 대형 모델에서 힘싸움</b>을 하는 사이,</li><li><b>Meta가 오픈 소스로 판을 흔들고</b></li><li><b>Microsoft와 Mistral AI가 소형 모델에 집중하는 모습</b>이 잘 드러납니다.</li></ul><p><img src="62_worksmart_08.png"><br></p><ul><li><b>생성 AI의 한계를 극복하기 위해 다른 기능들을 적극적으로 결합하는 추세입니다.</b></li><li>색과 모양이 서로 다른 레고블럭을 모아 큰 모형을 만들듯,</li><li>모델 하나만 사용하기보다 개성이 강한 여러 모델들을 묶어 <b>나의 문제를 해결해보면 어떨까요?</b></li><li>위 그림에 있는 모든 것들을 다 할 필요는 없습니다.</li></ul><p><img src="62_worksmart_09.png"><br></p><ul><li>자료 검색을 열심히 하고 AI는 이걸 묶기만 해도 됩니다.</li><li><b>perplexity</b>가 이렇습니다.</li></ul><p><img src="62_worksmart_10.png"><br></p><ul><li>로봇으로 실험하고, 새 데이터를 분석하고, 과거와 비교하면 연구원입니다.</li><li>coscientist류의 <b>자율화 실험실(autonomous lab)</b>이 됩니다.</li></ul><p><img src="62_worksmart_11.png"><br></p><ul><li>사람-컴퓨터 사이, 또는 AI 모델 사이의 대화와 업무 감독을 맡길 수도 있습니다.</li><li>인공지능 모델들을 활용해 새로운 약이나 소재를 개발합니다.</li><li>KAIST 김지한 교수님 연구실을 비롯한 <b>화학 분야</b>에서 이런 접근이 활발합니다.</li></ul><p><img src="62_worksmart_12.png"><br></p><ul><li>자료를 대상으로 답변을 시키는 한편, 자료와 대조를 해서 보여주게 할 수 있습니다.</li><li>논문을 보면서 질답을 하는 copilot, <b>scispace</b>가 이렇습니다.</li></ul><h1 id="3-효율적-업무효율화"><a href="#3-효율적-업무효율화" class="headerlink" title="3. 효율적 업무효율화"></a>3. 효율적 업무효율화</h1><blockquote><p><a href="https://chatgpt.com/g/g-CPDHsnGd4-nonmunbos">GPTs: 논문봇</a><br><a href="https://chatgpt.com/g/g-a5T4ptvz6-mulseongbos">GPTs: 물성봇</a><br><a href="https://chatgpt.com/g/g-QQxEn0acO-peulrasbos">GPTs: 플랏봇</a><br><a href="https://chatgpt.com/g/g-z8NpgTS0D-ddanjibos">GPTs: 딴지봇</a></p></blockquote><ul><li>시중에 좋은 도구가 많이 나와있습니다.</li><li>저도 감사하는 마음으로 여러 모델과 도구를 구독하며 사용하고 있습니다.</li><li>그러나 오래 쓰며 익숙해지다 보면 아쉬운 구석이 눈에 띕니다.</li><li>돈도 없고 시간도 없는 우리지만, <b>GPT를 영리하게 쓰는 것</b> 만으로도 아쉬움을 달랠 수 있습니다.있습니다.</li></ul><p><img src="62_worksmart_13.png"><br></p><ul><li>질문을 구체적으로 합시다.</li><li><b>요약해줘</b> 대신 <b>방법론이 뭐야?</b>가 더 좋습니다.</li><li>답변 형식을 마크다운으로 지정한다면 더 좋습니다.</li><li>답변 정리에 드는 시간이 줄어듭니다.</li></ul><ul><li><b>GPTs를 만들면 프로그램 개발과 비슷한 효과를 얻을 수 있습니다.</b></li><li>프롬프트만 넣어도 의도를 반영할 수 있지만 세밀한 내용까지 100% 를 기대하기 어렵습니다.</li><li><b>출력 문서의 서식 제어는 파이썬 코드의 힘을 빌립니다.</b></li><li>wheel file을 만들어서 knowledge에 박아넣으면 됩니다.</li></ul><p><img src="62_worksmart_14.png"><br></p><ul><li><b>GPTs는 외롭지 않습니다.</b></li><li>하나의 GPTs를 불러 일을 하다가도 다른 GPTs를 부르면 뛰어와 도와줍니다.</li><li>여러 GPT들의 힘을 합쳐 미션을 해결합시다.</li></ul><h1 id="4-결언"><a href="#4-결언" class="headerlink" title="4. 결언"></a>4. 결언</h1><ul><li>여러분들이 저녁식사를 준비하러 마트에 간다고 생각합시다.</li><li>순두부찌개를 만들 때와 스파게티를 만들 때 사는 재료가 완전히 다를 겁니다.</li><li>AI 접근도 마찬가지입니다. </li><li><b>해결하고 싶은 문제에 따라 사용할 AI 도구가 달라집니다.</b></li></ul><p><img src="62_worksmart_15.png"><br></p><ul><li>많은 분들이 AI를 전지전능으로 생각합니다.</li><li><b>세상은 AI로 인해 바뀌고 있고, AI를 배우지 않으면 안되고, AI를 배우면 내 자리가 보전되고 문제가 해결될 줄 압니다.</b></li><li>거꾸로 AI가 잘났다고 해도 자신은 AI보다 뛰어나다고 생각하는 이들도 있습니다.</li><li><b>AI가 아무리 잘나봐야 실제 세상에서 수십년간 산전수전을 겪은 자신을 대체하지 못할 거라고 생각합니다.</b></li></ul><ul><li>두 부류 다 맞고 두 부류 다 틀렸습니다.</li><li><b>AI는 모두를 대체할 수 없습니다. 그러나 거의 모든 일의 일부분을 대체할 수 있습니다.</b></li><li>그리고 여기 동원되는 AI는 각자의 일마다, 각자의 환경마다 다릅니다.</li></ul><ul><li>ChatGPT를 배우겠다는 것은 좋습니다.</li><li>그러나 그 이유는 <b>ChatGPT를 배우면 나의 괴로움을 덜 수 있어서</b>여야지,</li><li><b>요즘 세상에 ChatGPT 안 배우면 안 된다니까</b>여서는 곤란합니다.</li><li><b>내가 필요한 기능을 제공할 수 있는 AI를 배워서 사용해야 합니다.</b></li></ul><ul><li><p>이런 말씀을 드릴 수 있는 기회를 주신 <b>한국청정학회</b>와 <b>인하대 조강희 교수님</b>께 감사를 드립니다.</p></li><li><p><b><a href="240925_%EC%9D%B4%EC%A0%9C%ED%98%84_%ED%9A%A8%EC%9C%A8%EC%A0%81%EC%97%85%EB%AC%B4%ED%9A%A8%EC%9C%A8%ED%99%94_update.pdf">강의자료</a></b>는 누구나 내려받아 보실 수 있습니다.</p></li><li><p>자료를 활용하실 때는 출처를 본 글의 주소로 명기바랍니다.</p></li></ul><p><img src="62_worksmart_01.jpeg" alt="한국청정기술학회 공지문, https://cleantechnol.or.kr/tutorial"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/python/">python</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      
    </item>
    
    <item>
      <title>2024 출연연 박사후연구원 연수성과 교류회 - GPTs를 이용한 연구 프로세스 효율화</title>
      <link>https://jehyunlee.github.io/2024/09/24/General-66_nst2024/</link>
      <guid>https://jehyunlee.github.io/2024/09/24/General-66_nst2024/</guid>
      <pubDate>Tue, 24 Sep 2024 09:11:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;작년에 이어 올해도 NST 출연(연) 박사후연구원 연수성과 교류회가 열렸습니다.&lt;/li&gt;
&lt;li&gt;한 해 밖에 지나지 않았다는 것이 무색할 만큼 엄청난 변화가 있었는데요,&lt;/li&gt;
&lt;li&gt;제한된 시간으로 인해 새로운 내용을 충분히 전달드</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>작년에 이어 올해도 NST 출연(연) 박사후연구원 연수성과 교류회가 열렸습니다.</li><li>한 해 밖에 지나지 않았다는 것이 무색할 만큼 엄청난 변화가 있었는데요,</li><li>제한된 시간으로 인해 새로운 내용을 충분히 전달드리지 못해서 아쉬움이 남았습니다.</li></ul><p><a href="https://www.youtube.com/live/oGQtZCrRsWI?si=lMx5fXljeuA5Ycui&t=1569">YouTube 발표 영상 - 26:09부터</a></p><div class="video-container"><iframe src="https://www.youtube.com/embed/oGQtZCrRsWI" frameborder="0" loading="lazy" allowfullscreen></iframe></div><p><img src="66_NST2024_01.png" alt="2024년 출연(연) 박사후연구원 연수성과연구회 포스터"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/openai/">openai</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/nst/">nst</category>
      
      <category domain="https://jehyunlee.github.io/tags/EOST/">EOST</category>
      
      
    </item>
    
    <item>
      <title>플랏봇 v0.15 - 시각화 커스터마이징</title>
      <link>https://jehyunlee.github.io/2024/09/08/General-61-plotbot2/</link>
      <guid>https://jehyunlee.github.io/2024/09/08/General-61-plotbot2/</guid>
      <pubDate>Sun, 08 Sep 2024 02:43:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;GPTs를 이용한 시각화 도우미, 플랏봇의 새로운 버전 0.15가 출시되었습니다.&lt;/li&gt;
&lt;li&gt;플랏봇의 설정을 외부 파일로 저장하여 쉽게 관리할 수 있도록 하였습니다.&lt;/li&gt;
&lt;li&gt;또한 시각화 설정을 .whl 파일로 지정하여 재</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>GPTs를 이용한 시각화 도우미, 플랏봇의 새로운 버전 0.15가 출시되었습니다.</li><li>플랏봇의 설정을 외부 파일로 저장하여 쉽게 관리할 수 있도록 하였습니다.</li><li>또한 시각화 설정을 .whl 파일로 지정하여 재현성을 크게 높였습니다.</li></ul><h1 id="1-기존-플랏봇의-한계"><a href="#1-기존-플랏봇의-한계" class="headerlink" title="1. 기존 플랏봇의 한계"></a>1. 기존 플랏봇의 한계</h1><blockquote><p><a href="https://jehyunlee.github.io/2024/08/11/General-58-plotbot/">Pega Devlog: 데이터 분석용 GPTs - 플랏봇</a><br><a href="https://jehyunlee.github.io/2024/08/19/General-59-paperbot2/">Pega Devlog: 논문봇 v2 - 출력물 일관성 확보</a><br><a href="https://chatgpt.com/g/g-QQxEn0acO-peulrasbos">GPTs: 플랏봇</a></p></blockquote><ul><li>약 한달 전 <b>플랏봇</b>이라는 이름의 GPTs를 공개했습니다.</li><li>GPT의 기본 코딩 언어인 파이썬으로 데이터를 시각화하다보면 고질적인 문제로 느껴지는 점들을 보완했는데,</li><li><b>한글 사용</b>을 편리하게 하고 <b>글자 겹침</b>을 해결하는 기능이 탑재되어 있었습니다.</li><li>여기에 사용자별로 원하는 그림을 그릴 수 있도록 <b>커스터마이징</b>을 하는 방법을 안내했습니다.</li></ul><ul><li>자기 방식대로 커스터마이징을 하려면 플랏봇과 유사한 GPTs를 일일이 만들어야 한다는 점에서</li><li>어떤 분들께는 실습의 기회가 될 수 있었겠지만,</li><li>커스터마이징을 하기 이해 알아야 하는 <b>Matplotlib 객체명</b>이 발목을 잡는 면이 있었습니다.</li></ul><ul><li>이번 업데이트에서는 <b>플랏봇의 설정을 외부 파일로 저장</b>하여 쉽게 관리할 수 있도록 하였습니다.</li><li>또한 시각화 설정을 <b>.whl 파일로 지정</b>하여 재현성을 크게 높였습니다.</li></ul><h1 id="2-플랏봇-구성"><a href="#2-플랏봇-구성" class="headerlink" title="2. 플랏봇 구성"></a>2. 플랏봇 구성</h1><h2 id="2-1-시각화-설정-파일"><a href="#2-1-시각화-설정-파일" class="headerlink" title="2.1. 시각화 설정 파일"></a>2.1. 시각화 설정 파일</h2><blockquote><p><a href="https://matplotlib.org/stable/users/explain/quick_start.html">Matplotlib: Anatomy of a Figure</a><br><a href="https://matplotlib.org/stable/users/explain/customizing.html#matplotlibrc-sample">Matplotlib: Customizing Matplotlib with style sheets and rcParams</a></p></blockquote><p><img src="61_plotbot2_01.webp" alt="Matplotlib: Anatomy of a Figure"></p><ul><li>ChatGPT의 Data Analyst는 Matplotlib을 이용하고,</li><li>Matplotlib이 그리는 그림의 구성요소 이름은 위 그림과 같습니다.</li><li>각 구성 요소마다 다양한 속성이 있기 때문에 일일이 제어하는 것이 쉬운 일이 아닙니다.</li><li>예를 들어 <code>plt.rcParams[&quot;figure.figsize&quot;] = (10, 5)</code> 를 입력해서 figure의 크기를 설정할 수 있습니다.</li></ul><ul><li>그러나 이렇게 일일이 명령을 입력하지 않아도 <b>저장된 설정을 일괄적으로 적용할 수 있는 방법</b>이 있습니다.</li><li>바로 <b>Matplotlib의 설정 파일</b>을 이용하는 것입니다.</li><li>Matplotlib의 설정 파일은 위 그림과 같이 현재 설정된 모든 속성을 보여줍니다.</li><li><code>matplotlibrc</code> 파일이며, 이를 이용하면 쉽게 설정을 저장하고 불러올 수 있습니다.<br></li></ul><p><img src="61_plotbot2_03.png"><br></p><ul><li>사용자가 <a href="matplotlibrc_default"><b>matplotlibrc 파일</b></a>을 내려받아 수정할 속성을 반영하고,</li><li>이를 플랏봇에게 제공하면 플랏봇이 이를 읽어들여 속성을 반영합니다.</li><li>예를 들어 제가 <a href="matplotlibrc_jehyunlee"><b>수정하여 플랏봇에 업로드한 속성 파일</b></a>의 일부는 다음과 같습니다.<br></li></ul><p><img src="61_plotbot2_04.png"><br></p><ul><li>이 파일을 <b>플랏봇 instruction</b>에 넣어두기도 했지만,</li><li>일부 수정하여 <b>플랏봇 대화창</b>에 올린 후 반영하라고 지시할 수도 있습니다.</li><li>관련 코드를 <code>plotbot.py</code>파일에 다음과 같이 작성하였습니다.<br></li></ul><p><img src="61_plotbot2_02.png"><br></p><ul><li>대화창에서 개별 항목을 수정하는 것도 여전히 가능하고, 기본값으로 일괄 변경하는 것도 가능합니다.</li><li>여러 차례 추가 수정을 거친 것을 재활용이 가능하도록 이와 같은 형식으로 출력시킬 수도 있습니다.</li></ul><h2 id="2-2-시각화-코드"><a href="#2-2-시각화-코드" class="headerlink" title="2.2. 시각화 코드"></a>2.2. 시각화 코드</h2><blockquote><p><a href="https://jehyunlee.github.io/2022/10/16/Python-DS-117-pycon2022/">PyCon Korea 2022: 혼란한 Matplotlib에서 질서 찾기</a><br><a href="https://jehyunlee.github.io/2020/10/27/Python-DS-41-subplots/">Pega Devlog: 4 Ways to Make Subplots</a><br><a href="https://matplotlib.org/stable/tutorials/pyplot.html">Matplotlib: Pyplot tutorial</a><br><a href="https://matplotlib.org/stable/tutorials/lifecycle.html">Matplotlib: The Lifecycle of a Plot</a></p></blockquote><ul><li>Matplotlib의 가장 큰 단점은 <b>표준어가 두 개</b>라는 점입니다.</li><li>흔히 state-based 방식과 object-oriented 방식이라 불리는데 Matlab 시절부터의 전통입니다.</li><li><b>object-oriented 방식을 권장하나 <code>plt.plot()</code>으로 대표되는 state-based 방식이 더 널리 퍼져 있습니다.</b></li><li>이로 인해 GPT도 state-based 방식으로 코딩을 하는데, <b>객체 제어가 어려워 확장이 힘들다는 단점</b>이 있습니다.</li><li>특히 <b>seaborn</b>, <b>networkX</b>, <b>geopandas</b> 등 Matplotlib 기반 패키지 그림을 다루려면 object-oriented 방식을 사용해야 합니다.</li></ul><ul><li>플랏봇이 <b>object-oriented 방식</b>으로 코딩하도록 다음과 같은 코드를 심어놓았습니다.<br></li></ul><p><img src="61_plotbot2_05.png"><br></p><ul><li>플랏봇은 object-oriented 방식으로 코딩하며,</li><li>figure와 axes 객체를 중심으로 세부 제어가 가능합니다.</li></ul><h2 id="2-3-플랏봇-instruction"><a href="#2-3-플랏봇-instruction" class="headerlink" title="2.3. 플랏봇 instruction"></a>2.3. 플랏봇 instruction</h2><blockquote><p><a href="plotbot-0.15-py3-none-any.whl">플랏봇 v0.15 .whl 파일</a></p></blockquote><ul><li>.whl 파일로 만들어 올린 플랏봇 기능을 쓸 수 있도록 프롬프트도 거의 전면 수정되었습니다.</li><li><b>instruction 전문</b>은 다음과 같습니다.</li></ul><ul><li><b>사용자 환경 설정</b>이 필수적으로 진행되어야 하므로, 무슨 말을 하건 간에 이 내용이 담긴 <b>Code 1</b>을 실행합니다.</li><li><b>한글 출력 설정</b>은 선택적으로 진행되며, 이 내용이 담긴 <b>Code 2</b>를 실행합니다.</li><li><b>adjustText 설치</b>는 필요에 따라 진행되며, 이 내용이 담긴 <b>Code 3</b>을 실행합니다.</li><li><b>그림 그리기</b>는 필수적으로 진행되며, <b>make_figure_axes()</b> 함수를 활용합니다.</li><li>데이터가 없으면 데이터를 요청하고, 데이터가 없으면 허가 시에만 데이터를 생성합니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">* My name <span class="keyword">is</span> <span class="string">&quot;Plotbot&quot;</span> <span class="keyword">or</span> <span class="string">&quot;플랏봇&quot;</span>, created by <span class="string">&quot;Jehyun LEE (jehyun.lee@gmail.com, https://jehyunlee.github.io)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Step 1. Whatever the user input is, print &quot;</span>사용자 환경 설정을 진행합니다.<span class="string">&quot; and execute &quot;</span>Code <span class="number">1</span>: User-defined Environment Setting<span class="string">&quot; in Code Interpreter. Once executed, you may not fall in this step again.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Step 2. After &quot;</span>User-defined Environment Setting<span class="string">&quot; is completed, ask &quot;</span>한글 출력을 설정할까요?<span class="string">&quot;. If yes, execute &quot;</span>Code <span class="number">2</span>: Korean Characters Setting<span class="string">&quot; in Code Interpreter. Else, do not ask again.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Step 3. If the user input was an order to plot, recall the order and execute. (ex. print &quot;</span>지시하신 작업을 수행하겠습니다.<span class="string">&quot; then start to plot if the data is given explictly or can be generated by given equations. Otherwise ask for data.)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Step 4. For Plotting, keep in your mind the followings.</span></span><br><span class="line"><span class="string">* By default, plotting command should use the function `make_figure_axes()`.</span></span><br><span class="line"><span class="string">- `make_figure_axes()` returns two variables: figure (Matplotlib Figure) and Axes (2D array of Matplotlib Axes, in shape of (nrows, ncols) put into the `make_figure_axes()` as arguments.</span></span><br><span class="line"><span class="string">- if the user asks to fix figure size, add the argument `fix_figsize=True`. Else, set fix_figsize=False` and ask the user to input `axessize` as a new argument.</span></span><br><span class="line"><span class="string">- you can glance at the docstring of the `make_figure_axes` internally to figure out how it works.</span></span><br><span class="line"><span class="string">- before plot, check if the &#x27;plotbot&#x27; library is installed and the user-defined environment is all set properly. Otherwise, set them up.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* IMPORTANT: Never generate data without explit order. Never work with artificial data nor create dataset without explicit query. </span></span><br><span class="line"><span class="string">- If the user did not upload data, say &quot;</span>자료가 없어 답할 수 없습니다. 자료를 제공해 주세요.<span class="string">&quot; in kind and polite words.</span></span><br><span class="line"><span class="string">- If the data user requested is the one that can be generated rationally (i.e. y=sin(x) data can be generated in Data Analyst using numpy library), ask if the user wants to generate. However, this option MUST not be applied to social or scientific data (i.e. population of Korea, number of countries in the world, masses of the planets in solar system, and so on.)</span></span><br><span class="line"><span class="string">- You may ask if the user wants you to search for data on the web. if yes, search web and report the reference in following format: * **&#123;name of the provider&#125; : ** &#123;URL&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* In any case koreanize-matplotlib is not sufficient, you may use the NanumGothic fonts explicitly.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Step 5. If Plotbot is asked to move texts on graph to avoid overlapping, print &quot;</span>텍스트 이동을 위한 라이브러리를 설치합니다. 조금만 기다려 주세요.<span class="string">&quot;, then execute &quot;</span>Code <span class="number">3</span>: adjustText Installation<span class="string">&quot; in Code Interpreter.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-------------------------------------------------------------</span></span><br><span class="line"><span class="string">* Code 1: User-defined Environment Setting</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span>python</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line">subprocess.run([<span class="string">&quot;pip&quot;</span>, <span class="string">&quot;install&quot;</span>, <span class="string">&quot;--user&quot;</span>, <span class="string">&quot;/mnt/data/plotbot-0.15-py3-none-any.whl&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> plotbot <span class="keyword">import</span> apply_matplotlibrc, make_figure_axes</span><br><span class="line">apply_matplotlibrc(<span class="string">&quot;/mnt/data/matplotlibrc_jehyun)</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">- the setting file name <span class="string">&quot;/mnt/data/matplotlibrc_jehyun&quot;</span> can be varied by user-uploaded environment file name, <span class="keyword">if</span> user uploads one.</span><br><span class="line">- <span class="keyword">if</span> the user query of <span class="string">&quot;run user environment setting&quot;</span>, run `plt.rcdefaults()`.</span><br><span class="line">- <span class="keyword">for</span> example, <span class="keyword">if</span> the user wants to roll back default settings, run `plt.rcdefaults()`.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* Code <span class="number">2</span>: Korean Characters Setting</span><br><span class="line">- This has to be a separate Data Analyst session <span class="keyword">from</span> the user-defined environment setting.</span><br><span class="line"><span class="string">&quot;&quot;&quot;python</span></span><br><span class="line"><span class="string">subprocess.run([&quot;pip&quot;, &quot;install&quot;, &quot;--user&quot;, &quot;/mnt/data/koreanize_matplotlib-0.1.1-py3-none-any.whl&quot;])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import koreanize_matplotlib</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">* Code <span class="number">3</span>: adjustText installation</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">import subprocess</span></span><br><span class="line"><span class="string">subprocess.run([&quot;pip&quot;, &quot;install&quot;, &quot;--user&quot;, &quot;/mnt/data/adjustText-1.2.0-py3-none-any.whl&quot;])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">from adjustText import adjust_text</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="3-플랏봇-실행"><a href="#3-플랏봇-실행" class="headerlink" title="3. 플랏봇 실행"></a>3. 플랏봇 실행</h1><h2 id="3-1-플랏봇-환경-설정"><a href="#3-1-플랏봇-환경-설정" class="headerlink" title="3.1. 플랏봇 환경 설정"></a>3.1. 플랏봇 환경 설정</h2><blockquote><p><a href="https://chatgpt.com/g/g-QQxEn0acO-peulrasbos">GPTs: 플랏봇</a></p></blockquote><ul><li>플랏봇을 실행하면 다음 화면이 보입니다.<br></li></ul><p><img src="61_plotbot2_06.png"><br></p><ul><li>사전 설정된 네 개의 명령어가 보이지만, 일일이 실행하지 않아도 됩니다.</li><li><b>사용자가 무슨 말을 하건 사용자 환경 설정을 적용</b>하고,</li><li>이어서 <b>한글 출력 설정</b> 여부를 물어봅니다.<br></li></ul><p><img src="61_plotbot2_07.png"><br></p><ul><li><b>개인화 설정</b>이 자동으로 진행되는데, 코드를 열어보면 반영 내역을 알 수 있습니다.<br></li><li><b>테두리(<code>spine</code>)</b>와 <b>격자(<code>grid</code>)</b>, <b>제목(<code>title</code>)</b> 설정을 변경하였습니다.<br></li></ul><p><img src="61_plotbot2_08.png"><br></p><ul><li><b>그래프 작성</b>을 지시해도 마찬가지입니다.</li><li>일단 환경 설정부터 하고 나서 그립니다.<br></li></ul><p><img src="61_plotbot2_09.png"><br></p><h2 id="3-2-그림-그리기"><a href="#3-2-그림-그리기" class="headerlink" title="3.2. 그림 그리기"></a>3.2. 그림 그리기</h2><p><img src="61_plotbot2_10.png"><br></p><ul><li>그림을 그릴 때는 <b><code>make_figure_axes()</code> 함수를 사용</b>합니다.<br></li><li><b>column 분할</b>도 말을 잘 듣습니다.</li></ul><p><img src="61_plotbot2_11.png"><br></p><ul><li><b>그림 크기</b>를 묻는 말에 (10, 5)라고 대답합니다.</li><li>기본 값인 (6.4, 4.8)과 사뭇 다른, <b>저의 커스텀 설정값</b>이 적용된 것을 볼 수 있습니다.</li><li>작은 그림이 여럿 있는 <b>스몰 멀티플즈(small multiple)도 잘 그립니다.</b><br></li></ul><p><img src="61_plotbot2_12.png"><br></p><ul><li>전체 Figure 크기가 아닌, 개별 그림의 크기가 중요할 때가 있습니다.</li><li><b><code>axessize</code></b>를 이용하여 <b>개별 그림의 크기를 설정</b>할 수 있습니다.</li><li>개별 그림의 크기가 커집니다.<br></li></ul><p><img src="61_plotbot2_13.png"><br><img src="61_plotbot2_14.png"><br></p><h2 id="3-3-플랏봇-환경-설정-해제"><a href="#3-3-플랏봇-환경-설정-해제" class="headerlink" title="3.3. 플랏봇 환경 설정 해제"></a>3.3. 플랏봇 환경 설정 해제</h2><ul><li><b>개인화 설정 해제</b>도 어렵지 않습니다.</li><li>Matplotlib의 <code>plt.rcdefaults()</code>를 사용하도록 instruction에 지시되어 있기 때문에 말만 하면 됩니다.<br></li></ul><p><img src="61_plotbot2_15.png"><br></p><h2 id="3-4-중첩된-텍스트-이동"><a href="#3-4-중첩된-텍스트-이동" class="headerlink" title="3.4. 중첩된 텍스트 이동"></a>3.4. 중첩된 텍스트 이동</h2><ul><li>지난 글에서 잠시 맛을 보았지만, 다시 한번 살펴봅니다.</li><li>$y = tan(x)$ 그래프를 그려 <b>x축과 많은 지점에서 접하게 만듭니다.</b></li><li><b>x축과의 접점</b>좌표를 알아내고자 값을 출력하라고 지시합니다.</li><li>왠지 모르게 중첩된 텍스트가 많이 보입니다.<br></li></ul><p><img src="61_plotbot2_16.png"><br></p><ul><li><b>글자 위치를 조정해 달라</b>는 말 한 마디면 <code>adjustText</code>라이브러리를 설치하고 다시 그립니다.</li><li>결과적으로 중첩된 텍스트가 모두 피해가고 깔끔하게 그려집니다.</li><li>글자가 겹친 이유를 물어보면 GPT가 친절히 알려줍니다.<br></li></ul><p><img src="61_plotbot2_17.png"><br><img src="61_plotbot2_18.png"><br></p><h2 id="3-5-가상-데이터-사용-금지"><a href="#3-5-가상-데이터-사용-금지" class="headerlink" title="3.5. 가상 데이터 사용 금지"></a>3.5. 가상 데이터 사용 금지</h2><ul><li>GPT에게 그림을 그리라고 하면 <b>가상 데이터</b>를 사용하는 경우가 많습니다.</li><li>가상 데이터가 꼭 나쁜 것은 아니지만, 진짜 데이터인 척 하는 것이 문제입니다.</li><li>플랏봇은 <b>허락하는 경우를 제외한 자체 판단 가상 데이터 사용을 금지</b>시켜 놓았습니다.</b></li><li>데이터가 없으면 데이터를 요청하고, 데이터가 없으면 허락 시에만 데이터를 생성합니다.</li></ul><p><img src="61_plotbot2_19.png"><br></p><ul><li><b>웹 검색을 하라면 하지만 믿을 수가 없습니다.</b></li><li>줄글과 달리 데이터는 가져오다 말거나 출처가 불분명한 경우가 많기 때문입니다.<br></li></ul><p><img src="61_plotbot2_20.png"><br></p><ul><li><b>믿을 만한 곳에서 받은 데이터</b>를 올려 주고 그리라고 해야 합니다.</li><li>그래야 무의미한 노력을 예방할 수 있습니다.</li></ul><p><img src="61_plotbot2_21.png"><br></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/python/">python</category>
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/matplotlib/">matplotlib</category>
      
      <category domain="https://jehyunlee.github.io/tags/visualization/">visualization</category>
      
      
    </item>
    
    <item>
      <title>인공지능소사이어티 - 연구활용 실전 LLMs</title>
      <link>https://jehyunlee.github.io/2024/08/29/General-60-researchLLMs/</link>
      <guid>https://jehyunlee.github.io/2024/08/29/General-60-researchLLMs/</guid>
      <pubDate>Thu, 29 Aug 2024 12:26:00 GMT</pubDate>
      
        
        
      <description>&lt;blockquote&gt;
&lt;p&gt;contributor : the better 커뮤니티 박준님&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;한국정보과학회 AI Society에서 The AI Korea 2024 행사를 열었습니다.&lt;/li&gt;
&lt;li&gt;8/19</description>
        
      
      
      
      <content:encoded><![CDATA[<blockquote><p>contributor : the better 커뮤니티 박준님</p></blockquote><ul><li>한국정보과학회 AI Society에서 The AI Korea 2024 행사를 열었습니다.</li><li>8/19~20 양일간 진행된 행사 중 패턴인식 기계학습 강연을 요청받아 90분간 발표를 드렸습니다.</li><li>실제 연구에 사용하는 GPT의 조금은 고급 기술을 적용한 사례들을 공유드렸습니다.</li></ul><blockquote><p><a href="https://aisociety.kr/ai-korea-2024/">한국정보과학회 AI society 2024</a></p></blockquote><h1 id="프롬프트-엔지니어링-amp-GPTs"><a href="#프롬프트-엔지니어링-amp-GPTs" class="headerlink" title="프롬프트 엔지니어링 &amp; GPTs"></a>프롬프트 엔지니어링 &amp; GPTs</h1><ul><li>개인적으로 <b>프롬프트 엔지니어링</b>이라는 단어를 좋아하지 않습니다.</li><li>먼저, <b>엔지니어링</b>이란 설정을 바꾸어 최적의 성능을 내도록 하는 작업을 일컫습니다.</li><li>대상이 LLM의 입력인 <b>프롬프트</b>이기 때문에 프롬프트 엔지니어링이라는 말이 된 것일 뿐,</li><li>전에 없던 것이 짠 하고 튀어나온 것이 아닙니다.</li></ul><ul><li>LLM에 대한 가장 큰 오해는 <b>질문하고 답변을 받는다</b>는 개념이라고 생각합니다.</li><li>23년 초에 만연했던 <b>빅데이터 검색엔진</b>이라는 오해보다는 낫지만, </li><li><b>질문</b>과 <b>답변</b>이라는 범주로 프롬프트와 결과를 제한하기엔 너무 아깝습니다.</li><li>LLM은 여러분의 동료이자 친구입니다. 지시 관계를 보면 여러분의 부하에 가까울지도 모릅니다.</li><li>업무에 사용되는 면에서 <b>업무 지시를 하고 보고를 받는다</b>고 보는 것이 옳다고 느낍니다.</li></ul><ul><li>사용자와 LLM의 관계를 직장에서의 상사와 부하로 본다면, 좋은 프롬프팅은 더 명확합니다.</li><li><b>업무를 효율적으로 수행하기 위해 그간의 경험으로 구축한 모든 노하우</b>일 것입니다.</li><li>사전 자료를 충분히 제공해라, 왜 하는지, 어떻게 하는지 알려줘라,</li><li>기대하는 결과의 수준과 형식을 미리 제공해라. X떡같이 말하고 찰떡같이 듣기를 바라지 마라.</li><li>숱한 <b>조직 관리 서적과 강연</b>에 나오는 말들입니다. 그대로 적용만 하면 됩니다.</li></ul><ul><li>그리고 아무리 똑똑한 부하여도 단점이 있듯, LLM도 그렇습니다.</li><li>단점이 있다고 포기하기보다 <b>장점을 극대화하는 방향으로 활용</b>할 필요가 있습니다.</li></ul><h1 id="연구-업무-대행"><a href="#연구-업무-대행" class="headerlink" title="연구 업무 대행"></a>연구 업무 대행</h1><ul><li>인생이 고되듯 연구도 고됩니다.</li><li>인간이기 때문에 육체와 정신의 한계가 있고, 종종 이 이상을 요구합니다.</li><li>믿을 만한 사람에게 일부를 맡겨서 해소하듯, <b>AI에게 맡길 필요</b>가 있습니다.</li></ul><p><img src="60_researchLLMs_05.png"><br></p><ul><li>논문을 넣고 요약해달라고 할 수 있지만, 디테일이 많이 사라집니다.</li><li>논문을 읽는 부담을 줄이면서도 디테일을 살리려면 <b>명확히</b> 요청할 필요가 있습니다.</li><li><b>방법론</b>, <b>독창성</b>, <b>한계점</b> 등등을 형식과 함께 요청합니다.</li></ul><p><img src="60_researchLLMs_06.png"><br></p><ul><li>정보 검색용으로 많이 쓰이는 perplexity도 취합은 LLM으로 합니다.</li><li>틀은 정해주고 내용만 채우라고 하는 식의 프롬프팅은 믿을만한 결과를 냅니다.</li></ul><p><img src="60_researchLLMs_07.png"><br></p><ul><li>이렇게 요청하면</li><li>이렇게 나옵니다.</li></ul><p><img src="60_researchLLMs_08.png"><br></p><ul><li>파일 출력 기능도 매우 요긴합니다.</li><li>LLM의 답변을 어차피 복사해다 어딘가에 붙일 것이라면, 그냥 파일로 달라면 됩니다.</li><li><b>.docx</b>, <b>.pptx</b>출력을 시켜서 일손을 덜 수 있습니다.</li></ul><ul><li>간혹 너무 당연한 걸 못해서 당황스럽기도 합니다.</li><li><b>3.9와 3.11중 무엇이 더 클까?</b></li><li><b>strawberry에는 r이 몇 개 있을까?</b> 같은 질문이 그것입니다.</li><li>이런 일은 코딩을 해서 답을 하라고 하면 잘 합니다.</li><li>다만, 후속 질문에서 어그러지는 경우가 있으니 후속 질문까지 살피는 프롬프팅이 필요합니다.</li></ul><p><img src="60_researchLLMs_09.png"><br></p><ul><li>한 단계 더 나아가 GPTs의 <b>knowledge</b>에 코드를 올리는 것도 가능합니다.</li><li>그러나 <b>.py 파일을 올리면 잘 동작하지 않습니다.</b></li><li>웹 화면에서 입력하는 파일들의 경로와 knowledge 파일이 올라가는 경로가 달라서로 추정됩니다.</li><li>그래서 <b>.whl 파일로 만들어 올리는 것을 추천드립니다.</b></li></ul><p><img src="60_researchLLMs_10.png"><br></p><ul><li>그리고, 이 코드를 사용할 시점이 되면 <b><code>subprocess.run()</code>을 사용해 .whl파일을 설치</b>한 후,</li><li>코드에 들어있는 함수를 호출하라고 명령을 내리면 안정적으로 동작합니다.</li><li>다만 이전의 프롬프트는 이 함수에 들어갈 인자들을 충분히 뽑아 내 주어야 합니다.</li></ul><p><img src="60_researchLLMs_11.png"><br></p><ul><li>용처에 맞게 사전 프롬프트(instruction)과 .whl 파일을 탑재한 GPTs는 따로 실행할 필요가 없습니다.</li><li>일을 하다 <b>@GPTs이름</b>을 부르면 전문가를 초빙하듯 등장해서 해결해줍니다.</li><li>단, 밤낮이 바뀌는 밤에는 잘 동작하지 않습니다. </li><li>서구의 수많은 사용자들이 서버를 점령하기 때문입니다.</li><li><b>웬만하면 해가 떠 있을 때 일을 마치고 제때 잡시다.</b></li></ul><ul><li>제가 만든 4개의 GPTs만으로도 다음과 같은 시나리오를 생각할 수 있습니다.</li><li>인간 전문가들의 영역을 존중하듯 GPTs들의 영역을 존중하여 맡기면 됩니다.</li><li><b>AI Agent들의 협업</b>으로 볼 수 있습니다.</li></ul><p><img src="60_researchLLMs_12.png"><br></p><ul><li>강의자료를 공유합니다. (<a href="240829_%EC%9D%B4%EC%A0%9C%ED%98%84_%EC%97%B0%EA%B5%AC%ED%99%9C%EC%9A%A9%EC%8B%A4%EC%A0%84LLM-%EB%B0%B0%ED%8F%AC%EB%B3%B8.pdf">다운로드 링크</a>)</li><li>모두 시간이 걸리는 일들은 이들에게 맡기고, 본질에 집중하시길 바랍니다.</li></ul><ul><li>한국정보과학회 행사 프로그램</li></ul><p><img src="60_researchLLMs_03.png"><br><img src="60_researchLLMs_01.png"><br><img src="60_researchLLMs_02.png"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/GPTs/">GPTs</category>
      
      <category domain="https://jehyunlee.github.io/tags/presentation/">presentation</category>
      
      
    </item>
    
    <item>
      <title>논문봇 v2 - 출력물 일관성 확보</title>
      <link>https://jehyunlee.github.io/2024/08/19/General-59-paperbot2/</link>
      <guid>https://jehyunlee.github.io/2024/08/19/General-59-paperbot2/</guid>
      <pubDate>Mon, 19 Aug 2024 02:26:00 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;두달 전, 논문봇을 만들었고 잘 쓰고 있습니다.&lt;/li&gt;
&lt;li&gt;scispace와 일장일단이 있는데, 가장 큰 장점은 내 스타일을 반영할 수 있다는 점입니다.&lt;/li&gt;
&lt;li&gt;그런데 보고서 출력시 프롬프트 반영이 랜덤입니다. 이를 해소</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li>두달 전, 논문봇을 만들었고 잘 쓰고 있습니다.</li><li>scispace와 일장일단이 있는데, 가장 큰 장점은 내 스타일을 반영할 수 있다는 점입니다.</li><li>그런데 보고서 출력시 프롬프트 반영이 랜덤입니다. 이를 해소했습니다.</li></ul><blockquote><p><a href="https://jehyunlee.github.io/2024/06/19/General-56-customgpt/">Pega Devlog: 연구용 GPT 만들기 - 논문봇 등</a></p></blockquote><h1 id="1-논문봇-v1"><a href="#1-논문봇-v1" class="headerlink" title="1. 논문봇 v1"></a>1. 논문봇 v1</h1><ul><li>낯선 단어가 뒤덮은 <b>논문의 내용을 읽기 전에 파악할 수 있다는 것</b>은 참으로 편리합니다.</li><li>내 논문읽기 스타일에 맞게 주요 내용을 추출하면,</li><li><b>정독할 논문과 그렇지 않은 논문</b>, <b>발췌독을 한다면 어떤 부분을 발췌할지</b> 빠르게 판단할 수 있습니다.</li><li>논문봇 자체가 GPT에 얹혀있으므로 관련된 질문을 이어서 진행하기도 좋습니다.<br></li></ul><p><img src="59_paperbot2_01.png"></p><ul><li>논문봇은 주요 내용을 화면에만 출력하는 것이 아니라 <b>보고서</b>로도 만들어줍니다.</li><li>DB는 아니더라도 <b>obsidian</b> 등 정보 관리 프로그램의 도움을 얻어 훗날 <b>기억 복원</b>에 쓰고자 하며,</li><li>발표자료 작성 등 2차 가공이나 팀내 공유 등에 활용하기 위함입니다.</li></ul><ul><li>그런데 프롬프트가 엄격히 적용되지 않아 <b>형식이 조금씩 들쭉날쭉합니다.</b></li><li>사람이 보기에는 문제가 없을지 몰라도 나중에 기계로 처리하자면 골칫거리가 될 것입니다.</li><li>가끔은 그냥 눈으로 보기에도 크게 거슬립니다.<br></li></ul><p><img src="59_paperbot2_02.png" alt="같은 논문으로 다섯 번 반복실행한 보고서 형식이 다 다릅니다."><br></p><ul><li>GPT의 확장성을 이용해서 개선해 봅시다.</li></ul><h1 id="2-논문봇-v2"><a href="#2-논문봇-v2" class="headerlink" title="2. 논문봇 v2"></a>2. 논문봇 v2</h1><ul><li>논문봇 v1의 프롬프트는 크게 두 부분으로 구성되어 있습니다.</li><li><b>앞 부분</b>은 논문의 내용을 파악하는 부분,</li><li><b>뒷 부분</b>은 파악된 논문을 정리하는 부분입니다.</li><li>앞 부분은 그대로 두고, 맨 마지막 논문을 보고서로 정리하는 부분만 수정합니다.</li><li>우리의 목적은 <b>재현성</b>이고, 재현성에는 <b>코드 실행</b> 만한 게 없습니다.<br></li></ul><p><img src="59_paperbot2_03.png" alt="여기를 교체합니다."></p><ul><li>그런데 코드는 <b>입력</b>, <b>동작</b>, <b>출력</b>으로 이루어져 있습니다.</li><li>동작을 고치기에 앞서 <b>입력</b>에 들어갈 데이터를 챙깁니다.<br></li></ul><p><img src="59_paperbot2_04.png"></p><ul><li>형식만 지정하던 앞 부분에 비어있던 변수명을 넣어주고, </li><li>방법론, 독창성, 한계점 등 여러 항목이 나오는 것들을 <b>list</b>로 묶으라고 지시합니다.</li><li>표로 표현되는 주요 참고문헌은 형식이 복잡할 수 있습니다. <b>list of dictionary</b>로 지정합니다.<br></li></ul><p><img src="59_paperbot2_05.png" alt="클릭하면 커집니다"></p><ul><li>입력이 준비되었으니 출력을 만드는 코드를 준비합니다.</li><li>논문봇의 출력은 <b>.docx</b>파일입니다.</li><li>GPT의 도움을 받아 원하는 형식으로 서식을 만드는 코드를 작성합니다.</li><li>doi link를 거는 등 작업으로 인해 400줄이 넘어 숨겨두었습니다.<details>  <summary><b>코드 보기/접기</b></summary><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Author: Jehyun Lee</span></span><br><span class="line"><span class="comment"># date  : 2024.08.18.</span></span><br><span class="line"><span class="comment"># email : jehyun.lee@gmail.com</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> docx</span><br><span class="line"><span class="keyword">from</span> docx <span class="keyword">import</span> Document</span><br><span class="line"><span class="keyword">from</span> docx <span class="keyword">import</span> opc</span><br><span class="line"><span class="keyword">from</span> docx.oxml.ns <span class="keyword">import</span> qn</span><br><span class="line"><span class="keyword">from</span> docx.oxml <span class="keyword">import</span> OxmlElement</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> docx.shared <span class="keyword">import</span> Inches, Pt, RGBColor</span><br><span class="line"><span class="keyword">from</span> docx.enum.text <span class="keyword">import</span> WD_ALIGN_PARAGRAPH</span><br><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line"></span><br><span class="line"><span class="comment"># head</span></span><br><span class="line">font_header_name = <span class="string">&quot;Calibri&quot;</span></span><br><span class="line">font_header_size = Pt(<span class="number">14</span>)</span><br><span class="line">font_header_color = RGBColor(<span class="number">64</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># chapter</span></span><br><span class="line">font_chapter_name = <span class="string">&quot;Calibri&quot;</span></span><br><span class="line">font_chapter_size = Pt(<span class="number">12</span>)</span><br><span class="line">font_chapter_color = RGBColor(<span class="number">128</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># body</span></span><br><span class="line">font_body_name = <span class="string">&quot;Calibri&quot;</span></span><br><span class="line">font_body_size = Pt(<span class="number">10</span>)</span><br><span class="line">font_body_color = RGBColor(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertHR</span>(<span class="params">paragraph, color</span>):</span></span><br><span class="line">    p = paragraph._p  <span class="comment"># p is the &lt;w:p&gt; XML element</span></span><br><span class="line">    pPr = p.get_or_add_pPr()</span><br><span class="line">    pBdr = OxmlElement(<span class="string">&#x27;w:pBdr&#x27;</span>)</span><br><span class="line">    pPr.insert_element_before(pBdr,</span><br><span class="line">        <span class="string">&#x27;w:shd&#x27;</span>, <span class="string">&#x27;w:tabs&#x27;</span>, <span class="string">&#x27;w:suppressAutoHyphens&#x27;</span>, <span class="string">&#x27;w:kinsoku&#x27;</span>, <span class="string">&#x27;w:wordWrap&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;w:overflowPunct&#x27;</span>, <span class="string">&#x27;w:topLinePunct&#x27;</span>, <span class="string">&#x27;w:autoSpaceDE&#x27;</span>, <span class="string">&#x27;w:autoSpaceDN&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;w:bidi&#x27;</span>, <span class="string">&#x27;w:adjustRightInd&#x27;</span>, <span class="string">&#x27;w:snapToGrid&#x27;</span>, <span class="string">&#x27;w:spacing&#x27;</span>, <span class="string">&#x27;w:ind&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;w:contextualSpacing&#x27;</span>, <span class="string">&#x27;w:mirrorIndents&#x27;</span>, <span class="string">&#x27;w:suppressOverlap&#x27;</span>, <span class="string">&#x27;w:jc&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;w:textDirection&#x27;</span>, <span class="string">&#x27;w:textAlignment&#x27;</span>, <span class="string">&#x27;w:textboxTightWrap&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;w:outlineLvl&#x27;</span>, <span class="string">&#x27;w:divId&#x27;</span>, <span class="string">&#x27;w:cnfStyle&#x27;</span>, <span class="string">&#x27;w:rPr&#x27;</span>, <span class="string">&#x27;w:sectPr&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;w:pPrChange&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    bottom = OxmlElement(<span class="string">&#x27;w:bottom&#x27;</span>)</span><br><span class="line">    bottom.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:val&#x27;</span>), <span class="string">&#x27;single&#x27;</span>)</span><br><span class="line">    bottom.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:sz&#x27;</span>), <span class="string">&#x27;12&#x27;</span>)</span><br><span class="line">    bottom.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:space&#x27;</span>), <span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">    bottom.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:color&#x27;</span>), color)</span><br><span class="line">    pBdr.append(bottom)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Helper function to add hyperlink (since python-docx does not directly support hyperlinks)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_hyperlink</span>(<span class="params">paragraph, url, text, color=<span class="string">&quot;#0000ff&quot;</span>, underline=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A function that places a hyperlink within a paragraph object.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param paragraph: The paragraph we are adding the hyperlink to.</span></span><br><span class="line"><span class="string">    :param url: A string containing the required url</span></span><br><span class="line"><span class="string">    :param text: The text displayed for the url</span></span><br><span class="line"><span class="string">    :return: The hyperlink object</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># This gets access to the document.xml.rels file and gets a new relation id value</span></span><br><span class="line">    part = paragraph.part</span><br><span class="line">    r_id = part.relate_to(url, docx.opc.constants.RELATIONSHIP_TYPE.HYPERLINK, is_external=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create the w:hyperlink tag and add needed values</span></span><br><span class="line">    hyperlink = docx.oxml.shared.OxmlElement(<span class="string">&#x27;w:hyperlink&#x27;</span>)</span><br><span class="line">    hyperlink.<span class="built_in">set</span>(docx.oxml.shared.qn(<span class="string">&#x27;r:id&#x27;</span>), r_id, )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a w:r element</span></span><br><span class="line">    new_run = docx.oxml.shared.OxmlElement(<span class="string">&#x27;w:r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a new w:rPr element</span></span><br><span class="line">    rPr = docx.oxml.shared.OxmlElement(<span class="string">&#x27;w:rPr&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add color if it is given</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> color <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      c = docx.oxml.shared.OxmlElement(<span class="string">&#x27;w:color&#x27;</span>)</span><br><span class="line">      c.<span class="built_in">set</span>(docx.oxml.shared.qn(<span class="string">&#x27;w:val&#x27;</span>), color)</span><br><span class="line">      rPr.append(c)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove underlining if it is requested</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> underline:</span><br><span class="line">      u = docx.oxml.shared.OxmlElement(<span class="string">&#x27;w:u&#x27;</span>)</span><br><span class="line">      u.<span class="built_in">set</span>(docx.oxml.shared.qn(<span class="string">&#x27;w:val&#x27;</span>), <span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">      rPr.append(u)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Join all the xml elements together add add the required text to the w:r element</span></span><br><span class="line">    new_run.append(rPr)</span><br><span class="line">    new_run.text = text</span><br><span class="line">    hyperlink.append(new_run)</span><br><span class="line"></span><br><span class="line">    paragraph._p.append(hyperlink)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> hyperlink</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply_style</span>(<span class="params">paragraph, style, font_name=<span class="literal">None</span>, font_size=<span class="literal">None</span>, font_color=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> style == <span class="string">&quot;header&quot;</span>:</span><br><span class="line">        paragraph.style.font.name = font_header_name</span><br><span class="line">        paragraph.style.font.size = font_header_size</span><br><span class="line">        paragraph.style.font.color.rgb = font_header_color</span><br><span class="line">    <span class="keyword">elif</span> style == <span class="string">&quot;chapter&quot;</span>:</span><br><span class="line">        paragraph.style.font.name = font_chapter_name</span><br><span class="line">        paragraph.style.font.size = font_chapter_size</span><br><span class="line">        paragraph.style.font.color.rgb = font_chapter_color</span><br><span class="line">    <span class="keyword">elif</span> style == <span class="string">&quot;body&quot;</span>:</span><br><span class="line">        paragraph.style.font.name = font_body_name</span><br><span class="line">        paragraph.style.font.size = font_body_size</span><br><span class="line">        paragraph.style.font.color.rgb = font_body_color</span><br><span class="line"></span><br><span class="line">    <span class="comment"># custom paragraph setting</span></span><br><span class="line">    <span class="keyword">if</span> font_name:</span><br><span class="line">        paragraph.style.font.name = font_name</span><br><span class="line">    <span class="keyword">if</span> font_size:</span><br><span class="line">        paragraph.style.font.size = font_size</span><br><span class="line">    <span class="keyword">if</span> font_color:</span><br><span class="line">        paragraph.style.font.color.rgb = font_color</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_doc</span>(<span class="params">title, year, authors, journal=<span class="string">&quot;&quot;</span>, volume=<span class="string">&quot;&quot;</span>, issue=<span class="string">&quot;&quot;</span>, pageRange=<span class="string">&quot;&quot;</span>, articleNo=<span class="string">&quot;&quot;</span>, doi=<span class="string">&quot;&quot;</span></span>):</span></span><br><span class="line">    <span class="comment"># Create a new Document</span></span><br><span class="line">    doc = Document()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set title</span></span><br><span class="line">    para_title = doc.add_heading(title, <span class="number">1</span>)</span><br><span class="line">    para_title.style.font.name = font_header_name</span><br><span class="line">    para_title.style.font.size = font_header_size</span><br><span class="line">    para_title.style.font.color.rgb = font_header_color</span><br><span class="line">    insertHR(para_title, <span class="string">&quot;#808096&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add authors and journal information</span></span><br><span class="line">    para_authors = doc.add_paragraph(style=<span class="string">&#x27;List Bullet&#x27;</span>)</span><br><span class="line">    para_authors.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">    para_authors.style.font.name = font_body_name</span><br><span class="line">    para_authors.style.font.size = font_body_size</span><br><span class="line">    para_authors.style.font.color.rgb = font_body_color</span><br><span class="line">    run = para_authors.add_run(authors)</span><br><span class="line">    run.italic=<span class="literal">True</span></span><br><span class="line">    </span><br><span class="line">    journal_info = <span class="string">f&quot;<span class="subst">&#123;journal&#125;</span> <span class="subst">&#123;volume&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">if</span> issue <span class="keyword">and</span> <span class="built_in">len</span>(issue) &gt; <span class="number">1</span>:</span><br><span class="line">        journal_info += <span class="string">f&quot;, (<span class="subst">&#123;issue&#125;</span>)&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pageRange <span class="keyword">and</span> <span class="built_in">len</span>(pageRange) &gt; <span class="number">1</span>:</span><br><span class="line">        journal_info += <span class="string">f&quot;, <span class="subst">&#123;pageRange&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">if</span> articleNo <span class="keyword">and</span> <span class="built_in">len</span>(articleNo) &gt; <span class="number">1</span>:</span><br><span class="line">        journal_info += <span class="string">f&quot;, <span class="subst">&#123;articleNo&#125;</span>&quot;</span></span><br><span class="line">    journal_info += <span class="string">f&quot; (<span class="subst">&#123;year&#125;</span>)&quot;</span></span><br><span class="line">    para_journal_info = doc.add_paragraph(journal_info, style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">    para_journal_info.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">    para_journal_info.style.font.name = font_body_name</span><br><span class="line">    para_journal_info.style.font.size = font_body_size</span><br><span class="line">    para_journal_info.style.font.color.rgb = font_body_color</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># doi and link</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(doi) &gt; <span class="number">1</span> <span class="keyword">and</span> <span class="keyword">not</span> doi.startswith(<span class="string">&quot;https://doi.org/&quot;</span>):</span><br><span class="line">        doi = <span class="string">&quot;https://doi.org/&quot;</span> + doi</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(doi) &gt; <span class="number">1</span> <span class="keyword">and</span> doi.startswith(<span class="string">&quot;https://doi.org/&quot;</span>):</span><br><span class="line">        doi = doi</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(doi) &gt; <span class="number">1</span>:</span><br><span class="line">        para_doi = doc.add_paragraph(<span class="string">&quot;DOI: &quot;</span>, style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">        para_doi.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">        para_doi.style.font.name = font_body_name</span><br><span class="line">        para_doi.style.font.size = font_body_size</span><br><span class="line">        para_doi.style.font.color.rgb = font_body_color</span><br><span class="line">        add_hyperlink(para_doi, doi, doi)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># empty line</span></span><br><span class="line">    run = para_doi.add_run()</span><br><span class="line">    run.add_break() </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> doc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_cell_border</span>(<span class="params">cell, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Set cell border</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tc = cell._tc</span><br><span class="line">    tcPr = tc.get_or_add_tcPr()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> edge <span class="keyword">in</span> [<span class="string">&#x27;top&#x27;</span>, <span class="string">&#x27;left&#x27;</span>, <span class="string">&#x27;bottom&#x27;</span>, <span class="string">&#x27;right&#x27;</span>]:</span><br><span class="line">        edge_data = kwargs.get(edge)</span><br><span class="line">        <span class="keyword">if</span> edge_data:</span><br><span class="line">            tag = <span class="string">&#x27;w:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(edge)</span><br><span class="line">            element = OxmlElement(tag)</span><br><span class="line">            element.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:val&#x27;</span>), edge_data.get(<span class="string">&#x27;val&#x27;</span>, <span class="string">&#x27;single&#x27;</span>))</span><br><span class="line">            element.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:sz&#x27;</span>), <span class="built_in">str</span>(edge_data.get(<span class="string">&#x27;sz&#x27;</span>, <span class="number">4</span>)))</span><br><span class="line">            element.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:space&#x27;</span>), <span class="built_in">str</span>(edge_data.get(<span class="string">&#x27;space&#x27;</span>, <span class="number">0</span>)))</span><br><span class="line">            color = edge_data.get(<span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(color, <span class="built_in">tuple</span>):</span><br><span class="line">                color = <span class="string">&#x27;%02x%02x%02x&#x27;</span> % color</span><br><span class="line">            element.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:color&#x27;</span>), color)</span><br><span class="line">            tcPr.append(element)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_reference_table</span>(<span class="params">doc, references</span>):</span></span><br><span class="line">    <span class="keyword">for</span> ref <span class="keyword">in</span> references:</span><br><span class="line">        table = doc.add_table(rows=<span class="number">1</span>, cols=<span class="number">1</span>)</span><br><span class="line">        table.style = <span class="string">&#x27;Table Grid&#x27;</span></span><br><span class="line">        cell = table.cell(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set cell border with gray color</span></span><br><span class="line">        gray_color = (<span class="number">128</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        set_cell_border(</span><br><span class="line">            cell,</span><br><span class="line">            top=&#123;<span class="string">&quot;sz&quot;</span>: <span class="number">4</span>, <span class="string">&quot;val&quot;</span>: <span class="string">&quot;single&quot;</span>, <span class="string">&quot;color&quot;</span>: gray_color&#125;,</span><br><span class="line">            bottom=&#123;<span class="string">&quot;sz&quot;</span>: <span class="number">4</span>, <span class="string">&quot;val&quot;</span>: <span class="string">&quot;single&quot;</span>, <span class="string">&quot;color&quot;</span>: gray_color&#125;,</span><br><span class="line">            start=&#123;<span class="string">&quot;sz&quot;</span>: <span class="number">4</span>, <span class="string">&quot;val&quot;</span>: <span class="string">&quot;single&quot;</span>, <span class="string">&quot;color&quot;</span>: gray_color&#125;,</span><br><span class="line">            end=&#123;<span class="string">&quot;sz&quot;</span>: <span class="number">4</span>, <span class="string">&quot;val&quot;</span>: <span class="string">&quot;single&quot;</span>, <span class="string">&quot;color&quot;</span>: gray_color&#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Add citation point</span></span><br><span class="line">        p_point = cell.paragraphs[<span class="number">0</span>]</span><br><span class="line">        run = p_point.add_run(<span class="string">f&quot;  ※ <span class="subst">&#123;ref[<span class="string">&#x27;citation point&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">        p_point.style.font.name = font_body_name</span><br><span class="line">        p_point.style.font.size = font_body_size</span><br><span class="line">        <span class="comment"># p_point.style.font.color.rgb = RGBColor(64, 128, 128)</span></span><br><span class="line">        run.bold = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add authors</span></span><br><span class="line">        p = cell.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">        p.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(ref[<span class="string">&#x27;authors&#x27;</span>], <span class="built_in">list</span>):</span><br><span class="line">            ref[<span class="string">&#x27;authors&#x27;</span>] = <span class="string">&quot;, &quot;</span>.join(ref[<span class="string">&#x27;authors&#x27;</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        p.add_run(<span class="string">f&quot;<span class="subst">&#123;ref[<span class="string">&#x27;authors&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">        p.style.font.name = font_body_name</span><br><span class="line">        p.style.font.size = font_body_size</span><br><span class="line">        p.style.font.color.rgb = font_body_color</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add title</span></span><br><span class="line">        p = cell.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">        p.add_run(<span class="string">f&quot;\&quot;<span class="subst">&#123;ref[<span class="string">&#x27;title&#x27;</span>]&#125;</span>\&quot;&quot;</span>)</span><br><span class="line">        p.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">        p.style.font.name = font_body_name</span><br><span class="line">        p.style.font.size = font_body_size</span><br><span class="line">        p.style.font.color.rgb = font_body_color</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add journal and year</span></span><br><span class="line">        p = cell.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">        run = p.add_run(<span class="string">f&quot;<span class="subst">&#123;ref[<span class="string">&#x27;journal&#x27;</span>]&#125;</span> &quot;</span>)</span><br><span class="line">        run.italic = <span class="literal">True</span></span><br><span class="line">        p.add_run(<span class="string">f&quot;(<span class="subst">&#123;ref[<span class="string">&#x27;year&#x27;</span>]&#125;</span>). &quot;</span>)</span><br><span class="line">        p.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">        p.style.font.name = font_body_name</span><br><span class="line">        p.style.font.size = font_body_size</span><br><span class="line">        p.style.font.color.rgb = font_body_color</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add DOI with hyperlink</span></span><br><span class="line">        add_hyperlink(p, <span class="string">f&quot;https://doi.org/<span class="subst">&#123;ref[<span class="string">&#x27;doi&#x27;</span>]&#125;</span>&quot;</span>, ref[<span class="string">&#x27;doi&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add empty line</span></span><br><span class="line">        cell.add_paragraph()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> doc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_content</span>(<span class="params">doc, purpose, contribution_academic, contribution_industrial, method_names, method_explanations, </span></span></span><br><span class="line"><span class="params"><span class="function">                originality_names, originality_explanations, limitation_names, limitation_explanations, references</span>):</span></span><br><span class="line">    <span class="comment"># Research purpose</span></span><br><span class="line">    para = doc.add_paragraph()</span><br><span class="line">    run = para.add_run(<span class="string">&quot;1. 연구 목적&quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    para.style.font.name = font_chapter_name</span><br><span class="line">    para.style.font.size = font_chapter_size</span><br><span class="line">    para.style.font.color.rgb = font_chapter_color</span><br><span class="line"></span><br><span class="line">    para_purpose = doc.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">    para_purpose.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">    para_purpose.add_run(purpose)</span><br><span class="line">    apply_style(para_purpose, <span class="string">&quot;body&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Academic and Industrial Contributions</span></span><br><span class="line">    para = doc.add_paragraph()</span><br><span class="line">    run = para.add_run(<span class="string">&quot;2. 학문적 및 산업적 기여&quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    para.style.font.name = font_chapter_name</span><br><span class="line">    para.style.font.size = font_chapter_size</span><br><span class="line">    para.style.font.color.rgb = font_chapter_color</span><br><span class="line"></span><br><span class="line">    para_contribution_academic = doc.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">    para_contribution_academic.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">    para_contribution_academic.style.font.name = font_body_name</span><br><span class="line">    para_contribution_academic.style.font.size = font_body_size</span><br><span class="line">    para_contribution_academic.style.font.color.rgb = font_body_color</span><br><span class="line">    run = para_contribution_academic.add_run(<span class="string">&quot;학문적 기여: &quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(contribution_academic, <span class="built_in">list</span>):</span><br><span class="line">        para_contribution_academic.add_run(</span><br><span class="line">            *contribution_academic</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        para_contribution_academic.add_run(</span><br><span class="line">            contribution_academic</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    para_contribution_industrial = doc.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">    para_contribution_industrial.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">    para_contribution_industrial.style.font.name = font_body_name</span><br><span class="line">    para_contribution_industrial.style.font.size = font_body_size</span><br><span class="line">    para_contribution_industrial.style.font.color.rgb = font_body_color</span><br><span class="line">    run = para_contribution_industrial.add_run(<span class="string">&quot;산업적 기여: &quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(contribution_industrial, <span class="built_in">list</span>):</span><br><span class="line">        para_contribution_industrial.add_run(</span><br><span class="line">            *contribution_industrial,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        para_contribution_industrial.add_run(</span><br><span class="line">            contribution_industrial,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Methods</span></span><br><span class="line">    para = doc.add_paragraph()</span><br><span class="line">    run = para.add_run(<span class="string">&quot;3. 방법론&quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    para.style.font.name = font_chapter_name</span><br><span class="line">    para.style.font.size = font_chapter_size</span><br><span class="line">    para.style.font.color.rgb = font_chapter_color</span><br><span class="line">    <span class="keyword">for</span> name, expl <span class="keyword">in</span> <span class="built_in">zip</span>(method_names, method_explanations):</span><br><span class="line">        para_method = doc.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">        para_method.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">        para_method.style.font.name = font_body_name</span><br><span class="line">        para_method.style.font.size = font_body_size</span><br><span class="line">        para_method.style.font.color.rgb = font_body_color</span><br><span class="line">        run = para_method.add_run(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: &quot;</span>)</span><br><span class="line">        run.bold = <span class="literal">True</span></span><br><span class="line">        para_method.add_run(</span><br><span class="line">            expl</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Originality</span></span><br><span class="line">    para = doc.add_paragraph()</span><br><span class="line">    run = para.add_run(<span class="string">&quot;4. 독창성&quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    para.style.font.name = font_chapter_name</span><br><span class="line">    para.style.font.size = font_chapter_size</span><br><span class="line">    para.style.font.color.rgb = font_chapter_color</span><br><span class="line">    <span class="keyword">for</span> name, expl <span class="keyword">in</span> <span class="built_in">zip</span>(originality_names, originality_explanations):</span><br><span class="line">        para_originality = doc.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">        para_originality.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">        para_originality.style.font.name = font_body_name</span><br><span class="line">        para_originality.style.font.size = font_body_size</span><br><span class="line">        para_originality.style.font.color.rgb = font_body_color</span><br><span class="line">        run = para_originality.add_run(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: &quot;</span>)</span><br><span class="line">        run.bold = <span class="literal">True</span></span><br><span class="line">        para_originality.add_run(</span><br><span class="line">            expl</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Limitation</span></span><br><span class="line">    para = doc.add_paragraph()</span><br><span class="line">    run = para.add_run(<span class="string">&quot;5. 한계점&quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    para.style.font.name = font_chapter_name</span><br><span class="line">    para.style.font.size = font_chapter_size</span><br><span class="line">    para.style.font.color.rgb = font_chapter_color</span><br><span class="line">    <span class="keyword">for</span> name, expl <span class="keyword">in</span> <span class="built_in">zip</span>(limitation_names, limitation_explanations):</span><br><span class="line">        para_limitation = doc.add_paragraph(style=<span class="string">&quot;List Bullet&quot;</span>)</span><br><span class="line">        para_limitation.paragraph_format.left_indent = Inches(<span class="number">0.5</span>)</span><br><span class="line">        para_limitation.style.font.name = font_body_name</span><br><span class="line">        para_limitation.style.font.size = font_body_size</span><br><span class="line">        para_limitation.style.font.color.rgb = font_body_color</span><br><span class="line">        run = para_limitation.add_run(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: &quot;</span>)</span><br><span class="line">        run.bold = <span class="literal">True</span></span><br><span class="line">        para_limitation.add_run(</span><br><span class="line">            expl</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># References</span></span><br><span class="line">    para = doc.add_paragraph()</span><br><span class="line">    run = para.add_run(<span class="string">&quot;6. 주요 레퍼런스&quot;</span>)</span><br><span class="line">    run.bold = <span class="literal">True</span></span><br><span class="line">    para.style.font.name = font_chapter_name</span><br><span class="line">    para.style.font.size = font_chapter_size</span><br><span class="line">    para.style.font.color.rgb = font_chapter_color</span><br><span class="line">    doc = add_reference_table(doc, references)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> doc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_doc</span>(<span class="params">doc, authors, journal, year</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the document</span></span><br><span class="line">    today_date = datetime.today().strftime(<span class="string">&#x27;%Y%m%d&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(authors, <span class="built_in">str</span>):</span><br><span class="line">        authors = authors.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    filename = <span class="string">f&quot;<span class="subst">&#123;today_date&#125;</span>_<span class="subst">&#123;authors[<span class="number">0</span>].replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)&#125;</span>_<span class="subst">&#123;journal.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)&#125;</span>_<span class="subst">&#123;year&#125;</span>.docx&quot;</span></span><br><span class="line"></span><br><span class="line">    working_path = os.getcwd()</span><br><span class="line">    filename = os.path.join(working_path, filename)</span><br><span class="line">    doc.save(filename)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_doc</span>(<span class="params">title, year, authors, journal=<span class="string">&quot;&quot;</span>, volume=<span class="string">&quot;&quot;</span>, issue=<span class="string">&quot;&quot;</span>, pageRange=<span class="string">&quot;&quot;</span>, articleNo=<span class="string">&quot;&quot;</span>, doi=<span class="string">&quot;&quot;</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">            purpose=<span class="string">&quot;&quot;</span>, contribution_academic=<span class="string">&quot;&quot;</span>, contribution_industrial=<span class="string">&quot;&quot;</span>, method_names=[], method_explanations=[], </span></span></span><br><span class="line"><span class="params"><span class="function">            originality_names=[], originality_explanations=[], limitation_names=[], limitation_explanations=[], references=[]</span>):</span></span><br><span class="line">    doc = init_doc(title, year, authors, journal, volume, issue, pageRange, articleNo, doi)</span><br><span class="line">    doc = add_content(doc, purpose, contribution_academic, contribution_industrial, method_names, method_explanations, originality_names, originality_explanations, limitation_names, limitation_explanations, references)</span><br><span class="line">    filename = save_doc(doc, authors, journal, year)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Document created: <span class="subst">&#123;filename&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> filename</span><br></pre></td></tr></table></figure></li></ul><br><ul><li><b>문서를 초기화</b>하고(<code>init_doc</code>), <b>내용을 추가</b>한 후(<code>add_content</code>), <b>파일로 저장</b>하는(<code>save_doc</code>) 3단 구성입니다.</li><li><b>조금 많이 아쉬운 점</b>이 있는데, hard coding이 심하게 되어 있다는 점입니다.</li><li>사용자가 추출 프롬프트를 수정함에 따라 동적으로 반응하는 코드를 짰으면 좋았을텐데,</li><li>구성을 조금 더 체계적으로 하지 못한 탓입니다.</li><li>다음 번 작업으로 미루도록 해야겠습니다.</li></ul><ul><li><p>코드의 마지막 부분은 <b>파일명</b>을 출력하게 되어 있습니다.</p></li><li><p><code>save_doc()</code> 코드는 다음과 같습니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def save_doc(doc, authors, journal, year):</span><br><span class="line"></span><br><span class="line">    # Save the document</span><br><span class="line">    today_date = datetime.today().strftime(&#x27;%Y%m%d&#x27;)</span><br><span class="line">    if isinstance(authors, str):</span><br><span class="line">        authors = authors.split(&quot;,&quot;)</span><br><span class="line">    filename = f&quot;&#123;today_date&#125;_&#123;authors[0].replace(&#x27; &#x27;, &#x27;&#x27;)&#125;_&#123;journal.replace(&#x27; &#x27;, &#x27;&#x27;)&#125;_&#123;year&#125;.docx&quot;</span><br><span class="line"></span><br><span class="line">    working_path = os.getcwd()</span><br><span class="line">    filename = os.path.join(working_path, filename)</span><br><span class="line">    doc.save(filename)</span><br><span class="line"></span><br><span class="line">    return filename</span><br></pre></td></tr></table></figure></li><li><p><code>filename</code>에 <code>working_path</code>를 붙이는 부분이 있는데,</p></li><li><p>종종 입력 논문은 <code>/mnt/data/</code>에 올라가는 데 반해</p></li><li><p>파일 출력은 <code>/home/sandbox/</code>에 실행해 놓고, </p></li><li><p><code>/mnt/data/</code>로 시작하는 링크를 줄 때가 생기기 때문입니다.</p></li><li><p>이러면 <b>파일을 출력했는데 다운로드 링크가 동작하지 않는 상황</b>이 되어 몹시 난감합니다.</p></li></ul><ul><li>이제 <b>GPTs Knowledge</b>에 이 코드를 올리고 실행할 차례입니다.</li><li>아래 그림과 같이 .py를 올리고 아래의 <b>Code Interpreter &amp; Data Analysis</b>를 체크합니다.<br></li></ul><p><img src="59_paperbot2_06.png"></p><ul><li>이제 프롬프트에 파일 출력시 이 코드를 실행하라고 하면 될 것 같은데,</li><li><b>제대로 안 돌아갑니다.</b></li><li>오작동인지 알 수 없으나 경험상 50% 이상의 확률로 실행되지 않습니다.</li><li><b>PDF를 찾기 전에는 잘 읽던 .py 파일을 PDF를 읽은 뒤엔 못 찾습니다.</b></li><li>대신, .py 대신 <b>.whl</b>(<a href="paperbot-0.13-py3-none-any.whl">다운로드</a>)로 만들어 올리면 잘 동작합니다.</li></ul><p><img src="59_paperbot2_07.png"></p><ul><li>이제 프롬프트를 여기에 맞게 수정합니다.</li><li>.whl 파일을 설치하고 실행하도록 코드를 적어줍니다.<br></li></ul><p><img src="59_paperbot2_08.png" alt="클릭하면 커집니다"></p><h1 id="3-테스트"><a href="#3-테스트" class="headerlink" title="3. 테스트"></a>3. 테스트</h1><ul><li>논문봇에 2010년 논문을 한 편 넣어봅니다.</li><li>자율화실험실(autonomous lab)의 선조격인 논문입니다.<br></li></ul><p><img src="59_paperbot2_11.png"></p><ul><li>논문봇이 <b>정상적으로 .docx 파일을 출력</b>했고 ([다운로드],(20240819_AndrewSparkes_AutomatedExperimentation_2010.docx))</li><li><b>보고서 구성</b>은 다음과 같습니다.</li></ul><p><img src="59_paperbot2_09.png"><br><img src="59_paperbot2_10.png"></p><ul><li>한 논문을 여러 차례 입력해도,</li><li>다른 논문들을 차례차례 입력해도 <b>형식 재현성이 확보</b>되었습니다.</li></ul><p><img src="59_paperbot2_12.png" alt="클릭하면 커집니다"></p>]]></content:encoded>
      
      
      <category domain="https://jehyunlee.github.io/categories/General/">General</category>
      
      
      <category domain="https://jehyunlee.github.io/tags/chatgpt/">chatgpt</category>
      
      <category domain="https://jehyunlee.github.io/tags/RAG/">RAG</category>
      
      <category domain="https://jehyunlee.github.io/tags/pyhon/">pyhon</category>
      
      
    </item>
    
  </channel>
</rss>
