<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />

    

    
    <title>pytorch &amp; sklearn pipeline | Pega Devlog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="pytorch,sklearn,pipeline,neural network" />
    
    <meta name="description" content="저는 tabular data를 다룹니다. 간혹 딥러닝을 하고 싶지만 표준화등 전처리도 해야 합니다. 범주형 변수를 인코딩해서 feature importance도 보고 싶습니다. skorch(sklearn + pytorch)를 사용하면 가능합니다.  1. skorch &#x3D; sklearn + pytorch  skorch documentationskorch tu">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch &amp; sklearn pipeline">
<meta property="og:url" content="https://jehyunlee.github.io/2021/09/29/Python-DL-7-skorch_pipeline/index.html">
<meta property="og:site_name" content="Pega Devlog">
<meta property="og:description" content="저는 tabular data를 다룹니다. 간혹 딥러닝을 하고 싶지만 표준화등 전처리도 해야 합니다. 범주형 변수를 인코딩해서 feature importance도 보고 싶습니다. skorch(sklearn + pytorch)를 사용하면 가능합니다.  1. skorch &#x3D; sklearn + pytorch  skorch documentationskorch tu">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jehyunlee.github.io/thumbnails/Python-DL/7_skorch_pipeline_0.png">
<meta property="article:published_time" content="2021-09-29T02:57:00.000Z">
<meta property="article:modified_time" content="2021-09-30T03:43:16.325Z">
<meta property="article:author" content="Jehyun Lee">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="sklearn">
<meta property="article:tag" content="pipeline">
<meta property="article:tag" content="neural network">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jehyunlee.github.io/thumbnails/Python-DL/7_skorch_pipeline_0.png">
    
	<link rel="canonical" href="https://jehyunlee.github.io/2021/09/29/python-dl-7-skorch_pipeline/"/>

    
        <link rel="alternate" href="https://jehyunlee.github.io/rss2.xml" title="Pega Devlog" type="application/atom+xml" />
    

    
        <link rel="icon" href="/images/favicon-32x32.png" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/titillium-web/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">


    
<script src="/libs/jquery/3.5.0/jquery.min.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-155262264-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-155262264-1');
</script>
<!-- End Google Analytics -->

    
    
    


<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                    <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/GIS/">GIS</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/GIS/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/GIS/QGIS/">QGIS</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/ImageJ/">ImageJ</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/ImageJ/Cookbook/">Cookbook</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/ImageJ/Tutorial/">Tutorial</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/Data-Science/">Data Science</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/Deep-Learning/">Deep Learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/General/">General</a></li></ul></li></ul>
                                
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/Python/">Python</a><i class="icon fa fa-angle-right"></i><a class="page-title-link" href="/categories/Python/Deep-Learning/">Deep Learning</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-Python-DL-7-skorch_pipeline" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        pytorch &amp; sklearn pipeline
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2021/09/29/Python-DL-7-skorch_pipeline/" class="article-date">
       <time datetime="2021-09-29T02:57:00.000Z" itemprop="datePublished">2021-09-29</time>
    </a>
  </div>


<div class="article-date">
  <i class="fa fa-calendar-plus-o"></i>
  <a href="/2021/09/29/Python-DL-7-skorch_pipeline/" class="article-date">
     <time datetime="2021-09-30T03:43:16.325Z" itemprop="dateModified">2021-09-30</time>
  </a>
</div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/neural-network/" rel="tag">neural network</a>, <a class="tag-link-link" href="/tags/pipeline/" rel="tag">pipeline</a>, <a class="tag-link-link" href="/tags/pytorch/" rel="tag">pytorch</a>, <a class="tag-link-link" href="/tags/sklearn/" rel="tag">sklearn</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <ul>
<li>저는 tabular data를 다룹니다.</li>
<li>간혹 딥러닝을 하고 싶지만 표준화등 전처리도 해야 합니다.</li>
<li>범주형 변수를 인코딩해서 feature importance도 보고 싶습니다.</li>
<li>skorch(sklearn + pytorch)를 사용하면 가능합니다.</li>
</ul>
<h1 id="1-skorch-sklearn-pytorch"><a href="#1-skorch-sklearn-pytorch" class="headerlink" title="1. skorch = sklearn + pytorch"></a>1. skorch = sklearn + pytorch</h1><p><img src="7_skorch_pipeline.png"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://skorch.readthedocs.io/en/stable/index.html">skorch documentation</a><br><a target="_blank" rel="noopener" href="https://skorch.readthedocs.io/en/stable/user/tutorials.html">skorch tutorials</a></p>
</blockquote>
<ul>
<li>저같은 사람들을 위해 skorch라는 라이브러리가 있습니다.</li>
<li>scikit-learn의 장점인 <b>grid search 등을 딥러닝과 함께</b> 사용할 수 있고</li>
<li>tutorial에서 transfer learning, U-Net, Seq2Seq 등을 지원합니다.<br><br><img src="7_skorch_pipeline_9.png"><br></li>
</ul>
<h1 id="2-sklearn-pipeline"><a href="#2-sklearn-pipeline" class="headerlink" title="2. sklearn pipeline"></a>2. sklearn pipeline</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">scikit-learn.pipeline.Pipeline</a></p>
</blockquote>
<ul>
<li>scikit-learn의 파이프라인은 데이터 전처리에서 발생하는 불확실성을 줄여줍니다.</li>
<li>데이터가 거쳐갈 길을 단단하게 만들어줌으로써 실수를 사전에 예방할 수 있습니다.</li>
<li>특히 PCA나 One-hot encoding처럼 <b>trainset의 정보를 기억해서 testset에 적용해야 할 때 좋습니다</b>.</li>
</ul>
<h2 id="2-1-예제-데이터셋"><a href="#2-1-예제-데이터셋" class="headerlink" title="2.1. 예제 데이터셋"></a>2.1. 예제 데이터셋</h2><ul>
<li>펭귄 데이터셋을 사용해서 펭귄 체중 예측모델을 만들어 봅니다.</li>
<li>편의를 위해 결측치까지 싹 지운 채로 시작합니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 시각화 설정</span></span><br><span class="line">sns.set_context(<span class="string">&quot;talk&quot;</span>)</span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line">font_title = &#123;<span class="string">&quot;color&quot;</span>:<span class="string">&quot;gray&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Linux 한글 사용 설정</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>]=[<span class="string">&#x27;NanumGothic&#x27;</span>, <span class="string">&#x27;sans-serif&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 펭귄 데이터셋 불러오기</span></span><br><span class="line">df_peng = sns.load_dataset(<span class="string">&quot;penguins&quot;</span>)</span><br><span class="line">df_peng.dropna(inplace=<span class="literal">True</span>)</span><br><span class="line">df_peng.isna().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></li>
<li>실행 결과: 결측치가 모두 제거되었습니다.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">species              0</span><br><span class="line">island               0</span><br><span class="line">bill_length_mm       0</span><br><span class="line">bill_depth_mm        0</span><br><span class="line">flipper_length_mm    0</span><br><span class="line">body_mass_g          0</span><br><span class="line">sex                  0</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></li>
</ul>
<ul>
<li>데이터셋을 준비합니다.</li>
<li>펭귄 체중만 y, 나머지는 모두 X입니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = df_peng[<span class="string">&quot;body_mass_g&quot;</span>]</span><br><span class="line">X = df_peng.drop(<span class="string">&quot;body_mass_g&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line">X.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<img src="7_skorch_pipeline_10.png"><br></li>
</ul>
<ul>
<li>trainset과 testset으로 나눕니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-2-pipeline-구축"><a href="#2-2-pipeline-구축" class="headerlink" title="2.2. pipeline 구축"></a>2.2. pipeline 구축</h2><ul>
<li>scikit-learn으로 pipeline을 구축합니다.</li>
<li>numerical feature는 회귀모델 적용을 고려한 <code>PolynomialFeatures</code>와</li>
<li>데이터 정규화를 위한 <code>RobustScaler</code>를 거칩니다.</li>
<li>categorical feature는 <code>OneHotEncoder</code>를 거칩니다.</li>
</ul>
<ul>
<li><p>필요한 라이브러리를 불러옵니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoder</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># machine learning models</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line"><span class="comment"># pipeline</span></span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"></span><br><span class="line"><span class="comment"># metrics</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br></pre></td></tr></table></figure></li>
<li><p>pipeline을 구축하는 함수를 만듭니다.</p>
</li>
<li><p><code>get_model_0()</code>을 실행하면 파이프라인이 만들어질 것입니다.</p>
</li>
<li><p>전처리 후 머신러닝 모델로는 선형회귀와 랜덤포레스트를 선택할 수 있습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model_0</span>(<span class="params">X_cols, degree=<span class="number">1</span>, method=<span class="string">&quot;lr&quot;</span></span>):</span></span><br><span class="line">    </span><br><span class="line">    X_cols_ = deepcopy(X_cols)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1-1.categorical feature에 one-hot encoding 적용</span></span><br><span class="line">    cat_features = <span class="built_in">list</span>(<span class="built_in">set</span>(X_cols) &amp; <span class="built_in">set</span>([<span class="string">&quot;species&quot;</span>, <span class="string">&quot;island&quot;</span>, <span class="string">&quot;sex&quot;</span>]))</span><br><span class="line">    cat_transformer = OneHotEncoder(sparse=<span class="literal">False</span>, handle_unknown=<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1-2.numerical feature는 Power Transform과 Scaler를 거침</span></span><br><span class="line">    num_features = <span class="built_in">list</span>(<span class="built_in">set</span>(X_cols) - <span class="built_in">set</span>(cat_features))</span><br><span class="line">    num_features.sort()</span><br><span class="line">    num_transformer = Pipeline(steps=[(<span class="string">&quot;polynomial&quot;</span>, PolynomialFeatures(degree=degree)), </span><br><span class="line">                                      (<span class="string">&quot;scaler&quot;</span>, RobustScaler())</span><br><span class="line">                                     ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 인자 종류별 전처리 적용</span></span><br><span class="line">    preprocessor = ColumnTransformer(transformers=[(<span class="string">&quot;num&quot;</span>, num_transformer, num_features), </span><br><span class="line">                                                   (<span class="string">&quot;cat&quot;</span>, cat_transformer, cat_features)])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 전처리 후 머신러닝 모델 적용</span></span><br><span class="line">    <span class="keyword">if</span> method == <span class="string">&quot;lr&quot;</span>:</span><br><span class="line">        ml = LinearRegression(fit_intercept=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&quot;rf&quot;</span>:</span><br><span class="line">        ml = RandomForestRegressor()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 3. Pipeline</span></span><br><span class="line">    model = Pipeline(steps=[(<span class="string">&quot;preprocessor&quot;</span>, preprocessor), </span><br><span class="line">                            (<span class="string">&quot;ml&quot;</span>, ml)])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></li>
<li><p>6번째, 10번째 행을 보시면 조금 특이한 처리가 들어가 있습니다.</p>
</li>
<li><p><b>feature selection에 사용되는 장치</b>입니다.</p>
</li>
<li><p>feature 이름들을 하드코딩하면 feature selection이 불가능하기 때문에 이렇게 합니다.</p>
</li>
</ul>
<ul>
<li>만들어진 구조를 확인합니다.</li>
<li>일단 모든 인자를 모두 입력합니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> set_config</span><br><span class="line">set_config(display=<span class="string">&#x27;diagram&#x27;</span>)</span><br><span class="line">model_0 = get_model_0(<span class="built_in">list</span>(X_train.columns), degree=<span class="number">1</span>, method=<span class="string">&quot;lr&quot;</span>)</span><br><span class="line">model_0</span><br></pre></td></tr></table></figure>
<img src="7_skorch_pipeline_11.png"><br></li>
</ul>
<h2 id="2-3-pipeline-전처리-확인"><a href="#2-3-pipeline-전처리-확인" class="headerlink" title="2.3. pipeline 전처리 확인"></a>2.3. pipeline 전처리 확인</h2><ul>
<li>pipeline에서 전처리 모듈만 떼어서 실행합니다.</li>
<li>pipeline의 모듈을 호출하는 방법은 <b>모델이름[“모듈이름”]</b>입니다.</li>
<li>따라서 우리의 전처리 모듈은 <b>model_0[“preprocessor”]</b>입니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_train_pp = model_0[<span class="string">&quot;preprocessor&quot;</span>].fit_transform(X_train)</span><br><span class="line"><span class="built_in">print</span>(X_train_pp.shape)</span><br><span class="line">X_train_pp[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></li>
<li>실행 결과: 첫 행만 찍어봤습니다. <b>숫자가 많습니다</b><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">266</span>, <span class="number">12</span>)</span><br><span class="line">array([ <span class="number">0.</span>        , -<span class="number">0.80645161</span>,  <span class="number">0.08579088</span>,  <span class="number">1.</span>        ,  <span class="number">1.</span>        ,</span><br><span class="line">        <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ,</span><br><span class="line">        <span class="number">0.</span>        ,  <span class="number">1.</span>        ])</span><br></pre></td></tr></table></figure></li>
</ul>
<ul>
<li>6개의 인자를 넣었는데 12개가 나왔습니다.</li>
<li>처음의 0은 LinearRegression에서 만든 intercept 항입니다.</li>
<li>네번째 1부터는 species, island, sex의 one-hot encoding 결과물입니다.</li>
</ul>
<ul>
<li>전처리 이후 데이터 분포도 확인합니다.</li>
<li>시각화 코드는 다소 길고, 여기선 중요하지 않아서 접었습니다.<details>
  <summary><b>코드 보기/접기</b></summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Figure 생성</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>), constrained_layout=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Subfigures 생성</span></span><br><span class="line">subfigs = fig.subfigures(nrows=<span class="number">2</span>, wspace=<span class="number">0.05</span>)</span><br><span class="line">subfigs[<span class="number">0</span>].set_facecolor(<span class="string">&quot;lightgray&quot;</span>)</span><br><span class="line">subfigs[<span class="number">1</span>].set_facecolor(<span class="string">&quot;beige&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># subfigs[0]: raw data</span></span><br><span class="line">axs0 = subfigs[<span class="number">0</span>].subplots(ncols=<span class="number">3</span>, nrows=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">sns.kdeplot(X_train[<span class="string">&quot;bill_depth_mm&quot;</span>], cut=<span class="number">0</span>, fill=<span class="literal">True</span>, ax=axs0[<span class="number">0</span>])</span><br><span class="line">sns.kdeplot(X_train[<span class="string">&quot;bill_length_mm&quot;</span>], cut=<span class="number">0</span>, fill=<span class="literal">True</span>, ax=axs0[<span class="number">1</span>])</span><br><span class="line">sns.kdeplot(X_train[<span class="string">&quot;flipper_length_mm&quot;</span>], cut=<span class="number">0</span>, fill=<span class="literal">True</span>, ax=axs0[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># subfigs[1]: preprocessed data</span></span><br><span class="line">axs1 = subfigs[<span class="number">1</span>].subplots(ncols=<span class="number">3</span>, nrows=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">sns.kdeplot(X_train_pp[:,<span class="number">1</span>], cut=<span class="number">0</span>, fill=<span class="literal">True</span>, ax=axs1[<span class="number">0</span>])</span><br><span class="line">sns.kdeplot(X_train_pp[:,<span class="number">2</span>], cut=<span class="number">0</span>, fill=<span class="literal">True</span>, ax=axs1[<span class="number">1</span>])</span><br><span class="line">sns.kdeplot(X_train_pp[:,<span class="number">3</span>], cut=<span class="number">0</span>, fill=<span class="literal">True</span>, ax=axs1[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> axs1:</span><br><span class="line">    ax.axvline(<span class="number">0</span>, c=<span class="string">&quot;gray&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> axs <span class="keyword">in</span> [axs0, axs1]:</span><br><span class="line">    <span class="keyword">for</span> i, (ax, title) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(axs, [<span class="string">&#x27;bill_depth_mm&#x27;</span>, <span class="string">&#x27;bill_length_mm&#x27;</span>, <span class="string">&#x27;flipper_length_mm&#x27;</span>])):</span><br><span class="line">        ax.set_xlabel(<span class="string">&quot;&quot;</span>)</span><br><span class="line">        ax.set_title(<span class="string">f&quot;<span class="subst">&#123;title&#125;</span>&quot;</span>, fontdict=font_title, pad=<span class="number">16</span>)</span><br><span class="line">        <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">            ax.set_ylabel(<span class="string">&quot; \n&quot;</span>)</span><br><span class="line"></span><br><span class="line">subfigs[<span class="number">0</span>].suptitle(<span class="string">&quot;raw data\n&quot;</span>, fontweight=<span class="string">&quot;bold&quot;</span>)</span><br><span class="line">subfigs[<span class="number">1</span>].suptitle(<span class="string">&quot;preprocessed data\n&quot;</span>, fontweight=<span class="string">&quot;bold&quot;</span>)</span><br><span class="line">fig.suptitle(<span class="string">&quot; &quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="7_skorch_pipeline_1.png"><br></p>
<ul>
<li>RobustScaler의 효과가 잘 보입니다.</li>
</ul>
<h2 id="2-3-pipeline-학습"><a href="#2-3-pipeline-학습" class="headerlink" title="2.3. pipeline 학습"></a>2.3. pipeline 학습</h2><ul>
<li><p><b>pipeline 전체를 사용해서 학습</b>시킵니다.</p>
</li>
<li><p>명령은 scikit-learn 스타일 그대로 <code>.fit()</code>입니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_0.fit(X_train, y_train)</span><br></pre></td></tr></table></figure></li>
<li><p>학습이 잘 되었는지 결과를 확인합니다.</p>
</li>
<li><p>parity plot 시각화 코드는 접어두었습니다.</p>
<details>
  <summary><b>코드 보기/접기</b></summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parity plot</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_parity</span>(<span class="params">model, y_true, y_pred=<span class="literal">None</span>, X_to_pred=<span class="literal">None</span>, ax=<span class="literal">None</span>, **kwargs</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ax:</span><br><span class="line">        fig, ax = plt.subplots(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> y_pred <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        y_pred = model.predict(X_to_pred)</span><br><span class="line">    ax.scatter(y_true, y_pred, **kwargs)</span><br><span class="line">    xbound = ax.get_xbound()</span><br><span class="line">    xticks = [x <span class="keyword">for</span> x <span class="keyword">in</span> ax.get_xticks() <span class="keyword">if</span> xbound[<span class="number">0</span>] &lt;= x &lt;= xbound[<span class="number">1</span>]]</span><br><span class="line">    ax.set_xticks(xticks)</span><br><span class="line">    ax.set_xticklabels([<span class="string">f&quot;<span class="subst">&#123;x:<span class="number">.0</span>f&#125;</span>&quot;</span> <span class="keyword">for</span> x <span class="keyword">in</span> xticks])</span><br><span class="line">    ax.set_yticks(xticks)</span><br><span class="line">    ax.set_yticklabels([<span class="string">f&quot;<span class="subst">&#123;x:<span class="number">.0</span>f&#125;</span>&quot;</span> <span class="keyword">for</span> x <span class="keyword">in</span> xticks])</span><br><span class="line">    dxbound = <span class="number">0.05</span>*(xbound[<span class="number">1</span>]-xbound[<span class="number">0</span>])</span><br><span class="line">    ax.set_xlim(xbound[<span class="number">0</span>]-dxbound, xbound[<span class="number">1</span>]+dxbound)</span><br><span class="line">    ax.set_ylim(xbound[<span class="number">0</span>]-dxbound, xbound[<span class="number">1</span>]+dxbound)</span><br><span class="line">    </span><br><span class="line">    rmse = mean_squared_error(y_true, y_pred, squared=<span class="literal">False</span>)</span><br><span class="line">    r2 = r2_score(y_true, y_pred)</span><br><span class="line">    ax.text(<span class="number">0.95</span>, <span class="number">0.1</span>, <span class="string">f&quot;RMSE = <span class="subst">&#123;rmse:<span class="number">.2</span>f&#125;</span>\nR2 = <span class="subst">&#123;r2:<span class="number">.2</span>f&#125;</span>&quot;</span>, transform=ax.transAxes, </span><br><span class="line">            fontsize=<span class="number">14</span>, ha=<span class="string">&quot;right&quot;</span>, va=<span class="string">&quot;bottom&quot;</span>, bbox=&#123;<span class="string">&quot;boxstyle&quot;</span>:<span class="string">&quot;round&quot;</span>, <span class="string">&quot;fc&quot;</span>:<span class="string">&quot;w&quot;</span>, <span class="string">&quot;pad&quot;</span>:<span class="number">0.3</span>&#125;)</span><br><span class="line">    </span><br><span class="line">    ax.grid(<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ax</span><br><span class="line">    </span><br><span class="line">fig, axs = plt.subplots(ncols=<span class="number">2</span>, figsize=(<span class="number">8</span>, <span class="number">4</span>), constrained_layout=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line">plot_parity(model_0, y_train, X_to_pred=X_train, ax=axs[<span class="number">0</span>], c=<span class="string">&quot;g&quot;</span>, s=<span class="number">10</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plot_parity(model_0, y_test, X_to_pred=X_test, ax=axs[<span class="number">1</span>], c=<span class="string">&quot;m&quot;</span>, s=<span class="number">10</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ax, title <span class="keyword">in</span> <span class="built_in">zip</span>(axs, [<span class="string">&quot;train&quot;</span>, <span class="string">&quot;test&quot;</span>]):</span><br><span class="line">    ax.set_title(title, fontdict=font_title, pad=<span class="number">16</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="7_skorch_pipeline_2.png"><br></p>
<ul>
<li><p>단순 선형 회귀 모델인데 제법 쓸만합니다.</p>
</li>
<li><p>이제 pipeline에 랜덤포레스트 모델을 탑재해서 돌려봅니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_1 = get_model_0(<span class="built_in">list</span>(X_train.columns), degree=<span class="number">1</span>, method=<span class="string">&quot;rf&quot;</span>)</span><br><span class="line">model_1.fit(X_train, y_train)</span><br><span class="line">model_1</span><br></pre></td></tr></table></figure>
<p><img src="7_skorch_pipeline_3.png"><br></p>
</li>
<li><p>과적합이 의심되긴 하지만 랜덤포레스트도 잘 나오네요.</p>
</li>
</ul>
<ul>
<li><p>이번에는 <b>feature selection</b>도 되는지 확인합니다.</p>
</li>
<li><p>부리 길이<code>bill_length_mm</code>와 종<code>species</code>만 가지고 결과를 예측해봅니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_2 = get_model_0([<span class="string">&quot;bill_length_mm&quot;</span>, <span class="string">&quot;species&quot;</span>], degree=<span class="number">1</span>, method=<span class="string">&quot;rf&quot;</span>)</span><br><span class="line">model_2.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><img src="7_skorch_pipeline_4.png"><br></p>
</li>
<li><p>멀쩡한 인자들을 제외했으니 성능이 떨어지는 건 정상입니다.</p>
</li>
<li><p><b>pipeline을 작성하기에 따라 feature 중 일부만 넣어도 동작한다</b>는 것이 중요합니다.</p>
</li>
</ul>
<h1 id="3-pytorch-deep-learning"><a href="#3-pytorch-deep-learning" class="headerlink" title="3. pytorch deep learning"></a>3. pytorch deep learning</h1><ul>
<li>딥러닝은 다른 방법에 비해 복잡하고 연산자원이 많이 들지만 장점이 많습니다.</li>
<li>이미지나 시계열을 다룰 때 큰 힘을 발휘하는데, 간혹 tabular data에도 필요합니다.</li>
<li>pytorch만을 사용해서 모델을 만들어보고 pipeline에 탑재해서도 결과를 얻어봅니다.</li>
</ul>
<h2 id="3-1-pytorch-only"><a href="#3-1-pytorch-only" class="headerlink" title="3.1. pytorch only"></a>3.1. pytorch only</h2><ul>
<li><p>파이토치로 신경망 모델을 만들고 같은 데이터로 같은 문제를 풀어봅니다.</p>
</li>
<li><p>간단한 신경망 모델을 만듭니다. 나중에 pipeline 안에 넣을 겁니다. </p>
</li>
<li><p>feature selection을 대비해서 input dimension을 가변적으로 만듭니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> CyclicLR</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RegressorModule</span>(<span class="params">nn.Module</span>):</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, ninput=<span class="number">11</span>, init_weights=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RegressorModule, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.model = nn.Sequential(nn.Linear(ninput, <span class="number">16</span>),</span><br><span class="line">                                   nn.ReLU(),</span><br><span class="line">                                   nn.Linear(<span class="number">16</span>, <span class="number">16</span>),</span><br><span class="line">                                   nn.ReLU(),</span><br><span class="line">                                   nn.Linear(<span class="number">16</span>, <span class="number">12</span>),</span><br><span class="line">                                   nn.ReLU(),</span><br><span class="line">                                   nn.Linear(<span class="number">12</span>, <span class="number">8</span>),</span><br><span class="line">                                   nn.ReLU(),</span><br><span class="line">                                   nn.Linear(<span class="number">8</span>, <span class="number">1</span>),</span><br><span class="line">                                   )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.model(X)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>pytorch에 데이터를 넣으려면 tensor로 만들어야 합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train_tensor = torch.Tensor(pd.get_dummies(X_train).astype(np.float32).values)</span><br><span class="line">y_train_tensor = torch.Tensor(y_train.astype(np.float32).values)</span><br></pre></td></tr></table></figure></li>
<li><p>지금 만든 모델에 학습을 시킬 수 있는 코드를 구현합니다.</p>
</li>
<li><p>1만 epoch동안 충분히 데이터를 넣어봅니다.</p>
</li>
<li><p>loss function으로는 RMSELoss를 구현해서 사용했습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">net = RegressorModule()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RMSELoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eps=<span class="number">1e-6</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mse = nn.MSELoss()</span><br><span class="line">        self.eps = eps</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,yhat,y</span>):</span></span><br><span class="line">        loss = torch.sqrt(self.mse(yhat,y) + self.eps)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    </span><br><span class="line">loss_func = RMSELoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">losses = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    output = net.forward(X_train_tensor)</span><br><span class="line">    loss = loss_func(output, y_train_tensor.view(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    losses.append(loss)</span><br><span class="line">    </span><br><span class="line">plt.plot(losses)</span><br></pre></td></tr></table></figure>
<p><img src="7_skorch_pipeline_5.png"><br></p>
</li>
</ul>
<ul>
<li><p>제법 학습이 잘 된 것 같습니다.</p>
</li>
<li><p>예측 성능을 확인합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy array를 pytorch tensor로 변환</span></span><br><span class="line">X_test_tensor = torch.Tensor(pd.get_dummies(X_test).astype(np.float32).values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측값</span></span><br><span class="line">y_pred_train_tensor = net.forward(X_train_tensor)</span><br><span class="line">y_pred_test_tensor = net.forward(X_test_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorch tensor를 다시 numpy array로 변환</span></span><br><span class="line">y_pred_train = y_pred_train_tensor.detach().numpy()</span><br><span class="line">y_pred_test = y_pred_test_tensor.detach().numpy()</span><br></pre></td></tr></table></figure>
<p><img src="7_skorch_pipeline_6.png"><br></p>
</li>
<li><p><b>딥러닝으로도 제법 괜찮은 성능이 나오는 것</b>을 확인했습니다.</p>
</li>
</ul>
<h2 id="3-2-pytorch-pipeline"><a href="#3-2-pytorch-pipeline" class="headerlink" title="3.2. pytorch @pipeline"></a>3.2. pytorch @pipeline</h2><ul>
<li><b>skorch를 이용해서 pytorch를 pipeline 안에 탑재합니다.</b></li>
<li><b>skorch은 pytorch를 scikit-learn 객체처럼 만들어주는 일</b>을 합니다.</li>
<li>그래서 skorch로 감싼 pytorch 객체의 학습은 <b><code>fit()</code></b>이고,</li>
<li>예측은 <b><code>.forward()&lt;/b&gt;가 아니라 &lt;b&gt;</code>.predict()</b>입니다.</li>
</ul>
<ul>
<li>skorch의 <code>NeuralNetRegressor()</code>로 딥러닝 모듈 전체를 감싸고,</li>
<li>학습에 필요한 인자를 매개변수로 전달합니다.</li>
</ul>
<ul>
<li>그리고 중요한 사항이 하나 있습니다.</li>
<li><b>scikit-learn이 뱉는 <code>np.float64</code>를 <code>np.float32</code>로 변환</b>해야 합니다.</li>
<li>이를 위해 custom transformer를 만들어 적용합니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skorch <span class="keyword">import</span> NeuralNetRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model_T</span>(<span class="params">X_cols, degree=<span class="number">1</span>, method=<span class="string">&quot;lr&quot;</span></span>):</span></span><br><span class="line">    </span><br><span class="line">    X_cols_ = deepcopy(X_cols)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1-1.categorical feature에 one-hot encoding 적용</span></span><br><span class="line">    cat_features = <span class="built_in">list</span>(<span class="built_in">set</span>(X_cols) &amp; <span class="built_in">set</span>([<span class="string">&quot;species&quot;</span>, <span class="string">&quot;island&quot;</span>, <span class="string">&quot;sex&quot;</span>]))</span><br><span class="line">    cat_transformer = OneHotEncoder(sparse=<span class="literal">False</span>, handle_unknown=<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1-2.numerical feature는 Power Transform과 Scaler를 거침</span></span><br><span class="line">    num_features = <span class="built_in">list</span>(<span class="built_in">set</span>(X_cols) - <span class="built_in">set</span>(cat_features))</span><br><span class="line">    num_features.sort()</span><br><span class="line">    num_transformer = Pipeline(steps=[(<span class="string">&quot;polynomial&quot;</span>, PolynomialFeatures(degree=degree)), </span><br><span class="line">                                      (<span class="string">&quot;scaler&quot;</span>, RobustScaler())</span><br><span class="line">                                     ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 인자 종류별 전처리 적용</span></span><br><span class="line">    preprocessor = ColumnTransformer(transformers=[(<span class="string">&quot;num&quot;</span>, num_transformer, num_features), </span><br><span class="line">                                                   (<span class="string">&quot;cat&quot;</span>, cat_transformer, cat_features)])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. float64를 float32로 변환</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">FloatTransformer</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line">            <span class="keyword">return</span> self</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, x</span>):</span></span><br><span class="line">            <span class="keyword">return</span> np.array(x, dtype=np.float32)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 전처리 후 머신러닝 모델 적용</span></span><br><span class="line">    <span class="keyword">if</span> method == <span class="string">&quot;lr&quot;</span>:</span><br><span class="line">        ml = LinearRegression(fit_intercept=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&quot;rf&quot;</span>:</span><br><span class="line">        ml = RandomForestRegressor()</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&quot;torch&quot;</span>:</span><br><span class="line">        ninput = <span class="built_in">len</span>(num_features) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;species&quot;</span> <span class="keyword">in</span> cat_features:</span><br><span class="line">            ninput += <span class="number">3</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;island&quot;</span> <span class="keyword">in</span> cat_features:</span><br><span class="line">            ninput += <span class="number">3</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;sex&quot;</span> <span class="keyword">in</span> cat_features:</span><br><span class="line">            ninput += <span class="number">2</span></span><br><span class="line">            </span><br><span class="line">        net = NeuralNetRegressor(RegressorModule(ninput=ninput, init_weights=<span class="literal">False</span>),</span><br><span class="line">                         max_epochs=<span class="number">1000</span>, verbose=<span class="number">0</span>,</span><br><span class="line">                         warm_start=<span class="literal">True</span>,</span><br><span class="line"><span class="comment">#                          device=&#x27;cuda&#x27;,</span></span><br><span class="line">                         criterion=RMSELoss,</span><br><span class="line">                         optimizer = optim.Adam,</span><br><span class="line">                         optimizer__lr = <span class="number">0.01</span></span><br><span class="line">                        )</span><br><span class="line">        ml = net</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 3. Pipeline</span></span><br><span class="line">    model = Pipeline(steps=[(<span class="string">&quot;preprocessor&quot;</span>, preprocessor), </span><br><span class="line">                            (<span class="string">&quot;float64to32&quot;</span>, FloatTransformer()),</span><br><span class="line">                            (<span class="string">&quot;ml&quot;</span>, ml)])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></li>
</ul>
<ul>
<li><p>모델을 만들고 확인합니다.</p>
</li>
<li><p>앞서 pytorch로 구현한 뉴럴넷 구조가 그대로 들어가 있습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_T = get_model_T(<span class="built_in">list</span>(X_train.columns), degree=<span class="number">1</span>, method=<span class="string">&quot;torch&quot;</span>)</span><br><span class="line">model_T.fit(X_train, y_train.astype(np.float32).values.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">model_T</span><br></pre></td></tr></table></figure>
<p><img src="7_skorch_pipeline_13.png"><br></p>
</li>
<li><p><b>성능을 확인합니다.</b> 준수하네요.<br><img src="7_skorch_pipeline_7.png"><br></p>
</li>
</ul>
<h1 id="4-permutation-feature-importance"><a href="#4-permutation-feature-importance" class="headerlink" title="4. permutation feature importance"></a>4. permutation feature importance</h1><ul>
<li>같은 파이프라인에서 선형, 트리, 딥러닝이 모두 구현되었습니다.</li>
<li>각각의 인자 중요도를 한번 확인해보겠습니다.</li>
<li>permutation importance를 사용합니다.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.inspection <span class="keyword">import</span> permutation_importance</span><br><span class="line"></span><br><span class="line"><span class="comment"># Linear Regression</span></span><br><span class="line">pi_0 = permutation_importance(model_0, X_test, y_test, n_repeats=<span class="number">30</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Random Forest</span></span><br><span class="line">pi_1 = permutation_importance(model_1, X_test, y_test, n_repeats=<span class="number">30</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Neural Network</span></span><br><span class="line">pi_T = permutation_importance(model_T, X_test, y_test, n_repeats=<span class="number">30</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 시각화</span></span><br><span class="line">fig, axs = plt.subplots(ncols=<span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">5</span>), constrained_layout=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ax, pi, title <span class="keyword">in</span> <span class="built_in">zip</span>(axs, [pi_0, pi_1, pi_T], [<span class="string">&quot;Linear Reg.&quot;</span>, <span class="string">&quot;Random Forest&quot;</span>, <span class="string">&quot;Neural Net&quot;</span>]):</span><br><span class="line">    ax.barh(X_test.columns, pi.importances_mean, xerr=pi.importances_std, color=<span class="string">&quot;orange&quot;</span>)</span><br><span class="line">    ax.invert_yaxis()</span><br><span class="line">    ax.set_xlim(<span class="number">0</span>, )</span><br><span class="line">    ax.set_title(title, fontdict=font_title, pad=<span class="number">16</span>)</span><br></pre></td></tr></table></figure>
<img src="7_skorch_pipeline_8.png"><br></li>
</ul>
<ul>
<li><b>입력 feature별 인자 중요도가 깔끔하게 정리되었습니다.</b></li>
<li>양상도 전반적으로 비슷하게 나오네요.</li>
<li>사소한 기능같지만 <b>tabular data를 딥러닝으로 돌렸을 때 이 그림을 그리기가 어려웠습니다.</b></li>
<li>이 글과 코드가 비슷한 어려움을 겪는 여러분께 도움이 되면 좋겠습니다.</li>
</ul>

        </div>
		<p>
		<div style="text-align:center; margin:20px 0px 20px 0px">
		  <a href="https://donaricano.com/mypage/1543013959_CGtZmr" target="_blank">
			<img
			 src="https://d1u4yishnma8v5.cloudfront.net/donarincano_gift.png"
			 style="height:70px !important;width: 200px !important;"
			 />
		 </a><br>
		 <p><b>도움이 되셨나요?<p>카페인을 투입하시면 다음 포스팅으로 변환됩니다</b>
		</div>
        <footer class="article-footer">
            



    <a data-url="https://jehyunlee.github.io/2021/09/29/Python-DL-7-skorch_pipeline/" data-id="ckwknn50600ur74tq3cix9jvm" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "Jehyun Lee"
        },
        "headline": "pytorch &amp; sklearn pipeline",
        "image": "https://jehyunlee.github.io/thumbnails/Python-DL/7_skorch_pipeline_0.png",
        "keywords": "pytorch sklearn pipeline neural network",
        "genre": "Python Deep Learning",
        "datePublished": "2021-09-29",
        "dateCreated": "2021-09-29",
        "dateModified": "2021-09-30",
        "url": "https://jehyunlee.github.io/2021/09/29/Python-DL-7-skorch_pipeline/",
        "description": "
저는 tabular data를 다룹니다.
간혹 딥러닝을 하고 싶지만 표준화등 전처리도 해야 합니다.
범주형 변수를 인코딩해서 feature importance도 보고 싶습니다.
skorch(sklearn + pytorch)를 사용하면 가능합니다.

1. skorch = sklearn + pytorch

skorch documentationskorch tu",
        "wordCount": 4130
    }
</script>

</article>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/jehyunlee" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="https://jehyunlee.github.io/rss2.xml" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="instagram" href="https://www.instagram.com/jehyunlee20/" target="_blank" rel="noopener">
                        <i class="icon fa fa-instagram"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2021/10/05/Python-DS-85-popkr/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Population by gender and age
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2021/09/26/Python-General-9-fullmoon/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">Full moon</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/11/29/Python-DS-91-movie01/" class="thumbnail">
    
    
        <span style="background-image:url(/thumbnails/Python-DS/91_movie01_0.png)" alt="NIA Data Story - Movie) 0. intro" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Python/Data-Science/">Data Science</a></p>
                            <p class="item-title"><a href="/2021/11/29/Python-DS-91-movie01/" class="title">NIA Data Story - Movie) 0. intro</a></p>
                            <p class="item-date"><time datetime="2021-11-29T11:50:00.000Z" itemprop="datePublished">2021-11-29</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/11/22/Python-DS-90-density2d/" class="thumbnail">
    
    
        <span style="background-image:url(/thumbnails/Python-DS/90_density2d_00.png)" alt="2D distribution" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Python/Data-Science/">Data Science</a></p>
                            <p class="item-title"><a href="/2021/11/22/Python-DS-90-density2d/" class="title">2D distribution</a></p>
                            <p class="item-date"><time datetime="2021-11-22T11:50:00.000Z" itemprop="datePublished">2021-11-22</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/11/17/Python-DS-89_matprop/" class="thumbnail">
    
    
        <span style="background-image:url(/thumbnails/Python-DS/89_matprop_00.png)" alt="material property visualization" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Python/Data-Science/">Data Science</a></p>
                            <p class="item-title"><a href="/2021/11/17/Python-DS-89_matprop/" class="title">material property visualization</a></p>
                            <p class="item-date"><time datetime="2021-11-17T04:50:00.000Z" itemprop="datePublished">2021-11-17</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/11/09/Python-DS-88_gpd_mpl/" class="thumbnail">
    
    
        <span style="background-image:url(/thumbnails/Python-DS/88_gpd_mpl_00.png)" alt="solar radiation - time and space" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Python/Data-Science/">Data Science</a></p>
                            <p class="item-title"><a href="/2021/11/09/Python-DS-88_gpd_mpl/" class="title">solar radiation - time and space</a></p>
                            <p class="item-date"><time datetime="2021-11-09T10:38:00.000Z" itemprop="datePublished">2021-11-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/10/21/Python-DS-87_violinplotedit/" class="thumbnail">
    
    
        <span style="background-image:url(/thumbnails/Python-DS/87_violinplotedit00.png)" alt="modifying seaborn violin plot" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Python/Data-Science/">Data Science</a></p>
                            <p class="item-title"><a href="/2021/10/21/Python-DS-87_violinplotedit/" class="title">modifying seaborn violin plot</a></p>
                            <p class="item-date"><time datetime="2021-10-21T00:11:00.000Z" itemprop="datePublished">2021-10-21</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/GIS/">GIS</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GIS/Python/">Python</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/GIS/QGIS/">QGIS</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ImageJ/">ImageJ</a><span class="category-list-count">12</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ImageJ/Cookbook/">Cookbook</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ImageJ/Tutorial/">Tutorial</a><span class="category-list-count">8</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">105</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Data-Science/">Data Science</a><span class="category-list-count">89</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Deep-Learning/">Deep Learning</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/General/">General</a><span class="category-list-count">9</span></li></ul></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/1-cycle-learning-rate-policy/" style="font-size: 10px;">1 cycle learning rate policy</a> <a href="/tags/3D/" style="font-size: 12.14px;">3D</a> <a href="/tags/AI-Factory/" style="font-size: 10px;">AI Factory</a> <a href="/tags/AI-Frenz/" style="font-size: 11.43px;">AI Frenz</a> <a href="/tags/AI-festival/" style="font-size: 10.71px;">AI festival</a> <a href="/tags/Daejeon-Learning-Day/" style="font-size: 10px;">Daejeon Learning Day</a> <a href="/tags/Daejeon-Science-Festival/" style="font-size: 10px;">Daejeon Science Festival</a> <a href="/tags/Data-Scienctist/" style="font-size: 10px;">Data Scienctist</a> <a href="/tags/FacetGrid/" style="font-size: 10px;">FacetGrid</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/Google-Colab/" style="font-size: 10px;">Google Colab</a> <a href="/tags/Google-Form/" style="font-size: 10px;">Google Form</a> <a href="/tags/HelloDD/" style="font-size: 10px;">HelloDD</a> <a href="/tags/KIER/" style="font-size: 10px;">KIER</a> <a href="/tags/NIA/" style="font-size: 10px;">NIA</a> <a href="/tags/PCA/" style="font-size: 10px;">PCA</a> <a href="/tags/PairGrid/" style="font-size: 10px;">PairGrid</a> <a href="/tags/VOSviewer/" style="font-size: 10.71px;">VOSviewer</a> <a href="/tags/X-STEM/" style="font-size: 10px;">X-STEM</a> <a href="/tags/align/" style="font-size: 10px;">align</a> <a href="/tags/annotate/" style="font-size: 10px;">annotate</a> <a href="/tags/art/" style="font-size: 10px;">art</a> <a href="/tags/article/" style="font-size: 10px;">article</a> <a href="/tags/ascii/" style="font-size: 10px;">ascii</a> <a href="/tags/atom/" style="font-size: 10.71px;">atom</a> <a href="/tags/automation/" style="font-size: 10px;">automation</a> <a href="/tags/axes/" style="font-size: 10px;">axes</a> <a href="/tags/batch/" style="font-size: 10px;">batch</a> <a href="/tags/batch-normalization/" style="font-size: 10.71px;">batch normalization</a> <a href="/tags/bresenham/" style="font-size: 10px;">bresenham</a> <a href="/tags/calendar/" style="font-size: 10.71px;">calendar</a> <a href="/tags/calibration/" style="font-size: 10px;">calibration</a> <a href="/tags/channel-threshold/" style="font-size: 10px;">channel threshold</a> <a href="/tags/chrome-remote-desktop/" style="font-size: 10px;">chrome remote desktop</a> <a href="/tags/class/" style="font-size: 10px;">class</a> <a href="/tags/code-states/" style="font-size: 10px;">code states</a> <a href="/tags/cognitive-science/" style="font-size: 11.43px;">cognitive science</a> <a href="/tags/color/" style="font-size: 15.71px;">color</a> <a href="/tags/colorbar/" style="font-size: 12.86px;">colorbar</a> <a href="/tags/colormap/" style="font-size: 15px;">colormap</a> <a href="/tags/confidence-interval/" style="font-size: 10px;">confidence interval</a> <a href="/tags/convolution/" style="font-size: 10px;">convolution</a> <a href="/tags/cookbook/" style="font-size: 10.71px;">cookbook</a> <a href="/tags/csv/" style="font-size: 10px;">csv</a> <a href="/tags/data-augmentation/" style="font-size: 10px;">data augmentation</a> <a href="/tags/data-cleansing/" style="font-size: 10px;">data cleansing</a> <a href="/tags/data-generation/" style="font-size: 10.71px;">data generation</a> <a href="/tags/data-preprocessing/" style="font-size: 10px;">data preprocessing</a> <a href="/tags/data-sampling/" style="font-size: 10.71px;">data sampling</a> <a href="/tags/datetime/" style="font-size: 11.43px;">datetime</a> <a href="/tags/deep-learning/" style="font-size: 10px;">deep learning</a> <a href="/tags/displot/" style="font-size: 10px;">displot</a> <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/environment/" style="font-size: 10px;">environment</a> <a href="/tags/error-bar/" style="font-size: 10px;">error bar</a> <a href="/tags/fast-ai/" style="font-size: 10px;">fast.ai</a> <a href="/tags/font/" style="font-size: 10.71px;">font</a> <a href="/tags/geopandas/" style="font-size: 10px;">geopandas</a> <a href="/tags/get-data/" style="font-size: 10px;">get_data</a> <a href="/tags/get-lines/" style="font-size: 10px;">get_lines</a> <a href="/tags/gibbs-sampling/" style="font-size: 10px;">gibbs sampling</a> <a href="/tags/gis/" style="font-size: 14.29px;">gis</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/gitignore/" style="font-size: 10px;">gitignore</a> <a href="/tags/google-map/" style="font-size: 10px;">google map</a> <a href="/tags/google-trends/" style="font-size: 10px;">google trends</a> <a href="/tags/grid/" style="font-size: 10px;">grid</a> <a href="/tags/gridspec/" style="font-size: 10px;">gridspec</a> <a href="/tags/image/" style="font-size: 12.14px;">image</a> <a href="/tags/image-file/" style="font-size: 10px;">image file</a> <a href="/tags/imagej/" style="font-size: 16.43px;">imagej</a> <a href="/tags/inspection/" style="font-size: 10px;">inspection</a> <a href="/tags/installation/" style="font-size: 10px;">installation</a> <a href="/tags/io/" style="font-size: 10px;">io</a> <a href="/tags/isomap/" style="font-size: 10px;">isomap</a> <a href="/tags/jointplot/" style="font-size: 10px;">jointplot</a> <a href="/tags/jupyter-lab/" style="font-size: 10.71px;">jupyter lab</a> <a href="/tags/jython/" style="font-size: 12.86px;">jython</a> <a href="/tags/keras/" style="font-size: 10.71px;">keras</a> <a href="/tags/keras-learing-day/" style="font-size: 10px;">keras learing day</a> <a href="/tags/learning-rate/" style="font-size: 10px;">learning rate</a> <a href="/tags/legend/" style="font-size: 11.43px;">legend</a> <a href="/tags/linear-algebra/" style="font-size: 10px;">linear algebra</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/locally-linear-embedding/" style="font-size: 10px;">locally linear embedding</a> <a href="/tags/machine-learning/" style="font-size: 12.86px;">machine learning</a> <a href="/tags/matplotlib/" style="font-size: 18.57px;">matplotlib</a> <a href="/tags/midnight-commander/" style="font-size: 10px;">midnight commander</a> <a href="/tags/minimum-oriented-rectangle/" style="font-size: 10px;">minimum oriented rectangle</a> <a href="/tags/multidimensional-scaling/" style="font-size: 10px;">multidimensional scaling</a> <a href="/tags/natural-language/" style="font-size: 10.71px;">natural language</a> <a href="/tags/naver-map/" style="font-size: 10px;">naver map</a> <a href="/tags/neural-network/" style="font-size: 10px;">neural network</a> <a href="/tags/numpy/" style="font-size: 10.71px;">numpy</a> <a href="/tags/object-minimum-bounding-box/" style="font-size: 10px;">object minimum bounding box</a> <a href="/tags/open-API/" style="font-size: 10px;">open API</a> <a href="/tags/pairplot/" style="font-size: 10px;">pairplot</a> <a href="/tags/pandas/" style="font-size: 15.71px;">pandas</a> <a href="/tags/paraview/" style="font-size: 10.71px;">paraview</a> <a href="/tags/patches/" style="font-size: 10px;">patches</a> <a href="/tags/person-correlation/" style="font-size: 10px;">person correlation</a> <a href="/tags/pipeline/" style="font-size: 10px;">pipeline</a> <a href="/tags/polygon/" style="font-size: 11.43px;">polygon</a> <a href="/tags/powerpoint/" style="font-size: 10px;">powerpoint</a> <a href="/tags/presentation/" style="font-size: 17.14px;">presentation</a> <a href="/tags/principal-component-analysis/" style="font-size: 10px;">principal component analysis</a> <a href="/tags/probability/" style="font-size: 10.71px;">probability</a> <a href="/tags/proj/" style="font-size: 10px;">proj</a> <a href="/tags/pycon/" style="font-size: 10px;">pycon</a> <a href="/tags/pysolar/" style="font-size: 10.71px;">pysolar</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/pytorch/" style="font-size: 10.71px;">pytorch</a> <a href="/tags/qgis/" style="font-size: 10.71px;">qgis</a> <a href="/tags/raster/" style="font-size: 10.71px;">raster</a> <a href="/tags/ridgeplot/" style="font-size: 10.71px;">ridgeplot</a> <a href="/tags/roi/" style="font-size: 10px;">roi</a> <a href="/tags/savgol/" style="font-size: 10px;">savgol</a> <a href="/tags/scatter-density/" style="font-size: 10px;">scatter-density</a> <a href="/tags/sciencedirect/" style="font-size: 10px;">sciencedirect</a> <a href="/tags/scipy/" style="font-size: 10px;">scipy</a> <a href="/tags/scopus/" style="font-size: 10px;">scopus</a> <a href="/tags/script/" style="font-size: 10px;">script</a> <a href="/tags/seaborn/" style="font-size: 17.86px;">seaborn</a> <a href="/tags/segmentation/" style="font-size: 10px;">segmentation</a> <a href="/tags/set/" style="font-size: 10px;">set</a> <a href="/tags/shadow/" style="font-size: 10px;">shadow</a> <a href="/tags/shapefile/" style="font-size: 10.71px;">shapefile</a> <a href="/tags/signal-processing/" style="font-size: 12.14px;">signal processing</a> <a href="/tags/sklearn/" style="font-size: 12.14px;">sklearn</a> <a href="/tags/spines/" style="font-size: 10px;">spines</a> <a href="/tags/statistics/" style="font-size: 13.57px;">statistics</a> <a href="/tags/streamgraph/" style="font-size: 10px;">streamgraph</a> <a href="/tags/subplots/" style="font-size: 10.71px;">subplots</a> <a href="/tags/t-SNE/" style="font-size: 10px;">t-SNE</a> <a href="/tags/tensorflow/" style="font-size: 11.43px;">tensorflow</a> <a href="/tags/text/" style="font-size: 10px;">text</a> <a href="/tags/text-mining/" style="font-size: 10.71px;">text mining</a> <a href="/tags/translation/" style="font-size: 11.43px;">translation</a> <a href="/tags/uncertainty/" style="font-size: 10px;">uncertainty</a> <a href="/tags/unicode/" style="font-size: 10px;">unicode</a> <a href="/tags/vector/" style="font-size: 10px;">vector</a> <a href="/tags/vesta/" style="font-size: 10px;">vesta</a> <a href="/tags/visualization/" style="font-size: 19.29px;">visualization</a> <a href="/tags/wsl/" style="font-size: 10px;">wsl</a> <a href="/tags/x-window/" style="font-size: 10px;">x-window</a> <a href="/tags/xception/" style="font-size: 10px;">xception</a> <a href="/tags/youth/" style="font-size: 10px;">youth</a>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2021 Jehyun Lee</p>
                
                <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="https://github.com/ppoffice" target="_blank">PPOffice</a></p>
                
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

    </div>
    
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://jehyunlee.github.io/2021/09/29/Python-DL-7-skorch_pipeline/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>





    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML.js"></script>

    

    
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


</body>
</html>
